{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model3_feature3_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKhhaHUvYgoa",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition + 2 bi-lstm + 2 self-attention + scaled + 3 features + lr = 0.0005 + hidden dim = 100\n",
        "\n",
        "test acc: 0.9576\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY4scQ1RUve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwUrZvQakO2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "id = '1m2je3m7MiyHJynZv8bUtmUYWUJy7vCTl'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1Cm_SL9JHgJ6_1qh6FeuOpUFi_-lbtQw3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "id = '18Av4rRPwnlCdF2V4wXKioYlPNy7DgzFJ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtRDEwSCMcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the files of the PoS tags for the dataset\n",
        "# PoS tags are used as one of the features \n",
        "\n",
        "id = '1UmNHdUZxjfcuIzCcAKuBvfBXdSWFv47i'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.txt')\n",
        "\n",
        "id = '11bZIh5V9m2nZJ5s5xQ_gxHEHkAEhV8eQ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('validation.txt')\n",
        "\n",
        "id = '1V-LQuJWT62aCytYuhZuaxvICsqiF1rdK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK73yG9zfHbt",
        "colab_type": "code",
        "outputId": "796d2eee-a287-401e-dcce-5d97bbeed236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# create a list of Sentence and a list of NER\n",
        "\n",
        "sentences_train = df_train['Sentence'].tolist()\n",
        "ner_train = df_train['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_train_split = []\n",
        "ner_train_split = []\n",
        "for each_sentence in sentences_train:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_train_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_train:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_train_split.append(each_ner)\n",
        "print(sentence_train_split[1][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNInRtB7PDia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_val = df_val['Sentence'].tolist()\n",
        "ner_val = df_val['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_val_split = []\n",
        "ner_val_split = []\n",
        "for each_sentence in sentences_val:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_val_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_val:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_val_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjohNx5IvRVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence\n",
        "\n",
        "sentences_test = df_test['Sentence'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_test_split = []\n",
        "\n",
        "for each_sentence in sentences_test:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_test_split.append(each_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S049P4HVDJTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "    pos_data = []\n",
        "    pos = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':   \n",
        "            pos_data.append(pos)\n",
        "            pos = []\n",
        "        else:    \n",
        "            pos.append(i.replace('\\n','').split(' ')[1])\n",
        "    return pos_data[:n_sample]\n",
        "\n",
        "pos_train = read_data(\"train.txt\", 3000)\n",
        "pos_validation = read_data(\"validation.txt\",700)\n",
        "pos_test = read_data(\"test.txt\",3684)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5gUSbrHQ6J2",
        "colab_type": "text"
      },
      "source": [
        "# Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH_xBcfvfQp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirHmtHeIcGp",
        "colab_type": "code",
        "outputId": "9a13e38d-74d2-4574-9cde-ddf37735eabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "total_words = []\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        total_words.append(word)\n",
        "\n",
        "print(len(total_words))\n",
        "print(len(set(total_words)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93794\n",
            "13972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ezZdNCrEDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pos_list = []\n",
        "\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    pos_line = []\n",
        "    for each_pos in line:\n",
        "        pos_line.append(each_pos)\n",
        "    total_pos_list.append(pos_line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQNSEP8HXtS",
        "colab_type": "code",
        "outputId": "115a8f8a-87c4-452a-9bb9-6af8d05bbf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pos_to_ix = {}\n",
        "pos_list = []\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    for pos in line:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "pos_list = sorted(list(pos_to_ix.keys()))\n",
        "\n",
        "pos_list_length = len(pos_list)\n",
        "print(pos_list_length)\n",
        "print(pos_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My7OPDfWVvnk",
        "colab_type": "code",
        "outputId": "874bfc7b-2761-4782-b53c-9f08035ed656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# key is the pos tag, value is the one hot expression\n",
        "onehotpos = {}\n",
        "\n",
        "for i in range(pos_list_length):   \n",
        "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
        "    onehotpos[pos_list[i]] = list(onehot[0])\n",
        "\n",
        "print(onehotpos)\n",
        "\n",
        "def get_onehotpos(pos_sentence):\n",
        "    pos_list = []\n",
        "    for each_pos in pos_sentence:\n",
        "        onehot_pos = onehotpos[each_pos]\n",
        "        pos_list.append(onehot_pos)\n",
        "    return pos_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14mferpb4dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
        "sentence_to_pos = {}\n",
        "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
        "for i in range(total_length):\n",
        "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sf0ks6vBHqI",
        "colab_type": "code",
        "outputId": "423b03fa-fc5d-4b41-a837-7c7178f55072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(sentence_to_pos[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1NsLQ3qlBP",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XY3R9ePJOY",
        "colab_type": "code",
        "outputId": "fb17bc4d-4e13-45c9-807f-d0e3af0f4406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "DF = {}\n",
        "\n",
        "for each_sentence in total_sentences:\n",
        "    for term in np.unique(each_sentence):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "\n",
        "print(len(DF))\n",
        "\n",
        "\n",
        "tf_idf = {}\n",
        "N = total_length\n",
        "print(N)\n",
        "\n",
        "for i in range(N):\n",
        "    counter = Counter(total_sentences[i])\n",
        "    total_num_words = len(total_sentences[i])   \n",
        "    # the tfidf of all words in a sentence\n",
        "    each_sentence_tfidf = []\n",
        "    \n",
        "    for term in total_sentences[i]:\n",
        "        tf = counter[term]/total_num_words\n",
        "        df = DF[term]\n",
        "        idf = math.log(N/(df+1))+1\n",
        "        each_sentence_tfidf.append(tf*idf)\n",
        "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
        "    tf_idf[i] = each_sentence_tfidf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "7384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0WnqcLhCxNh",
        "colab_type": "code",
        "outputId": "48079d7d-5154-4e08-cc9a-cc4e25ceed03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(tf_idf[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.7867733572317377]\n",
            "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
            "[3.8549230994232344, 3.711082063197344]\n",
            "[3.236541785848771, 2.568193075858512]\n",
            "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFq1dlZnO9mi",
        "colab_type": "code",
        "outputId": "63b330fb-e716-4052-e9b9-0b26eb6764a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1\n",
            "9 9\n",
            "2 2\n",
            "2 2\n",
            "30 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3DcyEtJ93fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        sentence_feature_list = []\n",
        "        for j in range(len(sentence_to_pos[i])): \n",
        "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
        "        \n",
        "        feature_list.append(sentence_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0Tv48EMi__",
        "colab_type": "code",
        "outputId": "e6ed51eb-95d4-49eb-c7d1-0fc69354a27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "print(get_feature(0,5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7og4EnAq8aG",
        "colab_type": "text"
      },
      "source": [
        "## Distribution Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-vnejvEDZ7",
        "colab_type": "code",
        "outputId": "0dbc5b6c-0173-49de-f3fd-085ee59bfd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentence_lengths = []\n",
        "for each_sentence in total_sentences:\n",
        "    length = len(each_sentence)\n",
        "    sentence_lengths.append(length)\n",
        "\n",
        "total_sentence_num = len(sentence_lengths)\n",
        "largest_length = max(sentence_lengths)\n",
        "mean_length = np.mean(sentence_lengths)\n",
        "counts_length = np.bincount(sentence_lengths)\n",
        "counts_length = np.argmax(counts_length)\n",
        "length_less_than_counts = 0\n",
        "length_less_than_mean = 0 \n",
        "length_less_than_15 = 0\n",
        "length_less_than_20 = 0\n",
        "length_less_than_25 = 0\n",
        "length_less_than_30 = 0\n",
        "\n",
        "for length in sentence_lengths:\n",
        "  if length < counts_length:\n",
        "    length_less_than_counts += 1\n",
        "  if length < mean_length:\n",
        "    length_less_than_mean += 1\n",
        "  if length < 15:\n",
        "    length_less_than_15 += 1\n",
        "  if length < 20:\n",
        "    length_less_than_20 += 1\n",
        "  if length < 25:\n",
        "    length_less_than_25 += 1\n",
        "  if length < 30:\n",
        "    length_less_than_30 += 1\n",
        "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
        "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
        "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
        "print(y_rate)\n",
        "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences: 7384 Largest length of the sentence: 124\n",
            "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFsK7PUsNox",
        "colab_type": "text"
      },
      "source": [
        "There are 5 kinds of tag in total.\n",
        "\n",
        "'I-ORG': Organization\n",
        "\n",
        "'O': Other\n",
        "\n",
        "'I-LOC': Location \n",
        "\n",
        "'I-PER': Person \n",
        "\n",
        "'I-MISC': Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-UMIHEKrgCw",
        "colab_type": "code",
        "outputId": "bc8eb221-662e-4966-d75f-f339b20d1c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ner_train_list = []\n",
        "for each_ner in ner_train_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_train_list.append(each_tag)\n",
        "ner_train_set = list(set(ner_train_list))\n",
        "print(len(ner_train_list))\n",
        "print(len(ner_train_set))\n",
        "print(ner_train_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39572\n",
            "5\n",
            "['I-PER', 'O', 'I-MISC', 'I-ORG', 'I-LOC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chjiqNYkzNK",
        "colab_type": "code",
        "outputId": "e2e47b17-4fe2-479e-de1d-8d72afb6279b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ner_val_list = []\n",
        "for each_ner in ner_val_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_val_list.append(each_tag)\n",
        "ner_val_set = list(set(ner_val_list))\n",
        "print(len(ner_val_list))\n",
        "print(len(ner_val_set))\n",
        "print(ner_val_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556\n",
            "5\n",
            "['I-PER', 'O', 'I-MISC', 'I-ORG', 'I-LOC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDuagDgs1Yj4",
        "colab_type": "code",
        "outputId": "47baf435-b08f-44bc-880e-2c1180eee89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_train_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   1526\n",
            "O:       32137\n",
            "I-LOC:   1994\n",
            "I-PER:   2840\n",
            "I-MISC:  1075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_NXJRv7k__M",
        "colab_type": "code",
        "outputId": "163d18aa-98cb-48a4-c45d-958bb2b97051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_val_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   285\n",
            "O:       5790\n",
            "I-LOC:   419\n",
            "I-PER:   875\n",
            "I-MISC:  187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9s9J-lDKUC",
        "colab_type": "text"
      },
      "source": [
        "In the data, you can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfakfv0CRwAB",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "There are too many NaN values in Sentence # column, fill NaN by preceding values.\n",
        "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcu5O3OlEdPA",
        "colab_type": "text"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsvF8uXSgy5",
        "colab_type": "code",
        "outputId": "cb69eeb0-c826-455e-b231-4b4b5edfb799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\r\u001b[K     |                               | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |                               | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |                              | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |                              | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |                             | 51kB 9.8MB/s eta 0:00:01\r\u001b[K     |                             | 61kB 10.8MB/s eta 0:00:01\r\u001b[K     |                             | 71kB 11.0MB/s eta 0:00:01\r\u001b[K     |                            | 81kB 11.8MB/s eta 0:00:01\r\u001b[K     |                            | 92kB 10.8MB/s eta 0:00:01\r\u001b[K     |                           | 102kB 11.3MB/s eta 0:00:01\r\u001b[K     |                           | 112kB 11.3MB/s eta 0:00:01\r\u001b[K     |                          | 122kB 11.3MB/s eta 0:00:01\r\u001b[K     |                          | 133kB 11.3MB/s eta 0:00:01\r\u001b[K     |                         | 143kB 11.3MB/s eta 0:00:01\r\u001b[K     |                         | 153kB 11.3MB/s eta 0:00:01\r\u001b[K     |                         | 163kB 11.3MB/s eta 0:00:01\r\u001b[K     |                        | 174kB 11.3MB/s eta 0:00:01\r\u001b[K     |                        | 184kB 11.3MB/s eta 0:00:01\r\u001b[K     |                       | 194kB 11.3MB/s eta 0:00:01\r\u001b[K     |                       | 204kB 11.3MB/s eta 0:00:01\r\u001b[K     |                      | 215kB 11.3MB/s eta 0:00:01\r\u001b[K     |                      | 225kB 11.3MB/s eta 0:00:01\r\u001b[K     |                     | 235kB 11.3MB/s eta 0:00:01\r\u001b[K     |                     | 245kB 11.3MB/s eta 0:00:01\r\u001b[K     |                     | 256kB 11.3MB/s eta 0:00:01\r\u001b[K     |                    | 266kB 11.3MB/s eta 0:00:01\r\u001b[K     |                    | 276kB 11.3MB/s eta 0:00:01\r\u001b[K     |                   | 286kB 11.3MB/s eta 0:00:01\r\u001b[K     |                   | 296kB 11.3MB/s eta 0:00:01\r\u001b[K     |                  | 307kB 11.3MB/s eta 0:00:01\r\u001b[K     |                  | 317kB 11.3MB/s eta 0:00:01\r\u001b[K     |                  | 327kB 11.3MB/s eta 0:00:01\r\u001b[K     |                 | 337kB 11.3MB/s eta 0:00:01\r\u001b[K     |                 | 348kB 11.3MB/s eta 0:00:01\r\u001b[K     |                | 358kB 11.3MB/s eta 0:00:01\r\u001b[K     |                | 368kB 11.3MB/s eta 0:00:01\r\u001b[K     |               | 378kB 11.3MB/s eta 0:00:01\r\u001b[K     |               | 389kB 11.3MB/s eta 0:00:01\r\u001b[K     |              | 399kB 11.3MB/s eta 0:00:01\r\u001b[K     |              | 409kB 11.3MB/s eta 0:00:01\r\u001b[K     |              | 419kB 11.3MB/s eta 0:00:01\r\u001b[K     |             | 430kB 11.3MB/s eta 0:00:01\r\u001b[K     |             | 440kB 11.3MB/s eta 0:00:01\r\u001b[K     |            | 450kB 11.3MB/s eta 0:00:01\r\u001b[K     |            | 460kB 11.3MB/s eta 0:00:01\r\u001b[K     |           | 471kB 11.3MB/s eta 0:00:01\r\u001b[K     |           | 481kB 11.3MB/s eta 0:00:01\r\u001b[K     |          | 491kB 11.3MB/s eta 0:00:01\r\u001b[K     |          | 501kB 11.3MB/s eta 0:00:01\r\u001b[K     |          | 512kB 11.3MB/s eta 0:00:01\r\u001b[K     |         | 522kB 11.3MB/s eta 0:00:01\r\u001b[K     |         | 532kB 11.3MB/s eta 0:00:01\r\u001b[K     |        | 542kB 11.3MB/s eta 0:00:01\r\u001b[K     |        | 552kB 11.3MB/s eta 0:00:01\r\u001b[K     |       | 563kB 11.3MB/s eta 0:00:01\r\u001b[K     |       | 573kB 11.3MB/s eta 0:00:01\r\u001b[K     |       | 583kB 11.3MB/s eta 0:00:01\r\u001b[K     |      | 593kB 11.3MB/s eta 0:00:01\r\u001b[K     |      | 604kB 11.3MB/s eta 0:00:01\r\u001b[K     |     | 614kB 11.3MB/s eta 0:00:01\r\u001b[K     |     | 624kB 11.3MB/s eta 0:00:01\r\u001b[K     |    | 634kB 11.3MB/s eta 0:00:01\r\u001b[K     |    | 645kB 11.3MB/s eta 0:00:01\r\u001b[K     |   | 655kB 11.3MB/s eta 0:00:01\r\u001b[K     |   | 665kB 11.3MB/s eta 0:00:01\r\u001b[K     |   | 675kB 11.3MB/s eta 0:00:01\r\u001b[K     |  | 686kB 11.3MB/s eta 0:00:01\r\u001b[K     |  | 696kB 11.3MB/s eta 0:00:01\r\u001b[K     | | 706kB 11.3MB/s eta 0:00:01\r\u001b[K     | | 716kB 11.3MB/s eta 0:00:01\r\u001b[K     || 727kB 11.3MB/s eta 0:00:01\r\u001b[K     || 737kB 11.3MB/s eta 0:00:01\r\u001b[K     || 747kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4F991p-IqNS",
        "colab_type": "text"
      },
      "source": [
        "##Conditional random fields (CRF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Xcf07iR79l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPELELtSmYo",
        "colab_type": "code",
        "outputId": "bf2daef2-b1be-4de9-8b56-82fbd8136197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_train = []\n",
        "for line in range(len(sentence_train_split)):\n",
        "    combine_sentence = []\n",
        "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
        "        combine_sentence.append((each_word, each_tag))\n",
        "    zip_sentences_train.append(combine_sentence)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
            "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
            "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJIH2emlP1y",
        "colab_type": "code",
        "outputId": "4da11329-c869-477e-8897-9ec67cb9504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_val = []\n",
        "for line in range(len(sentence_val_split)):\n",
        "    combine_sentence_val = []\n",
        "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
        "        combine_sentence_val.append((each_word, each_tag))\n",
        "    zip_sentences_val.append(combine_sentence_val)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_val[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('cricket', 'O'), ('-', 'O'), ('leicestershire', 'I-ORG'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('top', 'O'), ('after', 'O'), ('innings', 'O'), ('victory', 'O'), ('.', 'O')]\n",
            "[('london', 'I-LOC'), ('1996-08-30', 'O')]\n",
            "[('west', 'I-MISC'), ('indian', 'I-MISC'), ('all-rounder', 'O'), ('phil', 'I-PER'), ('simmons', 'I-PER'), ('took', 'O'), ('four', 'O'), ('for', 'O'), ('38', 'O'), ('on', 'O'), ('friday', 'O'), ('as', 'O'), ('leicestershire', 'I-ORG'), ('beat', 'O'), ('somerset', 'I-ORG'), ('by', 'O'), ('an', 'O'), ('innings', 'O'), ('and', 'O'), ('39', 'O'), ('runs', 'O'), ('in', 'O'), ('two', 'O'), ('days', 'O'), ('to', 'O'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('the', 'O'), ('head', 'O'), ('of', 'O'), ('the', 'O'), ('county', 'O'), ('championship', 'O'), ('.', 'O')]\n",
            "[('their', 'O'), ('stay', 'O'), ('on', 'O'), ('top', 'O'), (',', 'O'), ('though', 'O'), (',', 'O'), ('may', 'O'), ('be', 'O'), ('short-lived', 'O'), ('as', 'O'), ('title', 'O'), ('rivals', 'O'), ('essex', 'I-ORG'), (',', 'O'), ('derbyshire', 'I-ORG'), ('and', 'O'), ('surrey', 'I-ORG'), ('all', 'O'), ('closed', 'O'), ('in', 'O'), ('on', 'O'), ('victory', 'O'), ('while', 'O'), ('kent', 'I-ORG'), ('made', 'O'), ('up', 'O'), ('for', 'O'), ('lost', 'O'), ('time', 'O'), ('in', 'O'), ('their', 'O'), ('rain-affected', 'O'), ('match', 'O'), ('against', 'O'), ('nottinghamshire', 'I-ORG'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alfVxIWIFEth",
        "colab_type": "text"
      },
      "source": [
        "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite formateach sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbaee897Sqoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    # postag = sent[i][1]\n",
        "    # a few features: upper? lower? title? \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:], # last three letters of the word\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(), \n",
        "        'word.istitle()': word.istitle(), # is it a title?\n",
        "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
        "       \n",
        "    }\n",
        "    # features of the previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        # postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "          \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    # features of the next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "       \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            \n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9Xu722SzYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features_train = [sent2features(s) for s in zip_sentences_train]\n",
        "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
        "\n",
        "features_val = [sent2features(s) for s in zip_sentences_val]\n",
        "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3g66D_kMlCp",
        "colab_type": "code",
        "outputId": "9ec225ef-1766-4751-8890-7e01f6eb43ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "     print(features_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'bias': 1.0, 'word.lower()': '-docstart-', 'word[-3:]': 'rt-', 'word[-2:]': 't-', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'eu', 'word[-3:]': 'eu', 'word[-2:]': 'eu', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'rejects', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'rejects', 'word[-3:]': 'cts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'eu', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'rejects', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'call', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'call', 'word[-3:]': 'all', 'word[-2:]': 'll', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'call', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'boycott', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'boycott', 'word[-3:]': 'ott', 'word[-2:]': 'tt', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'boycott', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'peter', 'word[-3:]': 'ter', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'blackburn', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'blackburn', 'word[-3:]': 'urn', 'word[-2:]': 'rn', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'peter', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'brussels', 'word[-3:]': 'els', 'word[-2:]': 'ls', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '1996-08-22', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '1996-08-22', 'word[-3:]': '-22', 'word[-2:]': '22', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'brussels', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'the', 'word[-3:]': 'the', 'word[-2:]': 'he', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'european', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'european', 'word[-3:]': 'ean', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'the', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'commission', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'commission', 'word[-3:]': 'ion', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'european', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'said', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'said', 'word[-3:]': 'aid', 'word[-2:]': 'id', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'commission', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'on', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'on', 'word[-3:]': 'on', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'said', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'thursday', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'thursday', 'word[-3:]': 'day', 'word[-2:]': 'ay', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'on', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'it', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'it', 'word[-3:]': 'it', 'word[-2:]': 'it', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'thursday', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disagreed', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disagreed', 'word[-3:]': 'eed', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'it', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'with', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'with', 'word[-3:]': 'ith', 'word[-2:]': 'th', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disagreed', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'with', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'advice', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'advice', 'word[-3:]': 'ice', 'word[-2:]': 'ce', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'advice', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'consumers', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'consumers', 'word[-3:]': 'ers', 'word[-2:]': 'rs', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'consumers', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'shun', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'shun', 'word[-3:]': 'hun', 'word[-2:]': 'un', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'shun', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'until', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'until', 'word[-3:]': 'til', 'word[-2:]': 'il', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'scientists', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'scientists', 'word[-3:]': 'sts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'until', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'determine', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'determine', 'word[-3:]': 'ine', 'word[-2:]': 'ne', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'scientists', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'whether', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'whether', 'word[-3:]': 'her', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'determine', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'mad', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'mad', 'word[-3:]': 'mad', 'word[-2:]': 'ad', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'whether', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'cow', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'cow', 'word[-3:]': 'cow', 'word[-2:]': 'ow', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'mad', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disease', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disease', 'word[-3:]': 'ase', 'word[-2:]': 'se', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'cow', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'can', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'can', 'word[-3:]': 'can', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disease', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'be', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'be', 'word[-3:]': 'be', 'word[-2:]': 'be', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'can', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'transmitted', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'transmitted', 'word[-3:]': 'ted', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'be', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'transmitted', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'sheep', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'sheep', 'word[-3:]': 'eep', 'word[-2:]': 'ep', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'sheep', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2kJfNAS1N2",
        "colab_type": "code",
        "outputId": "e80bccf6-5359-433a-fdd2-2c7982c4c5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxUCHw5FXGt",
        "colab_type": "text"
      },
      "source": [
        "Because tag O (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag O when we evaluate classification metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGFs5K6EVC0R",
        "colab_type": "text"
      },
      "source": [
        "B: begining of ... \n",
        "I: identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnMwxl4UVPN",
        "colab_type": "code",
        "outputId": "f8a9708f-c031-460a-bc0d-28d4a2d91ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ner_train_set.remove('O')\n",
        "classes = ner_train_set\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-PER', 'I-MISC', 'I-ORG', 'I-LOC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9jdSefS4id",
        "colab_type": "code",
        "outputId": "1eb97cd6-8a0c-467c-8723-23d8837ef49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(features_val)\n",
        "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.93      0.80      0.86       875\n",
            "      I-MISC       0.83      0.63      0.72       187\n",
            "       I-ORG       0.85      0.58      0.69       285\n",
            "       I-LOC       0.89      0.85      0.87       419\n",
            "\n",
            "   micro avg       0.90      0.76      0.82      1766\n",
            "   macro avg       0.88      0.72      0.78      1766\n",
            "weighted avg       0.90      0.76      0.82      1766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3oWq_PnK8wk",
        "colab_type": "text"
      },
      "source": [
        "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40His-7UKyvp",
        "colab_type": "code",
        "outputId": "dc45097f-0599-4311-bb27-a9568bade137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "I-PER  -> I-PER   3.403927\n",
            "I-ORG  -> I-ORG   3.384090\n",
            "I-MISC -> I-MISC  2.828140\n",
            "I-LOC  -> I-LOC   2.064296\n",
            "O      -> O       0.776679\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-PER  -> I-LOC   -2.677780\n",
            "I-PER  -> I-ORG   -2.689004\n",
            "I-LOC  -> I-PER   -3.410616\n",
            "I-ORG  -> I-LOC   -3.463856\n",
            "I-ORG  -> I-PER   -3.736825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbtE0AYpvtX",
        "colab_type": "text"
      },
      "source": [
        "## Bi-LSTM CRF model\n",
        "\n",
        "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCqGvJchOdR",
        "colab_type": "text"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWAK0NV3INF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert each unique word to the index\n",
        "word_to_ix = {}\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in ner_train_split + ner_val_split:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNgyvEADwYZt",
        "colab_type": "code",
        "outputId": "59d9145b-0d13-4292-a881-1793b15e2944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(len(word_list))\n",
        "for i in range(5):\n",
        "    print(word_list[i])\n",
        "    print(list(word_to_ix.values())[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "-docstart-\n",
            "0\n",
            "eu\n",
            "1\n",
            "rejects\n",
            "2\n",
            "german\n",
            "3\n",
            "call\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tndg_-ttwa6N",
        "colab_type": "code",
        "outputId": "e3f66282-9c04-4a74-cdb4-2fec78fab4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrekRAbtxL2",
        "colab_type": "code",
        "outputId": "3055f1ee-25aa-43a6-dfdc-3a8a50c4ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(word_list), len(tag_to_ix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEswz2QjhXBM",
        "colab_type": "text"
      },
      "source": [
        "#### Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oz6KVyjsxM9",
        "colab_type": "code",
        "outputId": "79462838-aa13-416d-ee8e-9efa37c12ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "# change a latest embedding!\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-50\") \n",
        "# word dimension\n",
        "EMBEDDING_DIM = 50\n",
        "embedding_matrix = []\n",
        "num_except = 0\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        num_except += 1\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlchZJO8hdXa",
        "colab_type": "text"
      },
      "source": [
        "#### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRs6mouFwEx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# use the index to represent each word in each sentence\n",
        "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
        "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
        "\n",
        "train_input_feature = get_feature(0, 2999)\n",
        "\n",
        "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
        "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
        "val_input_feature = get_feature(3000, 3699)\n",
        "\n",
        "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
        "test_input_feature = get_feature(3700, 7383)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEscWBrhjgb",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        \n",
        "\n",
        "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "        # Use nn.Embedding\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_3 = nn.LSTM(96, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "      \n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    # CRF: use the transition matrix to train our model\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    \n",
        "\n",
        "    def cal_self_attention(self, hidden, method):\n",
        "        # 1st type of calculation of the attention: Dot Product\n",
        "        if method == 'Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
        "          \n",
        "            attn_weights = F.softmax(a, dim = -1)\n",
        "           \n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "           \n",
        "\n",
        "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
        "        elif method == 'Scale Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
        "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "\n",
        "    def _get_lstm_features(self, sentence, features):\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # 96\n",
        "        features = features.view(len(features),1,-1)\n",
        "        # concat the word embedding with the word features\n",
        "        word_concat = torch.cat((embeds, features), dim = 2) # [1,1,96]\n",
        "\n",
        "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden) \n",
        "        \n",
        "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
        "        \n",
        "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden) \n",
        "        \n",
        "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')\n",
        "\n",
        "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
        "\n",
        "        \n",
        "        # change from 3 dimensions to 2 dimensions\n",
        "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    ''' Calculate the score for the viterbi decoding'''\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, features, tags):\n",
        "        feats = self._get_lstm_features(sentence, features)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    # sentence is a index expression of the words in the sentence \n",
        "    def forward(self, sentence, features):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, features)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNHEV1kiDKt",
        "colab_type": "text"
      },
      "source": [
        "#### Function for accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Moqs-zwboIn",
        "colab_type": "text"
      },
      "source": [
        "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def cal_acc(model, input_index, input_feature, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      ground_truth.extend(output_index[i])\n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      accuracy = accuracy_score(predicted, ground_truth)\n",
        "      \n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82UaXEOhoQQ",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UiokVOjPUn",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru",
        "colab_type": "code",
        "outputId": "fc6b4b3b-1305-4a24-d054-7cd9b1b024cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 370s\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "for epoch in range(30): \n",
        "    epoch_list.append(epoch) \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "  \n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        # Use the forward pass\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    val_loss = 0\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
        "        val_loss+=loss.item()\n",
        "        \n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 11520.03, train acc: 0.9395, val loss: 1512.88, val acc: 0.9279, time: 250.96s\n",
            "Epoch:2, Training loss: 4827.87, train acc: 0.9585, val loss: 1576.98, val acc: 0.9120, time: 256.72s\n",
            "Epoch:3, Training loss: 2852.15, train acc: 0.9683, val loss: 1576.42, val acc: 0.9183, time: 256.84s\n",
            "Epoch:4, Training loss: 1824.98, train acc: 0.9818, val loss: 1509.56, val acc: 0.9420, time: 260.05s\n",
            "Epoch:5, Training loss: 1243.68, train acc: 0.9858, val loss: 1274.54, val acc: 0.9509, time: 256.26s\n",
            "Epoch:6, Training loss: 885.28, train acc: 0.9907, val loss: 1346.10, val acc: 0.9547, time: 255.24s\n",
            "Epoch:7, Training loss: 787.08, train acc: 0.9908, val loss: 1407.48, val acc: 0.9513, time: 252.67s\n",
            "Epoch:8, Training loss: 592.66, train acc: 0.9884, val loss: 1605.40, val acc: 0.9378, time: 248.94s\n",
            "Epoch:9, Training loss: 523.32, train acc: 0.9913, val loss: 1510.82, val acc: 0.9525, time: 250.32s\n",
            "Epoch:10, Training loss: 433.06, train acc: 0.9938, val loss: 1573.19, val acc: 0.9543, time: 251.81s\n",
            "Epoch:11, Training loss: 417.98, train acc: 0.9945, val loss: 1855.56, val acc: 0.9457, time: 253.01s\n",
            "Epoch:12, Training loss: 379.04, train acc: 0.9965, val loss: 1617.17, val acc: 0.9580, time: 251.71s\n",
            "Epoch:13, Training loss: 417.49, train acc: 0.9978, val loss: 1534.78, val acc: 0.9582, time: 255.60s\n",
            "Epoch:14, Training loss: 372.77, train acc: 0.9972, val loss: 1520.01, val acc: 0.9600, time: 253.54s\n",
            "Epoch:15, Training loss: 363.46, train acc: 0.9944, val loss: 1920.80, val acc: 0.9464, time: 256.18s\n",
            "Epoch:16, Training loss: 327.08, train acc: 0.9970, val loss: 1639.76, val acc: 0.9557, time: 245.97s\n",
            "Epoch:17, Training loss: 316.05, train acc: 0.9971, val loss: 1690.90, val acc: 0.9543, time: 243.25s\n",
            "Epoch:18, Training loss: 315.10, train acc: 0.9968, val loss: 1599.93, val acc: 0.9590, time: 243.76s\n",
            "Epoch:19, Training loss: 317.92, train acc: 0.9971, val loss: 1474.87, val acc: 0.9615, time: 245.26s\n",
            "Epoch:20, Training loss: 275.03, train acc: 0.9974, val loss: 1494.59, val acc: 0.9588, time: 246.09s\n",
            "Epoch:21, Training loss: 291.75, train acc: 0.9980, val loss: 1520.02, val acc: 0.9566, time: 253.20s\n",
            "Epoch:22, Training loss: 262.85, train acc: 0.9978, val loss: 1572.89, val acc: 0.9559, time: 250.40s\n",
            "Epoch:23, Training loss: 291.64, train acc: 0.9966, val loss: 1624.18, val acc: 0.9606, time: 242.58s\n",
            "Epoch:24, Training loss: 301.23, train acc: 0.9984, val loss: 1581.65, val acc: 0.9569, time: 237.11s\n",
            "Epoch:25, Training loss: 255.66, train acc: 0.9961, val loss: 1607.35, val acc: 0.9546, time: 238.16s\n",
            "Epoch:26, Training loss: 297.80, train acc: 0.9978, val loss: 1573.99, val acc: 0.9604, time: 244.19s\n",
            "Epoch:27, Training loss: 251.53, train acc: 0.9976, val loss: 1726.52, val acc: 0.9525, time: 240.54s\n",
            "Epoch:28, Training loss: 203.82, train acc: 0.9979, val loss: 1797.83, val acc: 0.9550, time: 238.31s\n",
            "Epoch:29, Training loss: 260.79, train acc: 0.9976, val loss: 1656.88, val acc: 0.9576, time: 235.68s\n",
            "Epoch:30, Training loss: 231.88, train acc: 0.9977, val loss: 1591.19, val acc: 0.9553, time: 233.74s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DpPFktYijJ5",
        "colab_type": "code",
        "outputId": "51ea852b-1953-4dcf-808d-8c94b9e9be1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "torch.save(model, 'Bilstm_crf_model13_2.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMDDzcXXzgd",
        "colab_type": "code",
        "outputId": "6d3df3e9-62a8-4b54-9d6d-e57b6979fcc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7ANbv_jSzI",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAnJVsyPq5kR",
        "colab_type": "code",
        "outputId": "e930fa61-7f70-49ac-c73c-e5da01af88b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.8662    0.9117    0.8884       419\n",
            "      I-MISC     0.6864    0.8075    0.7420       187\n",
            "       I-ORG     0.8117    0.6807    0.7405       285\n",
            "       I-PER     0.9602    0.8823    0.9196       875\n",
            "           O     0.9803    0.9908    0.9856      5790\n",
            "\n",
            "    accuracy                         0.9576      7556\n",
            "   macro avg     0.8610    0.8546    0.8552      7556\n",
            "weighted avg     0.9580    0.9576    0.9573      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Vihry_Y3lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def leaderboard(model, input_index, input_feature):\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      \n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y0fX78Ysm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "test_pred_decode = decode_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xqOcTPz3iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "co1 = []\n",
        "co2 = []\n",
        "for i in range(len(test_pred_decode)):\n",
        "    co1.append(i)\n",
        "    co2.append(test_pred_decode[i])\n",
        "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
        "leaderboard.to_csv(\"leaderboard13_2.csv\", index=False, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXGK44ibbYBp",
        "colab_type": "code",
        "outputId": "488b7b07-c44b-4c98-ef51-0f3137adac4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "da=pd.read_csv(\"leaderboard13_2.csv\")\n",
        "da.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Predicted\n",
              "0   0         O\n",
              "1   1         O\n",
              "2   2         O\n",
              "3   3     I-LOC\n",
              "4   4         O\n",
              "5   5     I-PER\n",
              "6   6         O\n",
              "7   7         O\n",
              "8   8     I-LOC\n",
              "9   9         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVVLm4esLVJd",
        "colab_type": "code",
        "outputId": "d431b7f8-2bff-4ce2-d2bb-660408046fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(13972, 50)\n",
              "  (lstm_1): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_2): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_3): LSTM(96, 50, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}