{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model3_feature3_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKhhaHUvYgoa",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition + 2 bi-lstm + 2 self-attention + scaled + 3 features + lr = 0.0001 + hidden dim = 100\n",
        "\n",
        "\n",
        "val_acc: 0.9578\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY4scQ1RUve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwUrZvQakO2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "id = '1m2je3m7MiyHJynZv8bUtmUYWUJy7vCTl'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1Cm_SL9JHgJ6_1qh6FeuOpUFi_-lbtQw3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "id = '18Av4rRPwnlCdF2V4wXKioYlPNy7DgzFJ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtRDEwSCMcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the files of the PoS tags for the dataset\n",
        "# PoS tags are used as one of the features \n",
        "\n",
        "id = '1UmNHdUZxjfcuIzCcAKuBvfBXdSWFv47i'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.txt')\n",
        "\n",
        "id = '11bZIh5V9m2nZJ5s5xQ_gxHEHkAEhV8eQ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('validation.txt')\n",
        "\n",
        "id = '1V-LQuJWT62aCytYuhZuaxvICsqiF1rdK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK73yG9zfHbt",
        "colab_type": "code",
        "outputId": "867c2a27-a62f-47c8-e53c-ea6843ff6f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# create a list of Sentence and a list of NER\n",
        "\n",
        "sentences_train = df_train['Sentence'].tolist()\n",
        "ner_train = df_train['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_train_split = []\n",
        "ner_train_split = []\n",
        "for each_sentence in sentences_train:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_train_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_train:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_train_split.append(each_ner)\n",
        "print(sentence_train_split[1][0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNInRtB7PDia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_val = df_val['Sentence'].tolist()\n",
        "ner_val = df_val['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_val_split = []\n",
        "ner_val_split = []\n",
        "for each_sentence in sentences_val:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_val_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_val:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_val_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjohNx5IvRVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence\n",
        "\n",
        "sentences_test = df_test['Sentence'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_test_split = []\n",
        "\n",
        "for each_sentence in sentences_test:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_test_split.append(each_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S049P4HVDJTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "    pos_data = []\n",
        "    pos = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':   \n",
        "            pos_data.append(pos)\n",
        "            pos = []\n",
        "        else:    \n",
        "            pos.append(i.replace('\\n','').split(' ')[1])\n",
        "    return pos_data[:n_sample]\n",
        "\n",
        "pos_train = read_data(\"train.txt\", 3000)\n",
        "pos_validation = read_data(\"validation.txt\",700)\n",
        "pos_test = read_data(\"test.txt\",3684)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5gUSbrHQ6J2",
        "colab_type": "text"
      },
      "source": [
        "# Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH_xBcfvfQp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirHmtHeIcGp",
        "colab_type": "code",
        "outputId": "baa226a1-4223-4330-bcca-9829364b9450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "total_words = []\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        total_words.append(word)\n",
        "\n",
        "print(len(total_words))\n",
        "print(len(set(total_words)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93794\n",
            "13972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ezZdNCrEDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pos_list = []\n",
        "\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    pos_line = []\n",
        "    for each_pos in line:\n",
        "        pos_line.append(each_pos)\n",
        "    total_pos_list.append(pos_line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQNSEP8HXtS",
        "colab_type": "code",
        "outputId": "7a62eff6-040e-4ee8-8127-f9cb8dc84c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pos_to_ix = {}\n",
        "pos_list = []\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    for pos in line:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "pos_list = sorted(list(pos_to_ix.keys()))\n",
        "\n",
        "pos_list_length = len(pos_list)\n",
        "print(pos_list_length)\n",
        "print(pos_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My7OPDfWVvnk",
        "colab_type": "code",
        "outputId": "f765592c-56a2-4394-a8ab-d19e2dc456a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# key is the pos tag, value is the one hot expression\n",
        "onehotpos = {}\n",
        "\n",
        "for i in range(pos_list_length):   \n",
        "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
        "    onehotpos[pos_list[i]] = list(onehot[0])\n",
        "\n",
        "print(onehotpos)\n",
        "\n",
        "def get_onehotpos(pos_sentence):\n",
        "    pos_list = []\n",
        "    for each_pos in pos_sentence:\n",
        "        onehot_pos = onehotpos[each_pos]\n",
        "        pos_list.append(onehot_pos)\n",
        "    return pos_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14mferpb4dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
        "sentence_to_pos = {}\n",
        "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
        "for i in range(total_length):\n",
        "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sf0ks6vBHqI",
        "colab_type": "code",
        "outputId": "667fde3a-2f20-480a-db30-780ef2ec36bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(sentence_to_pos[i])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1NsLQ3qlBP",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XY3R9ePJOY",
        "colab_type": "code",
        "outputId": "d5e74fe3-ba1f-4f16-c373-7ef77a14b2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "DF = {}\n",
        "\n",
        "for each_sentence in total_sentences:\n",
        "    for term in np.unique(each_sentence):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "\n",
        "print(len(DF))\n",
        "\n",
        "\n",
        "tf_idf = {}\n",
        "N = total_length\n",
        "print(N)\n",
        "\n",
        "for i in range(N):\n",
        "    counter = Counter(total_sentences[i])\n",
        "    total_num_words = len(total_sentences[i])   \n",
        "    # the tfidf of all words in a sentence\n",
        "    each_sentence_tfidf = []\n",
        "    \n",
        "    for term in total_sentences[i]:\n",
        "        tf = counter[term]/total_num_words\n",
        "        df = DF[term]\n",
        "        idf = math.log(N/(df+1))+1\n",
        "        each_sentence_tfidf.append(tf*idf)\n",
        "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
        "    tf_idf[i] = each_sentence_tfidf\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "7384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0WnqcLhCxNh",
        "colab_type": "code",
        "outputId": "428e9f36-681c-47d2-dabe-7238106bb90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(tf_idf[i])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.7867733572317377]\n",
            "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
            "[3.8549230994232344, 3.711082063197344]\n",
            "[3.236541785848771, 2.568193075858512]\n",
            "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFq1dlZnO9mi",
        "colab_type": "code",
        "outputId": "4bec5fcd-3831-4be9-8c83-c55638df2344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1\n",
            "9 9\n",
            "2 2\n",
            "2 2\n",
            "30 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3DcyEtJ93fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        sentence_feature_list = []\n",
        "        for j in range(len(sentence_to_pos[i])): \n",
        "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
        "        \n",
        "        feature_list.append(sentence_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0Tv48EMi__",
        "colab_type": "code",
        "outputId": "df2e14c3-d46a-458b-eb16-a6e2c9e4bd89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\n",
        "print(get_feature(0,5))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7og4EnAq8aG",
        "colab_type": "text"
      },
      "source": [
        "## Distribution Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-vnejvEDZ7",
        "colab_type": "code",
        "outputId": "ebfcc4da-d5d1-4929-b5c8-5dde705de5a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentence_lengths = []\n",
        "for each_sentence in total_sentences:\n",
        "    length = len(each_sentence)\n",
        "    sentence_lengths.append(length)\n",
        "\n",
        "total_sentence_num = len(sentence_lengths)\n",
        "largest_length = max(sentence_lengths)\n",
        "mean_length = np.mean(sentence_lengths)\n",
        "counts_length = np.bincount(sentence_lengths)\n",
        "counts_length = np.argmax(counts_length)\n",
        "length_less_than_counts = 0\n",
        "length_less_than_mean = 0 \n",
        "length_less_than_15 = 0\n",
        "length_less_than_20 = 0\n",
        "length_less_than_25 = 0\n",
        "length_less_than_30 = 0\n",
        "\n",
        "for length in sentence_lengths:\n",
        "  if length < counts_length:\n",
        "    length_less_than_counts += 1\n",
        "  if length < mean_length:\n",
        "    length_less_than_mean += 1\n",
        "  if length < 15:\n",
        "    length_less_than_15 += 1\n",
        "  if length < 20:\n",
        "    length_less_than_20 += 1\n",
        "  if length < 25:\n",
        "    length_less_than_25 += 1\n",
        "  if length < 30:\n",
        "    length_less_than_30 += 1\n",
        "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
        "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
        "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
        "print(y_rate)\n",
        "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences: 7384 Largest length of the sentence: 124\n",
            "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFsK7PUsNox",
        "colab_type": "text"
      },
      "source": [
        "There are 5 kinds of tag in total.\n",
        "\n",
        "'I-ORG': Organization\n",
        "\n",
        "'O': Other\n",
        "\n",
        "'I-LOC': Location \n",
        "\n",
        "'I-PER': Person \n",
        "\n",
        "'I-MISC': Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-UMIHEKrgCw",
        "colab_type": "code",
        "outputId": "12140b28-740b-42b3-909e-62e3ffc18fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "ner_train_list = []\n",
        "for each_ner in ner_train_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_train_list.append(each_tag)\n",
        "ner_train_set = list(set(ner_train_list))\n",
        "print(len(ner_train_list))\n",
        "print(len(ner_train_set))\n",
        "print(ner_train_set)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39572\n",
            "5\n",
            "['I-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chjiqNYkzNK",
        "colab_type": "code",
        "outputId": "0a5d79b0-aaa2-4210-abfe-7f3b3731dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "ner_val_list = []\n",
        "for each_ner in ner_val_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_val_list.append(each_tag)\n",
        "ner_val_set = list(set(ner_val_list))\n",
        "print(len(ner_val_list))\n",
        "print(len(ner_val_set))\n",
        "print(ner_val_set)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556\n",
            "5\n",
            "['I-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDuagDgs1Yj4",
        "colab_type": "code",
        "outputId": "dfb2963f-faa6-469b-bd51-9c10c0a49e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_train_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   1526\n",
            "O:       32137\n",
            "I-LOC:   1994\n",
            "I-PER:   2840\n",
            "I-MISC:  1075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_NXJRv7k__M",
        "colab_type": "code",
        "outputId": "8316fc30-b582-49a5-b505-77e4ac632395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_val_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   285\n",
            "O:       5790\n",
            "I-LOC:   419\n",
            "I-PER:   875\n",
            "I-MISC:  187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9s9J-lDKUC",
        "colab_type": "text"
      },
      "source": [
        "In the data, you can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfakfv0CRwAB",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "There are too many NaN values in ‘Sentence #” column, fill NaN by preceding values.\n",
        "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcu5O3OlEdPA",
        "colab_type": "text"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsvF8uXSgy5",
        "colab_type": "code",
        "outputId": "a3b1aa39-60d6-432c-b11f-e79bc839aa2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4F991p-IqNS",
        "colab_type": "text"
      },
      "source": [
        "##Conditional random fields (CRF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Xcf07iR79l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPELELtSmYo",
        "colab_type": "code",
        "outputId": "406566be-c6cf-44e6-c680-39410bec362b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_train = []\n",
        "for line in range(len(sentence_train_split)):\n",
        "    combine_sentence = []\n",
        "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
        "        combine_sentence.append((each_word, each_tag))\n",
        "    zip_sentences_train.append(combine_sentence)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_train[i])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
            "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
            "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJIH2emlP1y",
        "colab_type": "code",
        "outputId": "446199af-6ea6-4d7e-90ac-af64007cbead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_val = []\n",
        "for line in range(len(sentence_val_split)):\n",
        "    combine_sentence_val = []\n",
        "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
        "        combine_sentence_val.append((each_word, each_tag))\n",
        "    zip_sentences_val.append(combine_sentence_val)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_val[i])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('cricket', 'O'), ('-', 'O'), ('leicestershire', 'I-ORG'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('top', 'O'), ('after', 'O'), ('innings', 'O'), ('victory', 'O'), ('.', 'O')]\n",
            "[('london', 'I-LOC'), ('1996-08-30', 'O')]\n",
            "[('west', 'I-MISC'), ('indian', 'I-MISC'), ('all-rounder', 'O'), ('phil', 'I-PER'), ('simmons', 'I-PER'), ('took', 'O'), ('four', 'O'), ('for', 'O'), ('38', 'O'), ('on', 'O'), ('friday', 'O'), ('as', 'O'), ('leicestershire', 'I-ORG'), ('beat', 'O'), ('somerset', 'I-ORG'), ('by', 'O'), ('an', 'O'), ('innings', 'O'), ('and', 'O'), ('39', 'O'), ('runs', 'O'), ('in', 'O'), ('two', 'O'), ('days', 'O'), ('to', 'O'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('the', 'O'), ('head', 'O'), ('of', 'O'), ('the', 'O'), ('county', 'O'), ('championship', 'O'), ('.', 'O')]\n",
            "[('their', 'O'), ('stay', 'O'), ('on', 'O'), ('top', 'O'), (',', 'O'), ('though', 'O'), (',', 'O'), ('may', 'O'), ('be', 'O'), ('short-lived', 'O'), ('as', 'O'), ('title', 'O'), ('rivals', 'O'), ('essex', 'I-ORG'), (',', 'O'), ('derbyshire', 'I-ORG'), ('and', 'O'), ('surrey', 'I-ORG'), ('all', 'O'), ('closed', 'O'), ('in', 'O'), ('on', 'O'), ('victory', 'O'), ('while', 'O'), ('kent', 'I-ORG'), ('made', 'O'), ('up', 'O'), ('for', 'O'), ('lost', 'O'), ('time', 'O'), ('in', 'O'), ('their', 'O'), ('rain-affected', 'O'), ('match', 'O'), ('against', 'O'), ('nottinghamshire', 'I-ORG'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alfVxIWIFEth",
        "colab_type": "text"
      },
      "source": [
        "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbaee897Sqoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    # postag = sent[i][1]\n",
        "    # a few features: upper? lower? title? \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:], # last three letters of the word\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(), \n",
        "        'word.istitle()': word.istitle(), # is it a title?\n",
        "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
        "       \n",
        "    }\n",
        "    # features of the previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        # postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "          \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    # features of the next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "       \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            \n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9Xu722SzYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features_train = [sent2features(s) for s in zip_sentences_train]\n",
        "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
        "\n",
        "features_val = [sent2features(s) for s in zip_sentences_val]\n",
        "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3g66D_kMlCp",
        "colab_type": "code",
        "outputId": "510ee918-d937-47ea-ae8d-8614df6ca9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for i in range(5):\n",
        "     print(features_train[i])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'bias': 1.0, 'word.lower()': '-docstart-', 'word[-3:]': 'rt-', 'word[-2:]': 't-', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'eu', 'word[-3:]': 'eu', 'word[-2:]': 'eu', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'rejects', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'rejects', 'word[-3:]': 'cts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'eu', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'rejects', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'call', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'call', 'word[-3:]': 'all', 'word[-2:]': 'll', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'call', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'boycott', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'boycott', 'word[-3:]': 'ott', 'word[-2:]': 'tt', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'boycott', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'peter', 'word[-3:]': 'ter', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'blackburn', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'blackburn', 'word[-3:]': 'urn', 'word[-2:]': 'rn', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'peter', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'brussels', 'word[-3:]': 'els', 'word[-2:]': 'ls', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '1996-08-22', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '1996-08-22', 'word[-3:]': '-22', 'word[-2:]': '22', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'brussels', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'the', 'word[-3:]': 'the', 'word[-2:]': 'he', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'european', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'european', 'word[-3:]': 'ean', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'the', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'commission', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'commission', 'word[-3:]': 'ion', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'european', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'said', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'said', 'word[-3:]': 'aid', 'word[-2:]': 'id', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'commission', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'on', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'on', 'word[-3:]': 'on', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'said', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'thursday', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'thursday', 'word[-3:]': 'day', 'word[-2:]': 'ay', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'on', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'it', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'it', 'word[-3:]': 'it', 'word[-2:]': 'it', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'thursday', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disagreed', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disagreed', 'word[-3:]': 'eed', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'it', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'with', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'with', 'word[-3:]': 'ith', 'word[-2:]': 'th', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disagreed', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'with', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'advice', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'advice', 'word[-3:]': 'ice', 'word[-2:]': 'ce', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'advice', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'consumers', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'consumers', 'word[-3:]': 'ers', 'word[-2:]': 'rs', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'consumers', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'shun', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'shun', 'word[-3:]': 'hun', 'word[-2:]': 'un', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'shun', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'until', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'until', 'word[-3:]': 'til', 'word[-2:]': 'il', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'scientists', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'scientists', 'word[-3:]': 'sts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'until', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'determine', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'determine', 'word[-3:]': 'ine', 'word[-2:]': 'ne', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'scientists', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'whether', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'whether', 'word[-3:]': 'her', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'determine', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'mad', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'mad', 'word[-3:]': 'mad', 'word[-2:]': 'ad', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'whether', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'cow', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'cow', 'word[-3:]': 'cow', 'word[-2:]': 'ow', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'mad', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disease', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disease', 'word[-3:]': 'ase', 'word[-2:]': 'se', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'cow', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'can', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'can', 'word[-3:]': 'can', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disease', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'be', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'be', 'word[-3:]': 'be', 'word[-2:]': 'be', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'can', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'transmitted', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'transmitted', 'word[-3:]': 'ted', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'be', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'transmitted', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'sheep', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'sheep', 'word[-3:]': 'eep', 'word[-2:]': 'ep', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'sheep', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2kJfNAS1N2",
        "colab_type": "code",
        "outputId": "6701d10f-68a0-404a-8820-3612a6c79c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(features_train, labels_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxUCHw5FXGt",
        "colab_type": "text"
      },
      "source": [
        "Because tag “O” (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag “O” when we evaluate classification metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGFs5K6EVC0R",
        "colab_type": "text"
      },
      "source": [
        "B: begining of ... \n",
        "I: identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnMwxl4UVPN",
        "colab_type": "code",
        "outputId": "9b19dbed-9f15-4b57-bd30-4b2aa76b3a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ner_train_set.remove('O')\n",
        "classes = ner_train_set\n",
        "print(classes)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-MISC', 'I-PER', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9jdSefS4id",
        "colab_type": "code",
        "outputId": "bc016a47-0fb6-410a-e4df-3fbcb71504d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(features_val)\n",
        "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      I-MISC       0.83      0.63      0.72       187\n",
            "       I-PER       0.93      0.80      0.86       875\n",
            "       I-LOC       0.89      0.85      0.87       419\n",
            "       I-ORG       0.85      0.58      0.69       285\n",
            "\n",
            "   micro avg       0.90      0.76      0.82      1766\n",
            "   macro avg       0.88      0.72      0.78      1766\n",
            "weighted avg       0.90      0.76      0.82      1766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3oWq_PnK8wk",
        "colab_type": "text"
      },
      "source": [
        "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40His-7UKyvp",
        "colab_type": "code",
        "outputId": "5e0f3e1a-576b-4b2a-97aa-5580947d3e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "I-PER  -> I-PER   3.403927\n",
            "I-ORG  -> I-ORG   3.384090\n",
            "I-MISC -> I-MISC  2.828140\n",
            "I-LOC  -> I-LOC   2.064296\n",
            "O      -> O       0.776679\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-PER  -> I-LOC   -2.677780\n",
            "I-PER  -> I-ORG   -2.689004\n",
            "I-LOC  -> I-PER   -3.410616\n",
            "I-ORG  -> I-LOC   -3.463856\n",
            "I-ORG  -> I-PER   -3.736825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbtE0AYpvtX",
        "colab_type": "text"
      },
      "source": [
        "## Bi-LSTM CRF model\n",
        "\n",
        "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCqGvJchOdR",
        "colab_type": "text"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWAK0NV3INF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert each unique word to the index\n",
        "word_to_ix = {}\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in ner_train_split + ner_val_split:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNgyvEADwYZt",
        "colab_type": "code",
        "outputId": "6bb396df-d66e-4112-9007-4f7590bee19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "print(len(word_list))\n",
        "for i in range(5):\n",
        "    print(word_list[i])\n",
        "    print(list(word_to_ix.values())[i])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "-docstart-\n",
            "0\n",
            "eu\n",
            "1\n",
            "rejects\n",
            "2\n",
            "german\n",
            "3\n",
            "call\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tndg_-ttwa6N",
        "colab_type": "code",
        "outputId": "b9f9a9bc-96d6-40ee-ffc5-cecd2e92a9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(tag_to_ix)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrekRAbtxL2",
        "colab_type": "code",
        "outputId": "ce1a0bfe-9611-493c-b009-b7b350cd8991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(word_list), len(tag_to_ix))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEswz2QjhXBM",
        "colab_type": "text"
      },
      "source": [
        "#### Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oz6KVyjsxM9",
        "colab_type": "code",
        "outputId": "b7d1e65b-06e5-42a1-9baa-822f0ac2c4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "# change a latest embedding!\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-50\") \n",
        "# word dimension\n",
        "EMBEDDING_DIM = 50\n",
        "embedding_matrix = []\n",
        "num_except = 0\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        num_except += 1\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlchZJO8hdXa",
        "colab_type": "text"
      },
      "source": [
        "#### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRs6mouFwEx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# use the index to represent each word in each sentence\n",
        "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
        "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
        "\n",
        "train_input_feature = get_feature(0, 2999)\n",
        "\n",
        "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
        "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
        "val_input_feature = get_feature(3000, 3699)\n",
        "\n",
        "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
        "test_input_feature = get_feature(3700, 7383)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEscWBrhjgb",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        \n",
        "\n",
        "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "        # Use nn.Embedding\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_3 = nn.LSTM(96, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "      \n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    # CRF: use the transition matrix to train our model\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    \n",
        "\n",
        "    def cal_self_attention(self, hidden, method):\n",
        "        # 1st type of calculation of the attention: Dot Product\n",
        "        if method == 'Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
        "          \n",
        "            attn_weights = F.softmax(a, dim = -1)\n",
        "           \n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "           \n",
        "\n",
        "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
        "        elif method == 'Scale Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
        "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "\n",
        "    def _get_lstm_features(self, sentence, features):\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # 96\n",
        "        features = features.view(len(features),1,-1)\n",
        "        # concat the word embedding with the word features\n",
        "        word_concat = torch.cat((embeds, features), dim = 2) # [1,1,96]\n",
        "\n",
        "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden) \n",
        "        \n",
        "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
        "        \n",
        "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden) \n",
        "        \n",
        "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')\n",
        "\n",
        "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
        "\n",
        "        \n",
        "        # change from 3 dimensions to 2 dimensions\n",
        "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    ''' Calculate the score for the viterbi decoding'''\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, features, tags):\n",
        "        feats = self._get_lstm_features(sentence, features)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    # sentence is a index expression of the words in the sentence \n",
        "    def forward(self, sentence, features):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, features)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNHEV1kiDKt",
        "colab_type": "text"
      },
      "source": [
        "#### Function for accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Moqs-zwboIn",
        "colab_type": "text"
      },
      "source": [
        "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def cal_acc(model, input_index, input_feature, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      ground_truth.extend(output_index[i])\n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      accuracy = accuracy_score(predicted, ground_truth)\n",
        "      \n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82UaXEOhoQQ",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UiokVOjPUn",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru",
        "colab_type": "code",
        "outputId": "ab3d1c94-24d3-4604-a86d-e1c2427b4afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 370s\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "for epoch in range(20): \n",
        "    epoch_list.append(epoch) \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "  \n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        # Use the forward pass\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    val_loss = 0\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
        "        val_loss+=loss.item()\n",
        "        \n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 21192.60, train acc: 0.9014, val loss: 2390.01, val acc: 0.8957, time: 434.52s\n",
            "Epoch:2, Training loss: 8492.36, train acc: 0.9383, val loss: 1557.33, val acc: 0.9260, time: 440.14s\n",
            "Epoch:3, Training loss: 5963.26, train acc: 0.9542, val loss: 1413.21, val acc: 0.9314, time: 440.76s\n",
            "Epoch:4, Training loss: 4782.88, train acc: 0.9635, val loss: 1345.43, val acc: 0.9399, time: 437.27s\n",
            "Epoch:5, Training loss: 3954.46, train acc: 0.9678, val loss: 1273.59, val acc: 0.9420, time: 436.70s\n",
            "Epoch:6, Training loss: 3394.96, train acc: 0.9704, val loss: 1321.51, val acc: 0.9402, time: 436.35s\n",
            "Epoch:7, Training loss: 2898.80, train acc: 0.9758, val loss: 1257.94, val acc: 0.9497, time: 434.77s\n",
            "Epoch:8, Training loss: 2521.63, train acc: 0.9775, val loss: 1289.05, val acc: 0.9467, time: 439.38s\n",
            "Epoch:9, Training loss: 2198.47, train acc: 0.9813, val loss: 1209.99, val acc: 0.9512, time: 438.72s\n",
            "Epoch:10, Training loss: 1881.99, train acc: 0.9828, val loss: 1275.51, val acc: 0.9464, time: 440.35s\n",
            "Epoch:11, Training loss: 1625.45, train acc: 0.9860, val loss: 1255.04, val acc: 0.9530, time: 448.33s\n",
            "Epoch:12, Training loss: 1380.65, train acc: 0.9864, val loss: 1287.97, val acc: 0.9546, time: 449.11s\n",
            "Epoch:13, Training loss: 1188.78, train acc: 0.9891, val loss: 1277.56, val acc: 0.9531, time: 439.35s\n",
            "Epoch:14, Training loss: 1022.31, train acc: 0.9905, val loss: 1377.08, val acc: 0.9549, time: 437.55s\n",
            "Epoch:15, Training loss: 859.64, train acc: 0.9924, val loss: 1306.78, val acc: 0.9567, time: 436.80s\n",
            "Epoch:16, Training loss: 746.43, train acc: 0.9946, val loss: 1312.15, val acc: 0.9566, time: 438.53s\n",
            "Epoch:17, Training loss: 635.48, train acc: 0.9942, val loss: 1439.31, val acc: 0.9580, time: 440.64s\n",
            "Epoch:18, Training loss: 578.68, train acc: 0.9962, val loss: 1346.10, val acc: 0.9567, time: 441.11s\n",
            "Epoch:19, Training loss: 468.18, train acc: 0.9970, val loss: 1403.57, val acc: 0.9570, time: 443.64s\n",
            "Epoch:20, Training loss: 454.06, train acc: 0.9971, val loss: 1404.13, val acc: 0.9569, time: 437.46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DpPFktYijJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "85a114e4-e6fc-436b-aeea-7d5ffae4f073"
      },
      "source": [
        "torch.save(model, 'Bilstm_crf_model13_1.pt')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMDDzcXXzgd",
        "colab_type": "code",
        "outputId": "6748ba5f-6d22-43f2-a883-9c2a086b46d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7ANbv_jSzI",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAnJVsyPq5kR",
        "colab_type": "code",
        "outputId": "953e26db-d328-4417-f21b-8b085cfe2ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.9150    0.8998    0.9073       419\n",
            "      I-MISC     0.8363    0.7647    0.7989       187\n",
            "       I-ORG     0.6910    0.7298    0.7099       285\n",
            "       I-PER     0.9400    0.8949    0.9169       875\n",
            "           O     0.9806    0.9889    0.9848      5790\n",
            "\n",
            "    accuracy                         0.9578      7556\n",
            "   macro avg     0.8726    0.8556    0.8636      7556\n",
            "weighted avg     0.9578    0.9578    0.9577      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Vihry_Y3lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def leaderboard(model, input_index, input_feature):\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      \n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y0fX78Ysm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "test_pred_decode = decode_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xqOcTPz3iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "co1 = []\n",
        "co2 = []\n",
        "for i in range(len(test_pred_decode)):\n",
        "    co1.append(i)\n",
        "    co2.append(test_pred_decode[i])\n",
        "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
        "leaderboard.to_csv(\"leaderboard13_1.csv\", index=False, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXGK44ibbYBp",
        "colab_type": "code",
        "outputId": "50997216-9207-406a-e23b-593c29d69471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "da=pd.read_csv(\"leaderboard13_1.csv\")\n",
        "da.head(10)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Predicted\n",
              "0   0         O\n",
              "1   1         O\n",
              "2   2         O\n",
              "3   3     I-LOC\n",
              "4   4         O\n",
              "5   5     I-PER\n",
              "6   6         O\n",
              "7   7         O\n",
              "8   8     I-LOC\n",
              "9   9         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVVLm4esLVJd",
        "colab_type": "code",
        "outputId": "6ce4e7d4-0dc9-4e3a-d7d9-e18b1f077d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(13972, 50)\n",
              "  (lstm_1): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_2): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_3): LSTM(96, 50, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}