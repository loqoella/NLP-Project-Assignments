{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model3_feature2_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKhhaHUvYgoa",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition + 3 bi-lstm + 2 self-attention + feature (word2vec + pos) + hidden_dim = 100\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY4scQ1RUve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwUrZvQakO2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "id = '1m2je3m7MiyHJynZv8bUtmUYWUJy7vCTl'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1Cm_SL9JHgJ6_1qh6FeuOpUFi_-lbtQw3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "id = '18Av4rRPwnlCdF2V4wXKioYlPNy7DgzFJ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtRDEwSCMcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the files of the PoS tags for the dataset\n",
        "# PoS tags are used as one of the features \n",
        "\n",
        "id = '1UmNHdUZxjfcuIzCcAKuBvfBXdSWFv47i'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.txt')\n",
        "\n",
        "id = '11bZIh5V9m2nZJ5s5xQ_gxHEHkAEhV8eQ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('validation.txt')\n",
        "\n",
        "id = '1V-LQuJWT62aCytYuhZuaxvICsqiF1rdK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK73yG9zfHbt",
        "colab_type": "code",
        "outputId": "392b61be-7aaa-47a6-8401-a3d67efab56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a list of Sentence and a list of NER\n",
        "\n",
        "sentences_train = df_train['Sentence'].tolist()\n",
        "ner_train = df_train['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_train_split = []\n",
        "ner_train_split = []\n",
        "for each_sentence in sentences_train:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_train_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_train:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_train_split.append(each_ner)\n",
        "print(sentence_train_split[1][0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNInRtB7PDia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_val = df_val['Sentence'].tolist()\n",
        "ner_val = df_val['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_val_split = []\n",
        "ner_val_split = []\n",
        "for each_sentence in sentences_val:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_val_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_val:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_val_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjohNx5IvRVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence\n",
        "\n",
        "sentences_test = df_test['Sentence'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_test_split = []\n",
        "\n",
        "for each_sentence in sentences_test:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_test_split.append(each_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S049P4HVDJTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "    pos_data = []\n",
        "    pos = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':   \n",
        "            pos_data.append(pos)\n",
        "            pos = []\n",
        "        else:    \n",
        "            pos.append(i.replace('\\n','').split(' ')[1])\n",
        "    return pos_data[:n_sample]\n",
        "\n",
        "pos_train = read_data(\"train.txt\", 3000)\n",
        "pos_validation = read_data(\"validation.txt\",700)\n",
        "pos_test = read_data(\"test.txt\",3684)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5gUSbrHQ6J2",
        "colab_type": "text"
      },
      "source": [
        "# Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH_xBcfvfQp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirHmtHeIcGp",
        "colab_type": "code",
        "outputId": "b4e1f6e4-271e-43a5-e50f-b4bc87dd50d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "total_words = []\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        total_words.append(word)\n",
        "\n",
        "print(len(total_words))\n",
        "print(len(set(total_words)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93794\n",
            "13972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ezZdNCrEDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pos_list = []\n",
        "\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    pos_line = []\n",
        "    for each_pos in line:\n",
        "        pos_line.append(each_pos)\n",
        "    total_pos_list.append(pos_line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQNSEP8HXtS",
        "colab_type": "code",
        "outputId": "ec2b2189-52d8-4c75-e205-0be83a00b8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pos_to_ix = {}\n",
        "pos_list = []\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    for pos in line:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "pos_list = sorted(list(pos_to_ix.keys()))\n",
        "\n",
        "pos_list_length = len(pos_list)\n",
        "print(pos_list_length)\n",
        "print(pos_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My7OPDfWVvnk",
        "colab_type": "code",
        "outputId": "96984932-e780-4b0e-b7a9-c8931db598f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# key is the pos tag, value is the one hot expression\n",
        "onehotpos = {}\n",
        "\n",
        "for i in range(pos_list_length):   \n",
        "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
        "    onehotpos[pos_list[i]] = list(onehot[0])\n",
        "\n",
        "print(onehotpos)\n",
        "\n",
        "def get_onehotpos(pos_sentence):\n",
        "    pos_list = []\n",
        "    for each_pos in pos_sentence:\n",
        "        onehot_pos = onehotpos[each_pos]\n",
        "        pos_list.append(onehot_pos)\n",
        "    return pos_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14mferpb4dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
        "sentence_to_pos = {}\n",
        "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
        "for i in range(total_length):\n",
        "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sf0ks6vBHqI",
        "colab_type": "code",
        "outputId": "e97c7d59-1281-4ef1-bbc1-71553909701e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(sentence_to_pos[i])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1NsLQ3qlBP",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3DcyEtJ93fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        sentence_feature_list = []\n",
        "        for j in range(len(sentence_to_pos[i])): \n",
        "            sentence_feature_list.append(sentence_to_pos[i][j])\n",
        "        \n",
        "        feature_list.append(sentence_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0Tv48EMi__",
        "colab_type": "code",
        "outputId": "ec0c7fc6-0852-4154-b98f-06758eed4e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "print(get_feature(0,5))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7og4EnAq8aG",
        "colab_type": "text"
      },
      "source": [
        "## Distribution Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-vnejvEDZ7",
        "colab_type": "code",
        "outputId": "2deb21bb-aa93-4baa-aa4e-d8a346c2fada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentence_lengths = []\n",
        "for each_sentence in total_sentences:\n",
        "    length = len(each_sentence)\n",
        "    sentence_lengths.append(length)\n",
        "\n",
        "total_sentence_num = len(sentence_lengths)\n",
        "largest_length = max(sentence_lengths)\n",
        "mean_length = np.mean(sentence_lengths)\n",
        "counts_length = np.bincount(sentence_lengths)\n",
        "counts_length = np.argmax(counts_length)\n",
        "length_less_than_counts = 0\n",
        "length_less_than_mean = 0 \n",
        "length_less_than_15 = 0\n",
        "length_less_than_20 = 0\n",
        "length_less_than_25 = 0\n",
        "length_less_than_30 = 0\n",
        "\n",
        "for length in sentence_lengths:\n",
        "  if length < counts_length:\n",
        "    length_less_than_counts += 1\n",
        "  if length < mean_length:\n",
        "    length_less_than_mean += 1\n",
        "  if length < 15:\n",
        "    length_less_than_15 += 1\n",
        "  if length < 20:\n",
        "    length_less_than_20 += 1\n",
        "  if length < 25:\n",
        "    length_less_than_25 += 1\n",
        "  if length < 30:\n",
        "    length_less_than_30 += 1\n",
        "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
        "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
        "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
        "print(y_rate)\n",
        "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences: 7384 Largest length of the sentence: 124\n",
            "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFsK7PUsNox",
        "colab_type": "text"
      },
      "source": [
        "There are 5 kinds of tag in total.\n",
        "\n",
        "'I-ORG': Organization\n",
        "\n",
        "'O': Other\n",
        "\n",
        "'I-LOC': Location \n",
        "\n",
        "'I-PER': Person \n",
        "\n",
        "'I-MISC': Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-UMIHEKrgCw",
        "colab_type": "code",
        "outputId": "fe0560c1-eec7-47ad-de77-60c7bc16acb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ner_train_list = []\n",
        "for each_ner in ner_train_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_train_list.append(each_tag)\n",
        "ner_train_set = list(set(ner_train_list))\n",
        "print(len(ner_train_list))\n",
        "print(len(ner_train_set))\n",
        "print(ner_train_set)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39572\n",
            "5\n",
            "['I-ORG', 'I-LOC', 'I-PER', 'O', 'I-MISC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chjiqNYkzNK",
        "colab_type": "code",
        "outputId": "2b109968-d7f9-4c6e-8ad9-22694d83e23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ner_val_list = []\n",
        "for each_ner in ner_val_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_val_list.append(each_tag)\n",
        "ner_val_set = list(set(ner_val_list))\n",
        "print(len(ner_val_list))\n",
        "print(len(ner_val_set))\n",
        "print(ner_val_set)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556\n",
            "5\n",
            "['I-ORG', 'I-LOC', 'I-PER', 'O', 'I-MISC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDuagDgs1Yj4",
        "colab_type": "code",
        "outputId": "281e6f21-95cf-4363-a2fa-ff54a27a74f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_train_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   1526\n",
            "O:       32137\n",
            "I-LOC:   1994\n",
            "I-PER:   2840\n",
            "I-MISC:  1075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_NXJRv7k__M",
        "colab_type": "code",
        "outputId": "ca3e3a43-9c8a-412f-fddb-1b286f8d1be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_val_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   285\n",
            "O:       5790\n",
            "I-LOC:   419\n",
            "I-PER:   875\n",
            "I-MISC:  187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9s9J-lDKUC",
        "colab_type": "text"
      },
      "source": [
        "In the data, you can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfakfv0CRwAB",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "There are too many NaN values in ‘Sentence #” column, fill NaN by preceding values.\n",
        "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcu5O3OlEdPA",
        "colab_type": "text"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsvF8uXSgy5",
        "colab_type": "code",
        "outputId": "e3d3a3b5-a83f-41ce-f777-d3692e558a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4F991p-IqNS",
        "colab_type": "text"
      },
      "source": [
        "##Conditional random fields (CRF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Xcf07iR79l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPELELtSmYo",
        "colab_type": "code",
        "outputId": "9da5c2f5-7ed0-46d2-96c0-9e32c1067f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_train = []\n",
        "for line in range(len(sentence_train_split)):\n",
        "    combine_sentence = []\n",
        "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
        "        combine_sentence.append((each_word, each_tag))\n",
        "    zip_sentences_train.append(combine_sentence)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_train[i])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
            "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
            "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJIH2emlP1y",
        "colab_type": "code",
        "outputId": "88c973d5-5861-45f8-dd63-de4b7ba1b09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_val = []\n",
        "for line in range(len(sentence_val_split)):\n",
        "    combine_sentence_val = []\n",
        "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
        "        combine_sentence_val.append((each_word, each_tag))\n",
        "    zip_sentences_val.append(combine_sentence_val)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_val[i])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('cricket', 'O'), ('-', 'O'), ('leicestershire', 'I-ORG'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('top', 'O'), ('after', 'O'), ('innings', 'O'), ('victory', 'O'), ('.', 'O')]\n",
            "[('london', 'I-LOC'), ('1996-08-30', 'O')]\n",
            "[('west', 'I-MISC'), ('indian', 'I-MISC'), ('all-rounder', 'O'), ('phil', 'I-PER'), ('simmons', 'I-PER'), ('took', 'O'), ('four', 'O'), ('for', 'O'), ('38', 'O'), ('on', 'O'), ('friday', 'O'), ('as', 'O'), ('leicestershire', 'I-ORG'), ('beat', 'O'), ('somerset', 'I-ORG'), ('by', 'O'), ('an', 'O'), ('innings', 'O'), ('and', 'O'), ('39', 'O'), ('runs', 'O'), ('in', 'O'), ('two', 'O'), ('days', 'O'), ('to', 'O'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('the', 'O'), ('head', 'O'), ('of', 'O'), ('the', 'O'), ('county', 'O'), ('championship', 'O'), ('.', 'O')]\n",
            "[('their', 'O'), ('stay', 'O'), ('on', 'O'), ('top', 'O'), (',', 'O'), ('though', 'O'), (',', 'O'), ('may', 'O'), ('be', 'O'), ('short-lived', 'O'), ('as', 'O'), ('title', 'O'), ('rivals', 'O'), ('essex', 'I-ORG'), (',', 'O'), ('derbyshire', 'I-ORG'), ('and', 'O'), ('surrey', 'I-ORG'), ('all', 'O'), ('closed', 'O'), ('in', 'O'), ('on', 'O'), ('victory', 'O'), ('while', 'O'), ('kent', 'I-ORG'), ('made', 'O'), ('up', 'O'), ('for', 'O'), ('lost', 'O'), ('time', 'O'), ('in', 'O'), ('their', 'O'), ('rain-affected', 'O'), ('match', 'O'), ('against', 'O'), ('nottinghamshire', 'I-ORG'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alfVxIWIFEth",
        "colab_type": "text"
      },
      "source": [
        "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbaee897Sqoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    # postag = sent[i][1]\n",
        "    # a few features: upper? lower? title? \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:], # last three letters of the word\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(), \n",
        "        'word.istitle()': word.istitle(), # is it a title?\n",
        "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
        "       \n",
        "    }\n",
        "    # features of the previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        # postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "          \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    # features of the next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "       \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            \n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9Xu722SzYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features_train = [sent2features(s) for s in zip_sentences_train]\n",
        "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
        "\n",
        "features_val = [sent2features(s) for s in zip_sentences_val]\n",
        "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3g66D_kMlCp",
        "colab_type": "code",
        "outputId": "511470c2-93ea-4cf3-945a-a4c6fb7de3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for i in range(5):\n",
        "     print(features_train[i])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'bias': 1.0, 'word.lower()': '-docstart-', 'word[-3:]': 'rt-', 'word[-2:]': 't-', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'eu', 'word[-3:]': 'eu', 'word[-2:]': 'eu', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'rejects', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'rejects', 'word[-3:]': 'cts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'eu', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'rejects', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'call', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'call', 'word[-3:]': 'all', 'word[-2:]': 'll', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'call', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'boycott', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'boycott', 'word[-3:]': 'ott', 'word[-2:]': 'tt', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'boycott', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'peter', 'word[-3:]': 'ter', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'blackburn', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'blackburn', 'word[-3:]': 'urn', 'word[-2:]': 'rn', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'peter', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'brussels', 'word[-3:]': 'els', 'word[-2:]': 'ls', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '1996-08-22', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '1996-08-22', 'word[-3:]': '-22', 'word[-2:]': '22', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'brussels', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'the', 'word[-3:]': 'the', 'word[-2:]': 'he', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'european', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'european', 'word[-3:]': 'ean', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'the', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'commission', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'commission', 'word[-3:]': 'ion', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'european', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'said', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'said', 'word[-3:]': 'aid', 'word[-2:]': 'id', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'commission', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'on', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'on', 'word[-3:]': 'on', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'said', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'thursday', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'thursday', 'word[-3:]': 'day', 'word[-2:]': 'ay', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'on', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'it', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'it', 'word[-3:]': 'it', 'word[-2:]': 'it', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'thursday', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disagreed', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disagreed', 'word[-3:]': 'eed', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'it', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'with', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'with', 'word[-3:]': 'ith', 'word[-2:]': 'th', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disagreed', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'with', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'advice', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'advice', 'word[-3:]': 'ice', 'word[-2:]': 'ce', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'advice', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'consumers', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'consumers', 'word[-3:]': 'ers', 'word[-2:]': 'rs', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'consumers', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'shun', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'shun', 'word[-3:]': 'hun', 'word[-2:]': 'un', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'shun', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'until', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'until', 'word[-3:]': 'til', 'word[-2:]': 'il', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'scientists', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'scientists', 'word[-3:]': 'sts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'until', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'determine', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'determine', 'word[-3:]': 'ine', 'word[-2:]': 'ne', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'scientists', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'whether', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'whether', 'word[-3:]': 'her', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'determine', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'mad', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'mad', 'word[-3:]': 'mad', 'word[-2:]': 'ad', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'whether', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'cow', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'cow', 'word[-3:]': 'cow', 'word[-2:]': 'ow', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'mad', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disease', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disease', 'word[-3:]': 'ase', 'word[-2:]': 'se', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'cow', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'can', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'can', 'word[-3:]': 'can', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disease', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'be', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'be', 'word[-3:]': 'be', 'word[-2:]': 'be', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'can', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'transmitted', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'transmitted', 'word[-3:]': 'ted', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'be', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'transmitted', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'sheep', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'sheep', 'word[-3:]': 'eep', 'word[-2:]': 'ep', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'sheep', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2kJfNAS1N2",
        "colab_type": "code",
        "outputId": "d7efa587-2210-472b-ed22-84d44e59340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(features_train, labels_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxUCHw5FXGt",
        "colab_type": "text"
      },
      "source": [
        "Because tag “O” (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag “O” when we evaluate classification metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGFs5K6EVC0R",
        "colab_type": "text"
      },
      "source": [
        "B: begining of ... \n",
        "I: identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnMwxl4UVPN",
        "colab_type": "code",
        "outputId": "64851bcb-7d36-4562-aaeb-c2f0c415c0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ner_train_set.remove('O')\n",
        "classes = ner_train_set\n",
        "print(classes)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-ORG', 'I-LOC', 'I-PER', 'I-MISC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9jdSefS4id",
        "colab_type": "code",
        "outputId": "c8b5e213-fff2-45ec-ba2d-9aecf7107a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(features_val)\n",
        "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-ORG       0.85      0.58      0.69       285\n",
            "       I-LOC       0.89      0.85      0.87       419\n",
            "       I-PER       0.93      0.80      0.86       875\n",
            "      I-MISC       0.83      0.63      0.72       187\n",
            "\n",
            "   micro avg       0.90      0.76      0.82      1766\n",
            "   macro avg       0.88      0.72      0.78      1766\n",
            "weighted avg       0.90      0.76      0.82      1766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3oWq_PnK8wk",
        "colab_type": "text"
      },
      "source": [
        "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40His-7UKyvp",
        "colab_type": "code",
        "outputId": "c3a0dcb3-61f5-4d56-972f-b8e8242c9061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "I-PER  -> I-PER   3.403927\n",
            "I-ORG  -> I-ORG   3.384090\n",
            "I-MISC -> I-MISC  2.828140\n",
            "I-LOC  -> I-LOC   2.064296\n",
            "O      -> O       0.776679\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-PER  -> I-LOC   -2.677780\n",
            "I-PER  -> I-ORG   -2.689004\n",
            "I-LOC  -> I-PER   -3.410616\n",
            "I-ORG  -> I-LOC   -3.463856\n",
            "I-ORG  -> I-PER   -3.736825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbtE0AYpvtX",
        "colab_type": "text"
      },
      "source": [
        "## Bi-LSTM CRF model\n",
        "\n",
        "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCqGvJchOdR",
        "colab_type": "text"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWAK0NV3INF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert each unique word to the index\n",
        "word_to_ix = {}\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in ner_train_split + ner_val_split:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNgyvEADwYZt",
        "colab_type": "code",
        "outputId": "e54f1a79-a273-45d7-816f-36ad5cf0a052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(len(word_list))\n",
        "for i in range(5):\n",
        "    print(word_list[i])\n",
        "    print(list(word_to_ix.values())[i])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "-docstart-\n",
            "0\n",
            "eu\n",
            "1\n",
            "rejects\n",
            "2\n",
            "german\n",
            "3\n",
            "call\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tndg_-ttwa6N",
        "colab_type": "code",
        "outputId": "75c9763c-035f-4029-ab51-e96cc4abbfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tag_to_ix)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrekRAbtxL2",
        "colab_type": "code",
        "outputId": "345d481c-8e3d-4b8a-cf17-454333ee581c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(word_list), len(tag_to_ix))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEswz2QjhXBM",
        "colab_type": "text"
      },
      "source": [
        "#### Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oz6KVyjsxM9",
        "colab_type": "code",
        "outputId": "cec28117-4a7f-4267-9a78-2affb1afc821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "# change a latest embedding!\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-50\") \n",
        "# word dimension\n",
        "EMBEDDING_DIM = 50\n",
        "embedding_matrix = []\n",
        "num_except = 0\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        num_except += 1\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlchZJO8hdXa",
        "colab_type": "text"
      },
      "source": [
        "#### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRs6mouFwEx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# use the index to represent each word in each sentence\n",
        "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
        "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
        "\n",
        "train_input_feature = get_feature(0, 2999)\n",
        "\n",
        "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
        "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
        "val_input_feature = get_feature(3000, 3699)\n",
        "\n",
        "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
        "test_input_feature = get_feature(3700, 7383)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDEcKXhP_yLV",
        "colab_type": "code",
        "outputId": "7d7d5925-bcde-4bd6-f0a8-98d55e867dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(train_input_index[i])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[10, 11]\n",
            "[12, 13]\n",
            "[14, 15, 16, 17, 18, 19, 20, 21, 22, 3, 23, 5, 24, 5, 25, 7, 8, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 5, 36, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqtXLVSPFJgl",
        "colab_type": "code",
        "outputId": "9f86bfe3-bd09-4968-89dd-946354acf7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(val_input_index[i])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[2001, 636, 2045, 210, 775, 154, 382, 117, 2090, 1798, 9]\n",
            "[261, 7913]\n",
            "[1001, 5476, 2285, 1693, 2048, 764, 2167, 68, 7914, 18, 1094, 141, 2045, 1758, 2017, 91, 155, 2090, 84, 3717, 2983, 229, 391, 947, 5, 210, 775, 154, 14, 1811, 159, 14, 2002, 2003, 9]\n",
            "[196, 4831, 18, 382, 69, 6020, 69, 1062, 34, 7915, 141, 1971, 388, 2034, 69, 7916, 84, 2070, 412, 1358, 229, 18, 1798, 477, 2037, 3390, 305, 68, 2851, 367, 229, 196, 7917, 1768, 742, 2064, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igZht_BbxOvw",
        "colab_type": "code",
        "outputId": "7d949f49-ee44-465f-dcd6-1ad8b448f886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(train_output_index[i])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[3, 2, 4, 2, 2, 2, 4, 2, 2]\n",
            "[5, 5]\n",
            "[6, 2]\n",
            "[2, 3, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEscWBrhjgb",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)   \n",
        "\n",
        "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "        # Use nn.Embedding\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_3 = nn.LSTM(95, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "      \n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    # CRF: use the transition matrix to train our model\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    # Attention Calculation: two methods\n",
        "    def cal_self_attention(self, hidden, method):\n",
        "        # 1st type of calculation of the attention: Dot Product\n",
        "        if method == 'Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
        "            attn_weights = F.softmax(a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "           \n",
        "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
        "        elif method == 'Scale Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
        "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "\n",
        "    def _get_lstm_features(self, sentence, features):\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # 96\n",
        "        features = features.view(len(features),1,-1)\n",
        "        # concat the word embedding with the word features\n",
        "        word_concat = torch.cat((embeds, features), dim = 2) # [1,1,96]\n",
        "\n",
        "     \n",
        "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden) \n",
        "        \n",
        "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
        "        \n",
        "\n",
        "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden) \n",
        "        \n",
        "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')\n",
        "\n",
        "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
        "\n",
        "        \n",
        "        # change from 3 dimensions to 2 dimensions\n",
        "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    ''' Calculate the score for the viterbi decoding'''\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, features, tags):\n",
        "        feats = self._get_lstm_features(sentence, features)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    # sentence is a index expression of the words in the sentence \n",
        "    def forward(self, sentence, features):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, features)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNHEV1kiDKt",
        "colab_type": "text"
      },
      "source": [
        "#### Function for accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Moqs-zwboIn",
        "colab_type": "text"
      },
      "source": [
        "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def cal_acc(model, input_index, input_feature, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      ground_truth.extend(output_index[i])\n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      accuracy = accuracy_score(predicted, ground_truth)\n",
        "      \n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82UaXEOhoQQ",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UiokVOjPUn",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru",
        "colab_type": "code",
        "outputId": "c9571916-6e00-49e6-f728-e84c3a04325f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 370s\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "for epoch in range(30): \n",
        "    epoch_list.append(epoch) \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "  \n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        # Use the forward pass\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    val_loss = 0\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
        "        val_loss+=loss.item()\n",
        "        \n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 26872.29, train acc: 0.8854, val loss: 3052.21, val acc: 0.8839, time: 252.13s\n",
            "Epoch:2, Training loss: 10712.36, train acc: 0.9279, val loss: 1979.61, val acc: 0.9217, time: 255.10s\n",
            "Epoch:3, Training loss: 7779.17, train acc: 0.9429, val loss: 1690.31, val acc: 0.9291, time: 252.92s\n",
            "Epoch:4, Training loss: 6125.11, train acc: 0.9561, val loss: 1609.29, val acc: 0.9326, time: 253.57s\n",
            "Epoch:5, Training loss: 5039.46, train acc: 0.9636, val loss: 1489.16, val acc: 0.9390, time: 245.37s\n",
            "Epoch:6, Training loss: 4287.04, train acc: 0.9686, val loss: 1415.23, val acc: 0.9430, time: 241.49s\n",
            "Epoch:7, Training loss: 3675.45, train acc: 0.9723, val loss: 1369.70, val acc: 0.9461, time: 240.75s\n",
            "Epoch:8, Training loss: 3248.58, train acc: 0.9759, val loss: 1290.59, val acc: 0.9463, time: 239.79s\n",
            "Epoch:9, Training loss: 2876.45, train acc: 0.9786, val loss: 1279.01, val acc: 0.9489, time: 235.52s\n",
            "Epoch:10, Training loss: 2546.48, train acc: 0.9806, val loss: 1304.10, val acc: 0.9489, time: 234.02s\n",
            "Epoch:11, Training loss: 2214.40, train acc: 0.9846, val loss: 1296.20, val acc: 0.9512, time: 239.41s\n",
            "Epoch:12, Training loss: 1967.24, train acc: 0.9857, val loss: 1289.27, val acc: 0.9513, time: 248.24s\n",
            "Epoch:13, Training loss: 1712.65, train acc: 0.9880, val loss: 1301.22, val acc: 0.9541, time: 241.69s\n",
            "Epoch:14, Training loss: 1470.09, train acc: 0.9890, val loss: 1333.65, val acc: 0.9522, time: 237.86s\n",
            "Epoch:15, Training loss: 1274.22, train acc: 0.9900, val loss: 1399.33, val acc: 0.9493, time: 235.50s\n",
            "Epoch:16, Training loss: 1053.17, train acc: 0.9911, val loss: 1432.97, val acc: 0.9524, time: 234.86s\n",
            "Epoch:17, Training loss: 920.58, train acc: 0.9922, val loss: 1321.57, val acc: 0.9539, time: 234.03s\n",
            "Epoch:18, Training loss: 795.22, train acc: 0.9941, val loss: 1436.52, val acc: 0.9537, time: 232.88s\n",
            "Epoch:19, Training loss: 690.06, train acc: 0.9941, val loss: 1398.77, val acc: 0.9565, time: 233.23s\n",
            "Epoch:20, Training loss: 578.62, train acc: 0.9960, val loss: 1545.42, val acc: 0.9555, time: 232.48s\n",
            "Epoch:21, Training loss: 551.40, train acc: 0.9963, val loss: 1501.51, val acc: 0.9576, time: 232.59s\n",
            "Epoch:22, Training loss: 488.87, train acc: 0.9969, val loss: 1524.59, val acc: 0.9545, time: 236.12s\n",
            "Epoch:23, Training loss: 390.85, train acc: 0.9976, val loss: 1599.75, val acc: 0.9578, time: 239.22s\n",
            "Epoch:24, Training loss: 384.25, train acc: 0.9977, val loss: 1577.61, val acc: 0.9562, time: 235.43s\n",
            "Epoch:25, Training loss: 293.00, train acc: 0.9980, val loss: 1626.43, val acc: 0.9529, time: 232.89s\n",
            "Epoch:26, Training loss: 276.71, train acc: 0.9984, val loss: 1680.32, val acc: 0.9553, time: 233.10s\n",
            "Epoch:27, Training loss: 300.09, train acc: 0.9972, val loss: 1668.41, val acc: 0.9557, time: 232.89s\n",
            "Epoch:28, Training loss: 256.46, train acc: 0.9975, val loss: 1746.89, val acc: 0.9561, time: 232.46s\n",
            "Epoch:29, Training loss: 234.18, train acc: 0.9986, val loss: 1808.84, val acc: 0.9539, time: 233.85s\n",
            "Epoch:30, Training loss: 222.49, train acc: 0.9983, val loss: 1890.04, val acc: 0.9576, time: 233.71s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMDDzcXXzgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "469c4735-368f-46b0-a792-8ef8cc321dc1"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7ANbv_jSzI",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAnJVsyPq5kR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "08c9c488-cdfe-4c7c-8044-60733caf836d"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.9332    0.8998    0.9162       419\n",
            "      I-MISC     0.7861    0.7861    0.7861       187\n",
            "       I-ORG     0.8000    0.6175    0.6970       285\n",
            "       I-PER     0.9284    0.8891    0.9083       875\n",
            "           O     0.9739    0.9936    0.9837      5790\n",
            "\n",
            "    accuracy                         0.9570      7556\n",
            "   macro avg     0.8843    0.8372    0.8583      7556\n",
            "weighted avg     0.9552    0.9570    0.9555      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_KMytuHgOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "14ead074-9d96-4147-e9e6-e78045620949"
      },
      "source": [
        "torch.save(model, 'Bilstm_crf_model14_feature2.pt')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vULrL_HFGrgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0faa3391-eaa7-4960-c5f7-201ebffe8a29"
      },
      "source": [
        "for i in range(5):\n",
        "    print(y_pred_decode[i])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "O\n",
            "O\n",
            "I-ORG\n",
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Vihry_Y3lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def leaderboard(model, input_index, input_feature):\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      \n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y0fX78Ysm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "test_pred_decode = decode_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7m0Mv2xaiq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "18806612-ecaf-493a-a8bc-bcd1ec386279"
      },
      "source": [
        "for i in range(5):\n",
        "    print(test_pred_decode[i])\n",
        "print(len(test_pred_decode))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "O\n",
            "O\n",
            "I-LOC\n",
            "O\n",
            "46666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xqOcTPz3iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "co1 = []\n",
        "co2 = []\n",
        "for i in range(len(test_pred_decode)):\n",
        "    co1.append(i)\n",
        "    co2.append(test_pred_decode[i])\n",
        "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
        "leaderboard.to_csv(\"leaderboard14_feature2.csv\", index=False, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXGK44ibbYBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "832ba3dd-553e-43fd-f197-7a40e8e4325e"
      },
      "source": [
        "da=pd.read_csv(\"leaderboard14_feature2.csv\")\n",
        "da.head(10)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Predicted\n",
              "0   0         O\n",
              "1   1         O\n",
              "2   2         O\n",
              "3   3     I-LOC\n",
              "4   4         O\n",
              "5   5     I-PER\n",
              "6   6         O\n",
              "7   7         O\n",
              "8   8     I-LOC\n",
              "9   9         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}