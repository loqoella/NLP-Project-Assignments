{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model3_feature3_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKhhaHUvYgoa",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition + 3 bi-lstm + 2 self-attention + 3 features + lr = 0.001 + hidden dim = 200\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xY4scQ1RUve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwUrZvQakO2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "id = '1m2je3m7MiyHJynZv8bUtmUYWUJy7vCTl'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1Cm_SL9JHgJ6_1qh6FeuOpUFi_-lbtQw3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "id = '18Av4rRPwnlCdF2V4wXKioYlPNy7DgzFJ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtRDEwSCMcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the files of the PoS tags for the dataset\n",
        "# PoS tags are used as one of the features \n",
        "\n",
        "id = '1UmNHdUZxjfcuIzCcAKuBvfBXdSWFv47i'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.txt')\n",
        "\n",
        "id = '11bZIh5V9m2nZJ5s5xQ_gxHEHkAEhV8eQ'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('validation.txt')\n",
        "\n",
        "id = '1V-LQuJWT62aCytYuhZuaxvICsqiF1rdK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK73yG9zfHbt",
        "colab_type": "code",
        "outputId": "34ed1094-0169-4522-de4c-be87f7a80520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# create a list of Sentence and a list of NER\n",
        "\n",
        "sentences_train = df_train['Sentence'].tolist()\n",
        "ner_train = df_train['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_train_split = []\n",
        "ner_train_split = []\n",
        "for each_sentence in sentences_train:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_train_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_train:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_train_split.append(each_ner)\n",
        "print(sentence_train_split[1][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNInRtB7PDia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_val = df_val['Sentence'].tolist()\n",
        "ner_val = df_val['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_val_split = []\n",
        "ner_val_split = []\n",
        "for each_sentence in sentences_val:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_val_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_val:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_val_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjohNx5IvRVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence\n",
        "\n",
        "sentences_test = df_test['Sentence'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_test_split = []\n",
        "\n",
        "for each_sentence in sentences_test:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_test_split.append(each_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S049P4HVDJTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "    pos_data = []\n",
        "    pos = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':   \n",
        "            pos_data.append(pos)\n",
        "            pos = []\n",
        "        else:    \n",
        "            pos.append(i.replace('\\n','').split(' ')[1])\n",
        "    return pos_data[:n_sample]\n",
        "\n",
        "pos_train = read_data(\"train.txt\", 3000)\n",
        "pos_validation = read_data(\"validation.txt\",700)\n",
        "pos_test = read_data(\"test.txt\",3684)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5gUSbrHQ6J2",
        "colab_type": "text"
      },
      "source": [
        "# Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH_xBcfvfQp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MirHmtHeIcGp",
        "colab_type": "code",
        "outputId": "c823e308-b750-465c-ca3c-e6ec7f617841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "total_words = []\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        total_words.append(word)\n",
        "\n",
        "print(len(total_words))\n",
        "print(len(set(total_words)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93794\n",
            "13972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ezZdNCrEDCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_pos_list = []\n",
        "\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    pos_line = []\n",
        "    for each_pos in line:\n",
        "        pos_line.append(each_pos)\n",
        "    total_pos_list.append(pos_line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQNSEP8HXtS",
        "colab_type": "code",
        "outputId": "fdbdeefe-7b29-4f1e-b53b-881eafb09727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pos_to_ix = {}\n",
        "pos_list = []\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    for pos in line:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "pos_list = sorted(list(pos_to_ix.keys()))\n",
        "\n",
        "pos_list_length = len(pos_list)\n",
        "print(pos_list_length)\n",
        "print(pos_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My7OPDfWVvnk",
        "colab_type": "code",
        "outputId": "a894727e-052b-4b7a-b9e4-e3fa80cbf25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# key is the pos tag, value is the one hot expression\n",
        "onehotpos = {}\n",
        "\n",
        "for i in range(pos_list_length):   \n",
        "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
        "    onehotpos[pos_list[i]] = list(onehot[0])\n",
        "\n",
        "print(onehotpos)\n",
        "\n",
        "def get_onehotpos(pos_sentence):\n",
        "    pos_list = []\n",
        "    for each_pos in pos_sentence:\n",
        "        onehot_pos = onehotpos[each_pos]\n",
        "        pos_list.append(onehot_pos)\n",
        "    return pos_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14mferpb4dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
        "sentence_to_pos = {}\n",
        "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
        "for i in range(total_length):\n",
        "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sf0ks6vBHqI",
        "colab_type": "code",
        "outputId": "a3f2c99b-dced-4314-b4d3-67731975de06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(sentence_to_pos[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1NsLQ3qlBP",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XY3R9ePJOY",
        "colab_type": "code",
        "outputId": "e3c3a741-6dc5-491d-c2a8-ef4c5bc471a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "DF = {}\n",
        "\n",
        "for each_sentence in total_sentences:\n",
        "    for term in np.unique(each_sentence):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "\n",
        "print(len(DF))\n",
        "\n",
        "\n",
        "tf_idf = {}\n",
        "N = total_length\n",
        "print(N)\n",
        "\n",
        "for i in range(N):\n",
        "    counter = Counter(total_sentences[i])\n",
        "    total_num_words = len(total_sentences[i])   \n",
        "    # the tfidf of all words in a sentence\n",
        "    each_sentence_tfidf = []\n",
        "    \n",
        "    for term in total_sentences[i]:\n",
        "        tf = counter[term]/total_num_words\n",
        "        df = DF[term]\n",
        "        idf = math.log(N/(df+1))+1\n",
        "        each_sentence_tfidf.append(tf*idf)\n",
        "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
        "    tf_idf[i] = each_sentence_tfidf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "7384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0WnqcLhCxNh",
        "colab_type": "code",
        "outputId": "7d1ac0e2-e29c-469c-896c-918df315cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(tf_idf[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.7867733572317377]\n",
            "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
            "[3.8549230994232344, 3.711082063197344]\n",
            "[3.236541785848771, 2.568193075858512]\n",
            "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFq1dlZnO9mi",
        "colab_type": "code",
        "outputId": "d92e153d-a69f-4f7b-80ae-c3c056d2fc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1\n",
            "9 9\n",
            "2 2\n",
            "2 2\n",
            "30 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3DcyEtJ93fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        sentence_feature_list = []\n",
        "        for j in range(len(sentence_to_pos[i])): \n",
        "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
        "        \n",
        "        feature_list.append(sentence_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF0Tv48EMi__",
        "colab_type": "code",
        "outputId": "15144d44-d5d3-4925-9e87-26ba77505b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "print(get_feature(0,5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7og4EnAq8aG",
        "colab_type": "text"
      },
      "source": [
        "## Distribution Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-vnejvEDZ7",
        "colab_type": "code",
        "outputId": "6fa04749-25aa-45da-a635-862f2b6a4c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentence_lengths = []\n",
        "for each_sentence in total_sentences:\n",
        "    length = len(each_sentence)\n",
        "    sentence_lengths.append(length)\n",
        "\n",
        "total_sentence_num = len(sentence_lengths)\n",
        "largest_length = max(sentence_lengths)\n",
        "mean_length = np.mean(sentence_lengths)\n",
        "counts_length = np.bincount(sentence_lengths)\n",
        "counts_length = np.argmax(counts_length)\n",
        "length_less_than_counts = 0\n",
        "length_less_than_mean = 0 \n",
        "length_less_than_15 = 0\n",
        "length_less_than_20 = 0\n",
        "length_less_than_25 = 0\n",
        "length_less_than_30 = 0\n",
        "\n",
        "for length in sentence_lengths:\n",
        "  if length < counts_length:\n",
        "    length_less_than_counts += 1\n",
        "  if length < mean_length:\n",
        "    length_less_than_mean += 1\n",
        "  if length < 15:\n",
        "    length_less_than_15 += 1\n",
        "  if length < 20:\n",
        "    length_less_than_20 += 1\n",
        "  if length < 25:\n",
        "    length_less_than_25 += 1\n",
        "  if length < 30:\n",
        "    length_less_than_30 += 1\n",
        "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
        "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
        "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
        "print(y_rate)\n",
        "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences: 7384 Largest length of the sentence: 124\n",
            "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFsK7PUsNox",
        "colab_type": "text"
      },
      "source": [
        "There are 5 kinds of tag in total.\n",
        "\n",
        "'I-ORG': Organization\n",
        "\n",
        "'O': Other\n",
        "\n",
        "'I-LOC': Location \n",
        "\n",
        "'I-PER': Person \n",
        "\n",
        "'I-MISC': Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-UMIHEKrgCw",
        "colab_type": "code",
        "outputId": "fab0d460-29bb-4186-b8bf-18d18f7340de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ner_train_list = []\n",
        "for each_ner in ner_train_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_train_list.append(each_tag)\n",
        "ner_train_set = list(set(ner_train_list))\n",
        "print(len(ner_train_list))\n",
        "print(len(ner_train_set))\n",
        "print(ner_train_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39572\n",
            "5\n",
            "['I-PER', 'I-MISC', 'O', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chjiqNYkzNK",
        "colab_type": "code",
        "outputId": "37accd12-b907-46d9-de3f-8d28015c334d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ner_val_list = []\n",
        "for each_ner in ner_val_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_val_list.append(each_tag)\n",
        "ner_val_set = list(set(ner_val_list))\n",
        "print(len(ner_val_list))\n",
        "print(len(ner_val_set))\n",
        "print(ner_val_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556\n",
            "5\n",
            "['I-PER', 'I-MISC', 'O', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDuagDgs1Yj4",
        "colab_type": "code",
        "outputId": "9e3354fe-b75b-4362-d591-8ebb60a61691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_train_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   1526\n",
            "O:       32137\n",
            "I-LOC:   1994\n",
            "I-PER:   2840\n",
            "I-MISC:  1075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_NXJRv7k__M",
        "colab_type": "code",
        "outputId": "1d232aa4-90a0-4acb-c458-d0c16a595a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_val_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   285\n",
            "O:       5790\n",
            "I-LOC:   419\n",
            "I-PER:   875\n",
            "I-MISC:  187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9s9J-lDKUC",
        "colab_type": "text"
      },
      "source": [
        "In the data, you can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfakfv0CRwAB",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "There are too many NaN values in Sentence # column, fill NaN by preceding values.\n",
        "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcu5O3OlEdPA",
        "colab_type": "text"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsvF8uXSgy5",
        "colab_type": "code",
        "outputId": "02a50ee9-31a5-4973-c055-ccf12652398e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4F991p-IqNS",
        "colab_type": "text"
      },
      "source": [
        "##Conditional random fields (CRF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Xcf07iR79l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQPELELtSmYo",
        "colab_type": "code",
        "outputId": "0110dcf7-64ec-4031-e09e-b2a15bba858a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_train = []\n",
        "for line in range(len(sentence_train_split)):\n",
        "    combine_sentence = []\n",
        "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
        "        combine_sentence.append((each_word, each_tag))\n",
        "    zip_sentences_train.append(combine_sentence)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
            "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
            "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJIH2emlP1y",
        "colab_type": "code",
        "outputId": "6462a4ee-faaa-4aa7-9bdf-b2fe362bec6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_val = []\n",
        "for line in range(len(sentence_val_split)):\n",
        "    combine_sentence_val = []\n",
        "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
        "        combine_sentence_val.append((each_word, each_tag))\n",
        "    zip_sentences_val.append(combine_sentence_val)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_val[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('cricket', 'O'), ('-', 'O'), ('leicestershire', 'I-ORG'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('top', 'O'), ('after', 'O'), ('innings', 'O'), ('victory', 'O'), ('.', 'O')]\n",
            "[('london', 'I-LOC'), ('1996-08-30', 'O')]\n",
            "[('west', 'I-MISC'), ('indian', 'I-MISC'), ('all-rounder', 'O'), ('phil', 'I-PER'), ('simmons', 'I-PER'), ('took', 'O'), ('four', 'O'), ('for', 'O'), ('38', 'O'), ('on', 'O'), ('friday', 'O'), ('as', 'O'), ('leicestershire', 'I-ORG'), ('beat', 'O'), ('somerset', 'I-ORG'), ('by', 'O'), ('an', 'O'), ('innings', 'O'), ('and', 'O'), ('39', 'O'), ('runs', 'O'), ('in', 'O'), ('two', 'O'), ('days', 'O'), ('to', 'O'), ('take', 'O'), ('over', 'O'), ('at', 'O'), ('the', 'O'), ('head', 'O'), ('of', 'O'), ('the', 'O'), ('county', 'O'), ('championship', 'O'), ('.', 'O')]\n",
            "[('their', 'O'), ('stay', 'O'), ('on', 'O'), ('top', 'O'), (',', 'O'), ('though', 'O'), (',', 'O'), ('may', 'O'), ('be', 'O'), ('short-lived', 'O'), ('as', 'O'), ('title', 'O'), ('rivals', 'O'), ('essex', 'I-ORG'), (',', 'O'), ('derbyshire', 'I-ORG'), ('and', 'O'), ('surrey', 'I-ORG'), ('all', 'O'), ('closed', 'O'), ('in', 'O'), ('on', 'O'), ('victory', 'O'), ('while', 'O'), ('kent', 'I-ORG'), ('made', 'O'), ('up', 'O'), ('for', 'O'), ('lost', 'O'), ('time', 'O'), ('in', 'O'), ('their', 'O'), ('rain-affected', 'O'), ('match', 'O'), ('against', 'O'), ('nottinghamshire', 'I-ORG'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alfVxIWIFEth",
        "colab_type": "text"
      },
      "source": [
        "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite formateach sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbaee897Sqoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    # postag = sent[i][1]\n",
        "    # a few features: upper? lower? title? \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:], # last three letters of the word\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(), \n",
        "        'word.istitle()': word.istitle(), # is it a title?\n",
        "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
        "       \n",
        "    }\n",
        "    # features of the previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        # postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "          \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    # features of the next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "       \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            \n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME9Xu722SzYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features_train = [sent2features(s) for s in zip_sentences_train]\n",
        "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
        "\n",
        "features_val = [sent2features(s) for s in zip_sentences_val]\n",
        "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3g66D_kMlCp",
        "colab_type": "code",
        "outputId": "58af7049-8f27-40b3-fda9-15157038d21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "     print(features_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'bias': 1.0, 'word.lower()': '-docstart-', 'word[-3:]': 'rt-', 'word[-2:]': 't-', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'eu', 'word[-3:]': 'eu', 'word[-2:]': 'eu', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'rejects', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'rejects', 'word[-3:]': 'cts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'eu', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'rejects', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'call', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'call', 'word[-3:]': 'all', 'word[-2:]': 'll', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'call', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'boycott', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'boycott', 'word[-3:]': 'ott', 'word[-2:]': 'tt', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'boycott', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'peter', 'word[-3:]': 'ter', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'blackburn', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'blackburn', 'word[-3:]': 'urn', 'word[-2:]': 'rn', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'peter', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'brussels', 'word[-3:]': 'els', 'word[-2:]': 'ls', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '1996-08-22', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '1996-08-22', 'word[-3:]': '-22', 'word[-2:]': '22', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'brussels', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n",
            "[{'bias': 1.0, 'word.lower()': 'the', 'word[-3:]': 'the', 'word[-2:]': 'he', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': 'european', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'european', 'word[-3:]': 'ean', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'the', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'commission', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'commission', 'word[-3:]': 'ion', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'european', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'said', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'said', 'word[-3:]': 'aid', 'word[-2:]': 'id', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'commission', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'on', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'on', 'word[-3:]': 'on', 'word[-2:]': 'on', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'said', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'thursday', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'thursday', 'word[-3:]': 'day', 'word[-2:]': 'ay', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'on', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'it', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'it', 'word[-3:]': 'it', 'word[-2:]': 'it', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'thursday', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disagreed', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disagreed', 'word[-3:]': 'eed', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'it', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'with', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'with', 'word[-3:]': 'ith', 'word[-2:]': 'th', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disagreed', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'german', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'german', 'word[-3:]': 'man', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'with', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'advice', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'advice', 'word[-3:]': 'ice', 'word[-2:]': 'ce', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'german', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'advice', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'consumers', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'consumers', 'word[-3:]': 'ers', 'word[-2:]': 'rs', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'consumers', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'shun', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'shun', 'word[-3:]': 'hun', 'word[-2:]': 'un', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'british', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'british', 'word[-3:]': 'ish', 'word[-2:]': 'sh', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'shun', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'lamb', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'lamb', 'word[-3:]': 'amb', 'word[-2:]': 'mb', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'british', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'until', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'until', 'word[-3:]': 'til', 'word[-2:]': 'il', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'lamb', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'scientists', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'scientists', 'word[-3:]': 'sts', 'word[-2:]': 'ts', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'until', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'determine', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'determine', 'word[-3:]': 'ine', 'word[-2:]': 'ne', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'scientists', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'whether', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'whether', 'word[-3:]': 'her', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'determine', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'mad', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'mad', 'word[-3:]': 'mad', 'word[-2:]': 'ad', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'whether', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'cow', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'cow', 'word[-3:]': 'cow', 'word[-2:]': 'ow', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'mad', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'disease', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'disease', 'word[-3:]': 'ase', 'word[-2:]': 'se', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'cow', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'can', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'can', 'word[-3:]': 'can', 'word[-2:]': 'an', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'disease', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'be', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'be', 'word[-3:]': 'be', 'word[-2:]': 'be', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'can', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'transmitted', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'transmitted', 'word[-3:]': 'ted', 'word[-2:]': 'ed', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'be', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'to', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'to', 'word[-3:]': 'to', 'word[-2:]': 'to', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'transmitted', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': 'sheep', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': 'sheep', 'word[-3:]': 'eep', 'word[-2:]': 'ep', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'to', '-1:word.istitle()': False, '-1:word.isupper()': False, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, '-1:word.lower()': 'sheep', '-1:word.istitle()': False, '-1:word.isupper()': False, 'EOS': True}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2kJfNAS1N2",
        "colab_type": "code",
        "outputId": "5c516e3d-e349-4713-ac81-75b619535a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxUCHw5FXGt",
        "colab_type": "text"
      },
      "source": [
        "Because tag O (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag O when we evaluate classification metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGFs5K6EVC0R",
        "colab_type": "text"
      },
      "source": [
        "B: begining of ... \n",
        "I: identity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSnMwxl4UVPN",
        "colab_type": "code",
        "outputId": "963f5ef0-eb26-41fd-b169-d5a609141bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ner_train_set.remove('O')\n",
        "classes = ner_train_set\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-PER', 'I-MISC', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9jdSefS4id",
        "colab_type": "code",
        "outputId": "f560efa0-a976-49fd-c90b-8814c05df767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(features_val)\n",
        "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.93      0.80      0.86       875\n",
            "      I-MISC       0.83      0.63      0.72       187\n",
            "       I-LOC       0.89      0.85      0.87       419\n",
            "       I-ORG       0.85      0.58      0.69       285\n",
            "\n",
            "   micro avg       0.90      0.76      0.82      1766\n",
            "   macro avg       0.88      0.72      0.78      1766\n",
            "weighted avg       0.90      0.76      0.82      1766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3oWq_PnK8wk",
        "colab_type": "text"
      },
      "source": [
        "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40His-7UKyvp",
        "colab_type": "code",
        "outputId": "30b9a369-040d-48b9-e99b-3c2ec92964e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "I-PER  -> I-PER   3.403927\n",
            "I-ORG  -> I-ORG   3.384090\n",
            "I-MISC -> I-MISC  2.828140\n",
            "I-LOC  -> I-LOC   2.064296\n",
            "O      -> O       0.776679\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-PER  -> I-LOC   -2.677780\n",
            "I-PER  -> I-ORG   -2.689004\n",
            "I-LOC  -> I-PER   -3.410616\n",
            "I-ORG  -> I-LOC   -3.463856\n",
            "I-ORG  -> I-PER   -3.736825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQbtE0AYpvtX",
        "colab_type": "text"
      },
      "source": [
        "## Bi-LSTM CRF model\n",
        "\n",
        "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCqGvJchOdR",
        "colab_type": "text"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MWAK0NV3INF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert each unique word to the index\n",
        "word_to_ix = {}\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in ner_train_split + ner_val_split:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNgyvEADwYZt",
        "colab_type": "code",
        "outputId": "9d9cfd50-581a-4627-ba5a-239ff197b98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(len(word_list))\n",
        "for i in range(5):\n",
        "    print(word_list[i])\n",
        "    print(list(word_to_ix.values())[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "-docstart-\n",
            "0\n",
            "eu\n",
            "1\n",
            "rejects\n",
            "2\n",
            "german\n",
            "3\n",
            "call\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tndg_-ttwa6N",
        "colab_type": "code",
        "outputId": "1a61348d-031d-48d0-a2a3-3524b1dea832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrekRAbtxL2",
        "colab_type": "code",
        "outputId": "7ef1c2b6-ccb0-45c1-fa19-222d4d2dd569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(word_list), len(tag_to_ix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEswz2QjhXBM",
        "colab_type": "text"
      },
      "source": [
        "#### Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oz6KVyjsxM9",
        "colab_type": "code",
        "outputId": "fc950fb5-4d33-47d6-c7c2-11da671a9bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "# change a latest embedding!\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-50\") \n",
        "# word dimension\n",
        "EMBEDDING_DIM = 50\n",
        "embedding_matrix = []\n",
        "num_except = 0\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        num_except += 1\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlchZJO8hdXa",
        "colab_type": "text"
      },
      "source": [
        "#### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRs6mouFwEx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# use the index to represent each word in each sentence\n",
        "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
        "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
        "\n",
        "train_input_feature = get_feature(0, 2999)\n",
        "\n",
        "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
        "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
        "val_input_feature = get_feature(3000, 3699)\n",
        "\n",
        "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
        "test_input_feature = get_feature(3700, 7383)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEscWBrhjgb",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        \n",
        "\n",
        "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "        # Use nn.Embedding\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_3 = nn.LSTM(96, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "      \n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    # CRF: use the transition matrix to train our model\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    \n",
        "\n",
        "    def cal_self_attention(self, hidden, method):\n",
        "        # 1st type of calculation of the attention: Dot Product\n",
        "        if method == 'Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
        "          \n",
        "            attn_weights = F.softmax(a, dim=-1)\n",
        "           \n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "           \n",
        "\n",
        "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
        "        elif method == 'Scale Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
        "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "\n",
        "    def _get_lstm_features(self, sentence, features):\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # 96\n",
        "        features = features.view(len(features),1,-1)\n",
        "        # concat the word embedding with the word features\n",
        "        word_concat = torch.cat((embeds, features), dim = 2) # [1,1,96]\n",
        "\n",
        "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden) \n",
        "        \n",
        "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
        "        \n",
        "\n",
        "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden) \n",
        "        \n",
        "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')\n",
        "\n",
        "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
        "\n",
        "        \n",
        "        # change from 3 dimensions to 2 dimensions\n",
        "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    ''' Calculate the score for the viterbi decoding'''\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, features, tags):\n",
        "        feats = self._get_lstm_features(sentence, features)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    # sentence is a index expression of the words in the sentence \n",
        "    def forward(self, sentence, features):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, features)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNHEV1kiDKt",
        "colab_type": "text"
      },
      "source": [
        "#### Function for accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Moqs-zwboIn",
        "colab_type": "text"
      },
      "source": [
        "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def cal_acc(model, input_index, input_feature, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      ground_truth.extend(output_index[i])\n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      accuracy = accuracy_score(predicted, ground_truth)\n",
        "      \n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82UaXEOhoQQ",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UiokVOjPUn",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru",
        "colab_type": "code",
        "outputId": "e125f8c3-2851-4eba-90d0-d5f2d73a567f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 370s\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "for epoch in range(20): \n",
        "    epoch_list.append(epoch) \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "  \n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        # Use the forward pass\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    val_loss = 0\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
        "        val_loss+=loss.item()\n",
        "        \n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 11076.55, train acc: 0.9443, val loss: 1530.86, val acc: 0.9258, time: 243.30s\n",
            "Epoch:2, Training loss: 4537.64, train acc: 0.9479, val loss: 2311.89, val acc: 0.8851, time: 250.09s\n",
            "Epoch:3, Training loss: 2455.27, train acc: 0.9620, val loss: 2282.63, val acc: 0.8929, time: 244.54s\n",
            "Epoch:4, Training loss: 1553.56, train acc: 0.9739, val loss: 2028.96, val acc: 0.9145, time: 250.54s\n",
            "Epoch:5, Training loss: 1198.22, train acc: 0.9864, val loss: 1579.04, val acc: 0.9438, time: 246.39s\n",
            "Epoch:6, Training loss: 995.41, train acc: 0.9909, val loss: 1324.26, val acc: 0.9543, time: 246.21s\n",
            "Epoch:7, Training loss: 862.85, train acc: 0.9928, val loss: 1406.02, val acc: 0.9513, time: 241.24s\n",
            "Epoch:8, Training loss: 840.26, train acc: 0.9921, val loss: 1426.43, val acc: 0.9557, time: 241.95s\n",
            "Epoch:9, Training loss: 747.53, train acc: 0.9931, val loss: 1346.74, val acc: 0.9522, time: 242.28s\n",
            "Epoch:10, Training loss: 553.33, train acc: 0.9943, val loss: 1417.33, val acc: 0.9541, time: 242.52s\n",
            "Epoch:11, Training loss: 657.16, train acc: 0.9914, val loss: 1511.96, val acc: 0.9513, time: 239.17s\n",
            "Epoch:12, Training loss: 558.70, train acc: 0.9950, val loss: 1514.16, val acc: 0.9524, time: 241.64s\n",
            "Epoch:13, Training loss: 554.05, train acc: 0.9957, val loss: 1446.50, val acc: 0.9549, time: 239.87s\n",
            "Epoch:14, Training loss: 522.95, train acc: 0.9943, val loss: 1558.61, val acc: 0.9504, time: 239.41s\n",
            "Epoch:15, Training loss: 518.60, train acc: 0.9966, val loss: 1430.28, val acc: 0.9575, time: 241.66s\n",
            "Epoch:16, Training loss: 455.36, train acc: 0.9950, val loss: 1509.90, val acc: 0.9557, time: 241.39s\n",
            "Epoch:17, Training loss: 440.62, train acc: 0.9961, val loss: 1629.13, val acc: 0.9559, time: 242.96s\n",
            "Epoch:18, Training loss: 478.85, train acc: 0.9952, val loss: 1776.37, val acc: 0.9428, time: 241.82s\n",
            "Epoch:19, Training loss: 496.20, train acc: 0.9941, val loss: 1496.94, val acc: 0.9537, time: 243.64s\n",
            "Epoch:20, Training loss: 477.96, train acc: 0.9957, val loss: 1381.95, val acc: 0.9575, time: 244.20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVVLm4esLVJd",
        "colab_type": "code",
        "outputId": "f95ee260-4178-4b0b-9694-0e811fec1d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Please comment your code\n",
        "model = torch.load('Bilstm_crf_model10_2.pt')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(13972, 50)\n",
              "  (lstm_1): LSTM(400, 100, bidirectional=True)\n",
              "  (lstm_2): LSTM(400, 100, bidirectional=True)\n",
              "  (lstm_3): LSTM(96, 100, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=200, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpMDDzcXXzgd",
        "colab_type": "code",
        "outputId": "65eaa0a4-f769-4afd-a5f1-793b2b48fe90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7ANbv_jSzI",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAnJVsyPq5kR",
        "colab_type": "code",
        "outputId": "241d1450-44bd-4b88-eb6c-9792c706c12c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.7967    0.9165    0.8524       419\n",
            "      I-MISC     0.8022    0.7807    0.7913       187\n",
            "       I-ORG     0.8478    0.6842    0.7573       285\n",
            "       I-PER     0.9243    0.8926    0.9081       875\n",
            "           O     0.9838    0.9884    0.9861      5790\n",
            "\n",
            "    accuracy                         0.9567      7556\n",
            "   macro avg     0.8710    0.8525    0.8591      7556\n",
            "weighted avg     0.9569    0.9567    0.9562      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao_KMytuHgOB",
        "colab_type": "code",
        "outputId": "a6ebd10e-7aa5-4d4b-96bf-21ad1e347ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "torch.save(model, 'Bilstm_crf_model10_2.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vULrL_HFGrgt",
        "colab_type": "code",
        "outputId": "a0ac23c3-c082-4598-f0f4-a31490688171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(y_pred_decode[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "O\n",
            "O\n",
            "I-ORG\n",
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Vihry_Y3lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def leaderboard(model, input_index, input_feature):\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      \n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y0fX78Ysm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "test_pred_decode = decode_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7m0Mv2xaiq-",
        "colab_type": "code",
        "outputId": "83413bdd-8135-4d20-de32-bc0eeb1caf51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(test_pred_decode[i])\n",
        "print(len(test_pred_decode))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "O\n",
            "O\n",
            "I-LOC\n",
            "O\n",
            "46666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xqOcTPz3iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "co1 = []\n",
        "co2 = []\n",
        "for i in range(len(test_pred_decode)):\n",
        "    co1.append(i)\n",
        "    co2.append(test_pred_decode[i])\n",
        "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
        "leaderboard.to_csv(\"leaderboard11_3.csv\", index=False, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXGK44ibbYBp",
        "colab_type": "code",
        "outputId": "141873f7-b05d-4592-f5c2-cdd8bb577ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "da=pd.read_csv(\"leaderboard11_3.csv\")\n",
        "da.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>I-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Predicted\n",
              "0   0         O\n",
              "1   1         O\n",
              "2   2         O\n",
              "3   3     I-LOC\n",
              "4   4         O\n",
              "5   5     I-ORG\n",
              "6   6         O\n",
              "7   7         O\n",
              "8   8     I-LOC\n",
              "9   9         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}