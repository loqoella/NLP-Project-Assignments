{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKhhaHUvYgoa"
   },
   "source": [
    "# Named Entity Recognition + 3 bi-lstm + 2 self-attention + 2 features + Adam + lr = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xY4scQ1RUve"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwUrZvQakO2P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_val = pd.read_csv(\"val.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aK73yG9zfHbt",
    "outputId": "f0edbce1-9de7-4a05-b570-716754356fe1"
   },
   "outputs": [],
   "source": [
    "# create a list of Sentence and a list of NER\n",
    "\n",
    "sentences_train = df_train['Sentence'].tolist()\n",
    "ner_train = df_train['NER'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_train_split = []\n",
    "ner_train_split = []\n",
    "for each_sentence in sentences_train:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_train_split.append(each_sentence)\n",
    "\n",
    "for each_ner in ner_train:\n",
    "    each_ner = each_ner.split(\" \")\n",
    "    ner_train_split.append(each_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNInRtB7PDia"
   },
   "outputs": [],
   "source": [
    "sentences_val = df_val['Sentence'].tolist()\n",
    "ner_val = df_val['NER'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_val_split = []\n",
    "ner_val_split = []\n",
    "for each_sentence in sentences_val:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_val_split.append(each_sentence)\n",
    "\n",
    "for each_ner in ner_val:\n",
    "    each_ner = each_ner.split(\" \")\n",
    "    ner_val_split.append(each_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjohNx5IvRVZ"
   },
   "outputs": [],
   "source": [
    "# create a list of Sentence\n",
    "\n",
    "sentences_test = df_test['Sentence'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_test_split = []\n",
    "\n",
    "for each_sentence in sentences_test:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_test_split.append(each_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S049P4HVDJTc"
   },
   "outputs": [],
   "source": [
    "def read_data(file_name, n_sample):\n",
    "    f = open(file_name)\n",
    "    documents = f.readlines()\n",
    "    pos_data = []\n",
    "    pos = []\n",
    "    for i in documents:\n",
    "        if i == '\\n':   \n",
    "            pos_data.append(pos)\n",
    "            pos = []\n",
    "        else:    \n",
    "            pos.append(i.replace('\\n','').split(' ')[1])\n",
    "    return pos_data[:n_sample]\n",
    "\n",
    "pos_train = read_data(\"trainpos.txt\", 3000)\n",
    "pos_validation = read_data(\"valpos.txt\",700)\n",
    "pos_test = read_data(\"testpos.txt\",3684)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5gUSbrHQ6J2"
   },
   "source": [
    "# Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mH_xBcfvfQp-"
   },
   "outputs": [],
   "source": [
    "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MirHmtHeIcGp",
    "outputId": "696f80c7-e52f-4dd3-e378-dc509a72f777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93794\n",
      "13972\n"
     ]
    }
   ],
   "source": [
    "total_words = []\n",
    "for sentence in total_sentences:\n",
    "    for word in sentence:\n",
    "        total_words.append(word)\n",
    "\n",
    "print(len(total_words))\n",
    "print(len(set(total_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ezZdNCrEDCP"
   },
   "outputs": [],
   "source": [
    "\n",
    "total_pos_list = []\n",
    "\n",
    "for line in pos_train + pos_validation + pos_test:\n",
    "    pos_line = []\n",
    "    for each_pos in line:\n",
    "        pos_line.append(each_pos)\n",
    "    total_pos_list.append(pos_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gWQNSEP8HXtS",
    "outputId": "a9d5b414-17ee-4c57-8f53-458ebdea9d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
     ]
    }
   ],
   "source": [
    "pos_to_ix = {}\n",
    "pos_list = []\n",
    "for line in pos_train + pos_validation + pos_test:\n",
    "    for pos in line:\n",
    "        if pos not in pos_to_ix:\n",
    "            pos_to_ix[pos] = len(pos_to_ix)\n",
    "pos_list = sorted(list(pos_to_ix.keys()))\n",
    "\n",
    "pos_list_length = len(pos_list)\n",
    "print(pos_list_length)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "My7OPDfWVvnk",
    "outputId": "613add2e-ec2c-4b16-e59a-2cd4d294ca50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "# key is the pos tag, value is the one hot expression\n",
    "onehotpos = {}\n",
    "\n",
    "for i in range(pos_list_length):   \n",
    "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
    "    onehotpos[pos_list[i]] = list(onehot[0])\n",
    "\n",
    "print(onehotpos)\n",
    "\n",
    "def get_onehotpos(pos_sentence):\n",
    "    pos_list = []\n",
    "    for each_pos in pos_sentence:\n",
    "        onehot_pos = onehotpos[each_pos]\n",
    "        pos_list.append(onehot_pos)\n",
    "    return pos_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r14mferpb4dD"
   },
   "outputs": [],
   "source": [
    "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
    "sentence_to_pos = {}\n",
    "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
    "for i in range(total_length):\n",
    "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm1NsLQ3qlBP"
   },
   "source": [
    "## TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "f0XY3R9ePJOY",
    "outputId": "21f27612-a188-45d5-d784-5615eeb96292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13972\n",
      "7384\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "DF = {}\n",
    "\n",
    "for each_sentence in total_sentences:\n",
    "    for term in np.unique(each_sentence):\n",
    "        try:\n",
    "            DF[term] +=1\n",
    "        except:\n",
    "            DF[term] =1\n",
    "\n",
    "print(len(DF))\n",
    "\n",
    "\n",
    "tf_idf = {}\n",
    "N = total_length\n",
    "print(N)\n",
    "\n",
    "for i in range(N):\n",
    "    counter = Counter(total_sentences[i])\n",
    "    total_num_words = len(total_sentences[i])   \n",
    "    # the tfidf of all words in a sentence\n",
    "    each_sentence_tfidf = []\n",
    "    \n",
    "    for term in total_sentences[i]:\n",
    "        tf = counter[term]/total_num_words\n",
    "        df = DF[term]\n",
    "        idf = math.log(N/(df+1))+1\n",
    "        each_sentence_tfidf.append(tf*idf)\n",
    "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
    "    tf_idf[i] = each_sentence_tfidf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "F0WnqcLhCxNh",
    "outputId": "c2111ba9-72fa-473c-dc6f-e630e6bd0d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7867733572317377]\n",
      "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
      "[3.8549230994232344, 3.711082063197344]\n",
      "[3.236541785848771, 2.568193075858512]\n",
      "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(tf_idf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "jFq1dlZnO9mi",
    "outputId": "f9806dd5-cf96-4eb0-8b9c-ef52ef4c6dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "9 9\n",
      "2 2\n",
      "2 2\n",
      "30 30\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3DcyEtJ93fo"
   },
   "outputs": [],
   "source": [
    "def get_feature(from_feature_index, to_feature_index):\n",
    "    feature_list = []\n",
    "    for i in range(from_feature_index, to_feature_index+1): \n",
    "        sentence_feature_list = []\n",
    "        for j in range(len(sentence_to_pos[i])): \n",
    "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
    "        \n",
    "        feature_list.append(sentence_feature_list)\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "dF0Tv48EMi__",
    "outputId": "f79a7b65-aa19-4373-80b8-e6fefc76f357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_feature(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7og4EnAq8aG"
   },
   "source": [
    "## Distribution Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "sO-vnejvEDZ7",
    "outputId": "8fa30dd2-e43d-4372-93cf-c8010f096f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 7384 Largest length of the sentence: 124\n",
      "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentence_lengths = []\n",
    "for each_sentence in total_sentences:\n",
    "    length = len(each_sentence)\n",
    "    sentence_lengths.append(length)\n",
    "\n",
    "total_sentence_num = len(sentence_lengths)\n",
    "largest_length = max(sentence_lengths)\n",
    "mean_length = np.mean(sentence_lengths)\n",
    "counts_length = np.bincount(sentence_lengths)\n",
    "counts_length = np.argmax(counts_length)\n",
    "length_less_than_counts = 0\n",
    "length_less_than_mean = 0 \n",
    "length_less_than_15 = 0\n",
    "length_less_than_20 = 0\n",
    "length_less_than_25 = 0\n",
    "length_less_than_30 = 0\n",
    "\n",
    "for length in sentence_lengths:\n",
    "  if length < counts_length:\n",
    "    length_less_than_counts += 1\n",
    "  if length < mean_length:\n",
    "    length_less_than_mean += 1\n",
    "  if length < 15:\n",
    "    length_less_than_15 += 1\n",
    "  if length < 20:\n",
    "    length_less_than_20 += 1\n",
    "  if length < 25:\n",
    "    length_less_than_25 += 1\n",
    "  if length < 30:\n",
    "    length_less_than_30 += 1\n",
    "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
    "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
    "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
    "print(y_rate)\n",
    "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jFsK7PUsNox"
   },
   "source": [
    "There are 5 kinds of tag in total.\n",
    "\n",
    "'I-ORG': Organization\n",
    "\n",
    "'O': Other\n",
    "\n",
    "'I-LOC': Location \n",
    "\n",
    "'I-PER': Person \n",
    "\n",
    "'I-MISC': Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8-UMIHEKrgCw",
    "outputId": "f3cd30b4-e425-41f3-b247-96ba05824fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39572\n",
      "5\n",
      "['I-PER', 'I-MISC', 'O', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_train_list = []\n",
    "for each_ner in ner_train_split:\n",
    "    for each_tag in each_ner:\n",
    "        ner_train_list.append(each_tag)\n",
    "ner_train_set = list(set(ner_train_list))\n",
    "print(len(ner_train_list))\n",
    "print(len(ner_train_set))\n",
    "print(ner_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "7chjiqNYkzNK",
    "outputId": "26918c46-b4d7-4b42-8343-d284d6828f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7556\n",
      "5\n",
      "['I-PER', 'I-MISC', 'O', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_val_list = []\n",
    "for each_ner in ner_val_split:\n",
    "    for each_tag in each_ner:\n",
    "        ner_val_list.append(each_tag)\n",
    "ner_val_set = list(set(ner_val_list))\n",
    "print(len(ner_val_list))\n",
    "print(len(ner_val_set))\n",
    "print(ner_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "FDuagDgs1Yj4",
    "outputId": "69be7027-cc74-4655-bc07-3cd24a2226ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-ORG:   1526\n",
      "O:       32137\n",
      "I-LOC:   1994\n",
      "I-PER:   2840\n",
      "I-MISC:  1075\n"
     ]
    }
   ],
   "source": [
    "# count the number of each tag\n",
    "num_org = 0\n",
    "num_o = 0\n",
    "num_loc = 0\n",
    "num_per = 0\n",
    "num_misc = 0\n",
    "for i in ner_train_list:\n",
    "    if i=='I-ORG':\n",
    "        num_org += 1\n",
    "    if i=='O':\n",
    "        num_o += 1\n",
    "    if i=='I-LOC':\n",
    "        num_loc += 1\n",
    "    if i=='I-PER':\n",
    "        num_per += 1\n",
    "    if i=='I-MISC':\n",
    "        num_misc += 1\n",
    "print(\"I-ORG:  \", num_org)\n",
    "print(\"O:      \", num_o)\n",
    "print(\"I-LOC:  \", num_loc)\n",
    "print(\"I-PER:  \", num_per)\n",
    "print(\"I-MISC: \", num_misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "S_NXJRv7k__M",
    "outputId": "2817e9c6-05e3-401f-aae8-b26309f54662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-ORG:   285\n",
      "O:       5790\n",
      "I-LOC:   419\n",
      "I-PER:   875\n",
      "I-MISC:  187\n"
     ]
    }
   ],
   "source": [
    "# count the number of each tag\n",
    "num_org = 0\n",
    "num_o = 0\n",
    "num_loc = 0\n",
    "num_per = 0\n",
    "num_misc = 0\n",
    "for i in ner_val_list:\n",
    "    if i=='I-ORG':\n",
    "        num_org += 1\n",
    "    if i=='O':\n",
    "        num_o += 1\n",
    "    if i=='I-LOC':\n",
    "        num_loc += 1\n",
    "    if i=='I-PER':\n",
    "        num_per += 1\n",
    "    if i=='I-MISC':\n",
    "        num_misc += 1\n",
    "print(\"I-ORG:  \", num_org)\n",
    "print(\"O:      \", num_o)\n",
    "print(\"I-LOC:  \", num_loc)\n",
    "print(\"I-PER:  \", num_per)\n",
    "print(\"I-MISC: \", num_misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP9s9J-lDKUC"
   },
   "source": [
    "In the data, you can see the different types of entities: \n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfakfv0CRwAB"
   },
   "source": [
    "## Data Preprocessing\n",
    "There are too many NaN values in ‘Sentence #” column, fill NaN by preceding values.\n",
    "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pcu5O3OlEdPA"
   },
   "source": [
    "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "5EsvF8uXSgy5",
    "outputId": "8981e272-fc21-46de-8bd5-ad0b2462d1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in /opt/conda/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.8.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (1.14.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (4.45.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4F991p-IqNS"
   },
   "source": [
    "##Conditional random fields (CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-Xcf07iR79l"
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "NQPELELtSmYo",
    "outputId": "730f47d9-b8a1-4c4b-a558-234f7e5d289d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-docstart-', 'O')]\n",
      "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
      "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
      "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
      "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#Retrieving sentences with their tags in zip\n",
    "zip_sentences_train = []\n",
    "for line in range(len(sentence_train_split)):\n",
    "    combine_sentence = []\n",
    "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
    "        combine_sentence.append((each_word, each_tag))\n",
    "    zip_sentences_train.append(combine_sentence)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print(zip_sentences_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "RCJIH2emlP1y",
    "outputId": "2267da94-029a-431b-bd25-95883beaa04d"
   },
   "outputs": [],
   "source": [
    "#Retrieving sentences with their tags in zip\n",
    "zip_sentences_val = []\n",
    "for line in range(len(sentence_val_split)):\n",
    "    combine_sentence_val = []\n",
    "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
    "        combine_sentence_val.append((each_word, each_tag))\n",
    "    zip_sentences_val.append(combine_sentence_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alfVxIWIFEth"
   },
   "source": [
    "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bbaee897Sqoa"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    # postag = sent[i][1]\n",
    "    # a few features: upper? lower? title? \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:], # last three letters of the word\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(), \n",
    "        'word.istitle()': word.istitle(), # is it a title?\n",
    "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
    "       \n",
    "    }\n",
    "    # features of the previous word\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        # postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "          \n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    # features of the next word\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "       \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            \n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ME9Xu722SzYZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "features_train = [sent2features(s) for s in zip_sentences_train]\n",
    "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
    "\n",
    "features_val = [sent2features(s) for s in zip_sentences_val]\n",
    "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "3F2kJfNAS1N2",
    "outputId": "566d89e5-1525-4aa3-8446-7eace22f3c87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnxUCHw5FXGt"
   },
   "source": [
    "Because tag “O” (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag “O” when we evaluate classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGFs5K6EVC0R"
   },
   "source": [
    "B: begining of ... \n",
    "I: identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hSnMwxl4UVPN",
    "outputId": "8d533591-8f5f-41a2-b790-cbdc1ef145e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-PER', 'I-MISC', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_train_set.remove('O')\n",
    "classes = ner_train_set\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "9C9jdSefS4id",
    "outputId": "9b77e88e-a5a8-4cbd-d001-2533a65ea4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-PER       0.93      0.80      0.86       875\n",
      "      I-MISC       0.83      0.63      0.72       187\n",
      "       I-ORG       0.85      0.58      0.69       285\n",
      "       I-LOC       0.89      0.85      0.87       419\n",
      "\n",
      "   micro avg       0.90      0.76      0.82      1766\n",
      "   macro avg       0.88      0.72      0.78      1766\n",
      "weighted avg       0.90      0.76      0.82      1766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "y_pred = crf.predict(features_val)\n",
    "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3oWq_PnK8wk"
   },
   "source": [
    "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "40His-7UKyvp",
    "outputId": "956c8a42-6b78-4bae-d9b6-0ab7adf5fd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-PER  -> I-PER   3.403927\n",
      "I-ORG  -> I-ORG   3.384090\n",
      "I-MISC -> I-MISC  2.828140\n",
      "I-LOC  -> I-LOC   2.064296\n",
      "O      -> O       0.776679\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-PER  -> I-LOC   -2.677780\n",
      "I-PER  -> I-ORG   -2.689004\n",
      "I-LOC  -> I-PER   -3.410616\n",
      "I-ORG  -> I-LOC   -3.463856\n",
      "I-ORG  -> I-PER   -3.736825\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQbtE0AYpvtX"
   },
   "source": [
    "## Bi-LSTM CRF model\n",
    "\n",
    "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cCqGvJchOdR"
   },
   "source": [
    "#### Generate word_to_ix and tag_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MWAK0NV3INF"
   },
   "outputs": [],
   "source": [
    "# convert each unique word to the index\n",
    "word_to_ix = {}\n",
    "for sentence in total_sentences:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "word_list = list(word_to_ix.keys())\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
    "for tags in ner_train_split + ner_val_split:\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tndg_-ttwa6N",
    "outputId": "24b138a3-c5c3-49bd-aeba-cad4b60dfb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "print(tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ajrekRAbtxL2",
    "outputId": "c85a5f3f-3e9c-4d88-8467-8e0f08233b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13972 7\n"
     ]
    }
   ],
   "source": [
    "print(len(word_list), len(tag_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEswz2QjhXBM"
   },
   "source": [
    "#### Generate Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.13.19-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 70.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Collecting botocore<1.17.0,>=1.16.19\n",
      "  Downloading botocore-1.16.19-py2.py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 73.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 77.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=6addc80f7ae9db828ae8447852e0c8c519b2ef1bb5acf4d834b94af4cf30375b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/bb/1c/9c/412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
      "Successfully built smart-open\n",
      "Installing collected packages: docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed boto3-1.13.19 botocore-1.16.19 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "-Oz6KVyjsxM9",
    "outputId": "0f981765-1fa6-4555-8b43-530a3a3877db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13972, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "# change a latest embedding!\n",
    "word_emb_model = api.load(\"glove-wiki-gigaword-100\") \n",
    "# word dimension\n",
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = []\n",
    "num_except = 0\n",
    "for word in word_list:\n",
    "    try:\n",
    "        embedding_matrix.append(word_emb_model.wv[word])\n",
    "    except:\n",
    "        num_except += 1\n",
    "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
    "\n",
    "embedding_matrix = np.array(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "Y0Y5AOY80TXw",
    "outputId": "381c8abd-e7b4-41d6-bb07-ba9a978fb93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2019.8.19)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 41.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 86.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=dd6b1afbac578fee65fbe2d37284d739022df7e73e301b083358c3e1786a9f2a\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.5-py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.7/site-packages (from flair) (4.45.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.7/site-packages (from flair) (3.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from flair) (0.22.2.post1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from flair) (2019.8.19)\n",
      "Requirement already satisfied: transformers>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from flair) (2.10.0)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading bpemb-0.3.0-py3-none-any.whl (19 kB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[K     |████████████████████████████████| 788 kB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from flair) (0.8.7)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 36.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hyperopt>=0.1.1\n",
      "  Downloading hyperopt-0.2.4-py2.py3-none-any.whl (964 kB)\n",
      "\u001b[K     |████████████████████████████████| 964 kB 45.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytest>=5.3.2 in /opt/conda/lib/python3.7/site-packages (from flair) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from flair) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from flair) (3.8.3)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (3.0.10)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.1.91)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.0.43)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->flair) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (2.0.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2020.4.5.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=2.10.0->flair) (7.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=5.3.2->flair) (3.1.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (1.13.19)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (1.16.19)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.15.2)\n",
      "Building wheels for collected packages: segtok, mpld3, sqlitedict, langdetect\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25019 sha256=fe72bfceedd0318c40b008810f174e7d950f1090ac3050600ecbc11d0ac85f53\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=bce77c7f4df3afedc360c6753c63eb246636907eeb59beb2c2e01f6069893ddc\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14688 sha256=be41790b349150f2be32a328c3eab82f4789174bdbd739317b6be1cbc6a0b99f\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/58/dd/2c/0a57aadf6a7f26bec0af66d742c50af74d11967780f0bb7a7d\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=172c95021d4f54495660226bfc289600de21f3416bfb315044afbc02c156d97e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\n",
      "Successfully built segtok mpld3 sqlitedict langdetect\n",
      "Installing collected packages: bpemb, segtok, mpld3, sqlitedict, langdetect, hyperopt, deprecated, flair\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 hyperopt-0.2.4 langdetect-1.0.8 mpld3-0.3 segtok-1.5.10 sqlitedict-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7384/7384 [01:59<00:00, 61.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "bert_emb_model = TransformerWordEmbeddings('bert-base-uncased')\n",
    "\n",
    "bert_embeddings = []\n",
    "for each_sentence in tqdm(total_sentences):\n",
    "    sentence_bert_emb = []\n",
    "    each_sentence = \" \".join(each_sentence)\n",
    "    each_sentence = Sentence(each_sentence)\n",
    "    # for each sentence\n",
    "    bert_emb_model.embed(each_sentence)\n",
    "    for word in each_sentence:\n",
    "        sentence_bert_emb.append(word.embedding)\n",
    "    \n",
    "    bert_embeddings.append(sentence_bert_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_feature(from_feature_index, to_feature_index):\n",
    "    feature_list = []\n",
    "    for i in range(from_feature_index, to_feature_index+1): \n",
    "        bert_feature_list = []\n",
    "        for j in range(len(bert_embeddings[i])): \n",
    "            a =  bert_embeddings[i][j]\n",
    "            a = a.cpu().numpy()\n",
    "            a = list(a)\n",
    "            bert_feature_list.append(a)\n",
    "        \n",
    "        feature_list.append(bert_feature_list)\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlchZJO8hdXa"
   },
   "source": [
    "#### convert dataset into idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRs6mouFwEx4"
   },
   "outputs": [],
   "source": [
    "def to_index(data, to_ix):\n",
    "    input_index_list = []\n",
    "    for sent in data:\n",
    "        input_index_list.append([to_ix[w] for w in sent])\n",
    "    return input_index_list\n",
    "\n",
    "# use the index to represent each word in each sentence\n",
    "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
    "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
    "\n",
    "\n",
    "train_input_feature = get_bert_feature(0, 2999)\n",
    "\n",
    "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
    "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
    "# val_input_feature = get_feature(3000, 3699)\n",
    "\n",
    "val_input_feature = get_bert_feature(3000, 3699)\n",
    "\n",
    "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
    "# test_input_feature = get_feature(3700, 7383)\n",
    "test_input_feature = get_bert_feature(3700, 7383)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXEscWBrhjgb"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5AgRWakkfmT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "\n",
    "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
    "        # Use nn.Embedding\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
    "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_3 = nn.LSTM(100+3072, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "      \n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
    "    \n",
    "    # CRF: use the transition matrix to train our model\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of the previous tag\n",
    "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    # Attention Calculation: two methods\n",
    "\n",
    "    def cal_self_attention(self, hidden, method):\n",
    "        # 1st type of calculation of the attention: Dot Product\n",
    "        if method == 'Dot Product':\n",
    "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
    "            # print(\"hidden1 \"+str(hidden1.shape))\n",
    "            # print(\"hidden2 \"+str(hidden2.shape))\n",
    "            # print(\"a shape \" + str(a.shape)) \n",
    "          \n",
    "            attn_weights = F.softmax(a, dim = -1)\n",
    "            # print(\"attn_weights\" + str(attn_weights.shape)) # [1, seq, 50]\n",
    "            # attn_weights = F.softmax(torch.bmm(hidden1, hidden2), dim=-1)\n",
    "            # print(\"hidden2.u\" + str((hidden2).shape))\n",
    "            attn_output = torch.bmm(attn_weights, hidden) \n",
    "            concat_output = torch.cat((attn_output, hidden), -1)\n",
    "            # print(concat_output,concat_output.size())\n",
    "\n",
    "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
    "        elif method == 'Scale Dot Product':\n",
    "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
    "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
    "            attn_output = torch.bmm(attn_weights, hidden) \n",
    "            concat_output = torch.cat((attn_output, hidden), -1)\n",
    "\n",
    "        return concat_output\n",
    "\n",
    "\n",
    "    def _get_lstm_features(self, sentence, features):\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        features = features.view(len(features),1,-1)\n",
    "        # concat the word embedding with the word features\n",
    "        word_concat = torch.cat((embeds, features), dim = 2) \n",
    "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden)        \n",
    "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
    "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden)         \n",
    "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')       \n",
    "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
    "     \n",
    "        # change from 3 dimensions to 2 dimensions\n",
    "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    ''' Calculate the score for the viterbi decoding'''\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).to(device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, features, tags):\n",
    "        feats = self._get_lstm_features(sentence, features)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    # sentence is a index expression of the words in the sentence \n",
    "    def forward(self, sentence, features):  \n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence, features)\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUNHEV1kiDKt"
   },
   "source": [
    "#### Function for accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Moqs-zwboIn"
   },
   "source": [
    "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJmu0oSsjLBm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def cal_acc(model, input_index, input_feature, output_index):\n",
    "    ground_truth = []\n",
    "    predicted = []\n",
    "    for i in range(len(input_index)):\n",
    "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
    "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
    "      # add elements of tuple to list\n",
    "      ground_truth.extend(output_index[i])\n",
    "      _, outputs = model(input_index_tensor, input_feature_float)\n",
    "      predicted.extend(outputs)\n",
    "      accuracy = accuracy_score(predicted, ground_truth)\n",
    "      \n",
    "    return ground_truth, predicted, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_82UaXEOhoQQ"
   },
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuzZ_et6FD7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9UiokVOjPUn"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "a0CMFVSwlLru",
    "outputId": "5111ab2e-3305-46ff-f1db-3cb6ef007012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss: 39118.37, train acc: 0.8025, val loss: 6178.21, val acc: 0.7586, time: 292.43s\n",
      "Epoch:2, Training loss: 25450.14, train acc: 0.8134, val loss: 4830.81, val acc: 0.7673, time: 291.46s\n",
      "Epoch:3, Training loss: 18503.27, train acc: 0.8612, val loss: 3014.89, val acc: 0.8409, time: 290.47s\n",
      "Epoch:4, Training loss: 11945.49, train acc: 0.9169, val loss: 2007.53, val acc: 0.9219, time: 292.48s\n",
      "Epoch:5, Training loss: 8757.81, train acc: 0.9333, val loss: 1492.49, val acc: 0.9342, time: 292.75s\n",
      "Epoch:6, Training loss: 6779.26, train acc: 0.9488, val loss: 1180.98, val acc: 0.9463, time: 293.50s\n",
      "Epoch:7, Training loss: 5356.74, train acc: 0.9635, val loss: 978.37, val acc: 0.9592, time: 292.71s\n",
      "Epoch:8, Training loss: 4227.07, train acc: 0.9728, val loss: 823.05, val acc: 0.9688, time: 290.60s\n",
      "Epoch:9, Training loss: 3350.58, train acc: 0.9804, val loss: 716.31, val acc: 0.9727, time: 293.93s\n",
      "Epoch:10, Training loss: 2675.65, train acc: 0.9860, val loss: 658.81, val acc: 0.9754, time: 292.56s\n",
      "Epoch:11, Training loss: 2102.93, train acc: 0.9894, val loss: 602.71, val acc: 0.9764, time: 292.51s\n",
      "Epoch:12, Training loss: 1675.15, train acc: 0.9922, val loss: 567.67, val acc: 0.9772, time: 293.60s\n",
      "Epoch:13, Training loss: 1310.46, train acc: 0.9940, val loss: 539.71, val acc: 0.9794, time: 293.96s\n",
      "Epoch:14, Training loss: 1047.62, train acc: 0.9958, val loss: 526.45, val acc: 0.9794, time: 294.11s\n",
      "Epoch:15, Training loss: 785.19, train acc: 0.9973, val loss: 523.34, val acc: 0.9805, time: 292.67s\n",
      "Epoch:16, Training loss: 599.30, train acc: 0.9979, val loss: 523.35, val acc: 0.9801, time: 290.26s\n",
      "Epoch:17, Training loss: 470.12, train acc: 0.9987, val loss: 532.19, val acc: 0.9807, time: 291.25s\n",
      "Epoch:18, Training loss: 360.45, train acc: 0.9990, val loss: 533.89, val acc: 0.9825, time: 292.34s\n",
      "Epoch:19, Training loss: 292.99, train acc: 0.9993, val loss: 545.62, val acc: 0.9812, time: 293.29s\n",
      "Epoch:20, Training loss: 221.36, train acc: 0.9994, val loss: 547.44, val acc: 0.9819, time: 291.45s\n",
      "Epoch:21, Training loss: 181.46, train acc: 0.9995, val loss: 552.22, val acc: 0.9824, time: 290.74s\n",
      "Epoch:22, Training loss: 143.78, train acc: 0.9997, val loss: 563.32, val acc: 0.9829, time: 290.26s\n",
      "Epoch:23, Training loss: 113.67, train acc: 0.9997, val loss: 565.70, val acc: 0.9828, time: 292.81s\n",
      "Epoch:24, Training loss: 90.03, train acc: 0.9997, val loss: 585.49, val acc: 0.9827, time: 292.82s\n",
      "Epoch:25, Training loss: 76.12, train acc: 0.9998, val loss: 599.71, val acc: 0.9827, time: 292.92s\n",
      "Epoch:26, Training loss: 58.53, train acc: 0.9998, val loss: 623.04, val acc: 0.9823, time: 292.77s\n",
      "Epoch:27, Training loss: 43.74, train acc: 0.9999, val loss: 619.70, val acc: 0.9824, time: 292.84s\n",
      "Epoch:28, Training loss: 33.29, train acc: 0.9999, val loss: 656.22, val acc: 0.9820, time: 293.53s\n",
      "Epoch:29, Training loss: 26.84, train acc: 0.9999, val loss: 657.69, val acc: 0.9816, time: 294.44s\n",
      "Epoch:30, Training loss: 19.16, train acc: 0.9999, val loss: 667.93, val acc: 0.9823, time: 292.17s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Each epoch will take about 370s\"\"\"\n",
    "\n",
    "import datetime\n",
    "epoch_list = []\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(30):  \n",
    "    epoch_list.append(epoch) \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    # i: index; idxs: word\n",
    "    for i, idxs in enumerate(train_input_index):\n",
    "        tags_index = train_output_index[i]\n",
    "\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "  \n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
    "        \n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        # Use the forward pass\n",
    "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "    train_loss_list.append(train_loss)\n",
    "    model.eval()\n",
    "    \n",
    "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
    "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
    "\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_loss = 0\n",
    "    # i: index; idxs: word\n",
    "    for i, idxs in enumerate(val_input_index):\n",
    "        tags_index = val_output_index[i]\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
    "        val_loss+=loss.item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
    "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
    "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uj7ANbv_jSzI"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIh-mWrvi6Pw"
   },
   "outputs": [],
   "source": [
    "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
    "\n",
    "def decode_output(output_list):\n",
    "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "    return [ix_to_tag[output] for output in output_list]\n",
    "\n",
    "y_true_decode = decode_output(y_true)\n",
    "y_pred_decode = decode_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "VAnJVsyPq5kR",
    "outputId": "df269a97-67de-4aad-8079-0e87b68c7dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC     0.9371    0.9594    0.9481       419\n",
      "      I-MISC     0.8690    0.7807    0.8225       187\n",
      "       I-ORG     0.9634    0.8316    0.8927       285\n",
      "       I-PER     0.9841    0.9909    0.9875       875\n",
      "           O     0.9894    0.9965    0.9929      5790\n",
      "\n",
      "    accuracy                         0.9823      7556\n",
      "   macro avg     0.9486    0.9118    0.9287      7556\n",
      "weighted avg     0.9819    0.9823    0.9818      7556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ao_KMytuHgOB",
    "outputId": "8219cac3-3d19-4850-fe9d-8307831e729c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'Bilstm_crf_bert3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "vULrL_HFGrgt",
    "outputId": "e03dcd60-b9bd-4a58-d618-5a43b2c2331b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "O\n",
      "O\n",
      "I-ORG\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(y_pred_decode[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84Vihry_Y3lP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def leaderboard(model, input_index, input_feature):\n",
    "    predicted = []\n",
    "    for i in range(len(input_index)):\n",
    "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
    "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
    "      # add elements of tuple to list\n",
    "      \n",
    "      _, outputs = model(input_index_tensor, input_feature_float)\n",
    "      predicted.extend(outputs)\n",
    "      \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0Y0fX78Ysm7"
   },
   "outputs": [],
   "source": [
    "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
    "\n",
    "def decode_output(output_list):\n",
    "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "    return [ix_to_tag[output] for output in output_list]\n",
    "\n",
    "test_pred_decode = decode_output(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2xqOcTPz3iU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "co1 = []\n",
    "co2 = []\n",
    "for i in range(len(test_pred_decode)):\n",
    "    co1.append(i)\n",
    "    co2.append(test_pred_decode[i])\n",
    "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
    "leaderboard.to_csv(\"leaderboard_bert3.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (word_embeds): Embedding(13972, 100)\n",
       "  (lstm_1): LSTM(200, 50, bidirectional=True)\n",
       "  (lstm_2): LSTM(200, 50, bidirectional=True)\n",
       "  (lstm_3): LSTM(3172, 50, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=100, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A2_Bilstm_crf_BERT.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
