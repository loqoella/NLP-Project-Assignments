{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKhhaHUvYgoa"
   },
   "source": [
    "# Named Entity Recognition + 3 bi-lstm + 2 self-attention + 2 features + Adam + lr = 0.00001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xY4scQ1RUve"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwUrZvQakO2P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_val = pd.read_csv(\"val.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aK73yG9zfHbt",
    "outputId": "f0edbce1-9de7-4a05-b570-716754356fe1"
   },
   "outputs": [],
   "source": [
    "# create a list of Sentence and a list of NER\n",
    "\n",
    "sentences_train = df_train['Sentence'].tolist()\n",
    "ner_train = df_train['NER'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_train_split = []\n",
    "ner_train_split = []\n",
    "for each_sentence in sentences_train:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_train_split.append(each_sentence)\n",
    "\n",
    "for each_ner in ner_train:\n",
    "    each_ner = each_ner.split(\" \")\n",
    "    ner_train_split.append(each_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNInRtB7PDia"
   },
   "outputs": [],
   "source": [
    "sentences_val = df_val['Sentence'].tolist()\n",
    "ner_val = df_val['NER'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_val_split = []\n",
    "ner_val_split = []\n",
    "for each_sentence in sentences_val:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_val_split.append(each_sentence)\n",
    "\n",
    "for each_ner in ner_val:\n",
    "    each_ner = each_ner.split(\" \")\n",
    "    ner_val_split.append(each_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjohNx5IvRVZ"
   },
   "outputs": [],
   "source": [
    "# create a list of Sentence\n",
    "\n",
    "sentences_test = df_test['Sentence'].tolist()\n",
    "\n",
    "# split each sentence by \" \"\n",
    "sentence_test_split = []\n",
    "\n",
    "for each_sentence in sentences_test:\n",
    "    each_sentence = each_sentence.split(\" \")\n",
    "    sentence_test_split.append(each_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S049P4HVDJTc"
   },
   "outputs": [],
   "source": [
    "def read_data(file_name, n_sample):\n",
    "    f = open(file_name)\n",
    "    documents = f.readlines()\n",
    "    pos_data = []\n",
    "    pos = []\n",
    "    for i in documents:\n",
    "        if i == '\\n':   \n",
    "            pos_data.append(pos)\n",
    "            pos = []\n",
    "        else:    \n",
    "            pos.append(i.replace('\\n','').split(' ')[1])\n",
    "    return pos_data[:n_sample]\n",
    "\n",
    "pos_train = read_data(\"trainpos.txt\", 3000)\n",
    "pos_validation = read_data(\"valpos.txt\",700)\n",
    "pos_test = read_data(\"testpos.txt\",3684)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5gUSbrHQ6J2"
   },
   "source": [
    "# Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mH_xBcfvfQp-"
   },
   "outputs": [],
   "source": [
    "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MirHmtHeIcGp",
    "outputId": "696f80c7-e52f-4dd3-e378-dc509a72f777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93794\n",
      "13972\n"
     ]
    }
   ],
   "source": [
    "total_words = []\n",
    "for sentence in total_sentences:\n",
    "    for word in sentence:\n",
    "        total_words.append(word)\n",
    "\n",
    "print(len(total_words))\n",
    "print(len(set(total_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ezZdNCrEDCP"
   },
   "outputs": [],
   "source": [
    "\n",
    "total_pos_list = []\n",
    "\n",
    "for line in pos_train + pos_validation + pos_test:\n",
    "    pos_line = []\n",
    "    for each_pos in line:\n",
    "        pos_line.append(each_pos)\n",
    "    total_pos_list.append(pos_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gWQNSEP8HXtS",
    "outputId": "a9d5b414-17ee-4c57-8f53-458ebdea9d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
     ]
    }
   ],
   "source": [
    "pos_to_ix = {}\n",
    "pos_list = []\n",
    "for line in pos_train + pos_validation + pos_test:\n",
    "    for pos in line:\n",
    "        if pos not in pos_to_ix:\n",
    "            pos_to_ix[pos] = len(pos_to_ix)\n",
    "pos_list = sorted(list(pos_to_ix.keys()))\n",
    "\n",
    "pos_list_length = len(pos_list)\n",
    "print(pos_list_length)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "My7OPDfWVvnk",
    "outputId": "613add2e-ec2c-4b16-e59a-2cd4d294ca50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "# key is the pos tag, value is the one hot expression\n",
    "onehotpos = {}\n",
    "\n",
    "for i in range(pos_list_length):   \n",
    "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
    "    onehotpos[pos_list[i]] = list(onehot[0])\n",
    "\n",
    "print(onehotpos)\n",
    "\n",
    "def get_onehotpos(pos_sentence):\n",
    "    pos_list = []\n",
    "    for each_pos in pos_sentence:\n",
    "        onehot_pos = onehotpos[each_pos]\n",
    "        pos_list.append(onehot_pos)\n",
    "    return pos_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r14mferpb4dD"
   },
   "outputs": [],
   "source": [
    "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
    "sentence_to_pos = {}\n",
    "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
    "for i in range(total_length):\n",
    "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm1NsLQ3qlBP"
   },
   "source": [
    "## TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "f0XY3R9ePJOY",
    "outputId": "21f27612-a188-45d5-d784-5615eeb96292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13972\n",
      "7384\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "DF = {}\n",
    "\n",
    "for each_sentence in total_sentences:\n",
    "    for term in np.unique(each_sentence):\n",
    "        try:\n",
    "            DF[term] +=1\n",
    "        except:\n",
    "            DF[term] =1\n",
    "\n",
    "print(len(DF))\n",
    "\n",
    "\n",
    "tf_idf = {}\n",
    "N = total_length\n",
    "print(N)\n",
    "\n",
    "for i in range(N):\n",
    "    counter = Counter(total_sentences[i])\n",
    "    total_num_words = len(total_sentences[i])   \n",
    "    # the tfidf of all words in a sentence\n",
    "    each_sentence_tfidf = []\n",
    "    \n",
    "    for term in total_sentences[i]:\n",
    "        tf = counter[term]/total_num_words\n",
    "        df = DF[term]\n",
    "        idf = math.log(N/(df+1))+1\n",
    "        each_sentence_tfidf.append(tf*idf)\n",
    "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
    "    tf_idf[i] = each_sentence_tfidf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "F0WnqcLhCxNh",
    "outputId": "c2111ba9-72fa-473c-dc6f-e630e6bd0d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7867733572317377]\n",
      "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
      "[3.8549230994232344, 3.711082063197344]\n",
      "[3.236541785848771, 2.568193075858512]\n",
      "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(tf_idf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "jFq1dlZnO9mi",
    "outputId": "f9806dd5-cf96-4eb0-8b9c-ef52ef4c6dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "9 9\n",
      "2 2\n",
      "2 2\n",
      "30 30\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3DcyEtJ93fo"
   },
   "outputs": [],
   "source": [
    "def get_feature(from_feature_index, to_feature_index):\n",
    "    feature_list = []\n",
    "    for i in range(from_feature_index, to_feature_index+1): \n",
    "        sentence_feature_list = []\n",
    "        for j in range(len(sentence_to_pos[i])): \n",
    "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
    "        \n",
    "        feature_list.append(sentence_feature_list)\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "dF0Tv48EMi__",
    "outputId": "f79a7b65-aa19-4373-80b8-e6fefc76f357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_feature(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7og4EnAq8aG"
   },
   "source": [
    "## Distribution Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "sO-vnejvEDZ7",
    "outputId": "8fa30dd2-e43d-4372-93cf-c8010f096f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 7384 Largest length of the sentence: 124\n",
      "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentence_lengths = []\n",
    "for each_sentence in total_sentences:\n",
    "    length = len(each_sentence)\n",
    "    sentence_lengths.append(length)\n",
    "\n",
    "total_sentence_num = len(sentence_lengths)\n",
    "largest_length = max(sentence_lengths)\n",
    "mean_length = np.mean(sentence_lengths)\n",
    "counts_length = np.bincount(sentence_lengths)\n",
    "counts_length = np.argmax(counts_length)\n",
    "length_less_than_counts = 0\n",
    "length_less_than_mean = 0 \n",
    "length_less_than_15 = 0\n",
    "length_less_than_20 = 0\n",
    "length_less_than_25 = 0\n",
    "length_less_than_30 = 0\n",
    "\n",
    "for length in sentence_lengths:\n",
    "  if length < counts_length:\n",
    "    length_less_than_counts += 1\n",
    "  if length < mean_length:\n",
    "    length_less_than_mean += 1\n",
    "  if length < 15:\n",
    "    length_less_than_15 += 1\n",
    "  if length < 20:\n",
    "    length_less_than_20 += 1\n",
    "  if length < 25:\n",
    "    length_less_than_25 += 1\n",
    "  if length < 30:\n",
    "    length_less_than_30 += 1\n",
    "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
    "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
    "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
    "print(y_rate)\n",
    "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jFsK7PUsNox"
   },
   "source": [
    "There are 5 kinds of tag in total.\n",
    "\n",
    "'I-ORG': Organization\n",
    "\n",
    "'O': Other\n",
    "\n",
    "'I-LOC': Location \n",
    "\n",
    "'I-PER': Person \n",
    "\n",
    "'I-MISC': Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8-UMIHEKrgCw",
    "outputId": "f3cd30b4-e425-41f3-b247-96ba05824fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39572\n",
      "5\n",
      "['I-PER', 'I-MISC', 'O', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_train_list = []\n",
    "for each_ner in ner_train_split:\n",
    "    for each_tag in each_ner:\n",
    "        ner_train_list.append(each_tag)\n",
    "ner_train_set = list(set(ner_train_list))\n",
    "print(len(ner_train_list))\n",
    "print(len(ner_train_set))\n",
    "print(ner_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "7chjiqNYkzNK",
    "outputId": "26918c46-b4d7-4b42-8343-d284d6828f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7556\n",
      "5\n",
      "['I-PER', 'I-MISC', 'O', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_val_list = []\n",
    "for each_ner in ner_val_split:\n",
    "    for each_tag in each_ner:\n",
    "        ner_val_list.append(each_tag)\n",
    "ner_val_set = list(set(ner_val_list))\n",
    "print(len(ner_val_list))\n",
    "print(len(ner_val_set))\n",
    "print(ner_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "FDuagDgs1Yj4",
    "outputId": "69be7027-cc74-4655-bc07-3cd24a2226ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-ORG:   1526\n",
      "O:       32137\n",
      "I-LOC:   1994\n",
      "I-PER:   2840\n",
      "I-MISC:  1075\n"
     ]
    }
   ],
   "source": [
    "# count the number of each tag\n",
    "num_org = 0\n",
    "num_o = 0\n",
    "num_loc = 0\n",
    "num_per = 0\n",
    "num_misc = 0\n",
    "for i in ner_train_list:\n",
    "    if i=='I-ORG':\n",
    "        num_org += 1\n",
    "    if i=='O':\n",
    "        num_o += 1\n",
    "    if i=='I-LOC':\n",
    "        num_loc += 1\n",
    "    if i=='I-PER':\n",
    "        num_per += 1\n",
    "    if i=='I-MISC':\n",
    "        num_misc += 1\n",
    "print(\"I-ORG:  \", num_org)\n",
    "print(\"O:      \", num_o)\n",
    "print(\"I-LOC:  \", num_loc)\n",
    "print(\"I-PER:  \", num_per)\n",
    "print(\"I-MISC: \", num_misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "S_NXJRv7k__M",
    "outputId": "2817e9c6-05e3-401f-aae8-b26309f54662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-ORG:   285\n",
      "O:       5790\n",
      "I-LOC:   419\n",
      "I-PER:   875\n",
      "I-MISC:  187\n"
     ]
    }
   ],
   "source": [
    "# count the number of each tag\n",
    "num_org = 0\n",
    "num_o = 0\n",
    "num_loc = 0\n",
    "num_per = 0\n",
    "num_misc = 0\n",
    "for i in ner_val_list:\n",
    "    if i=='I-ORG':\n",
    "        num_org += 1\n",
    "    if i=='O':\n",
    "        num_o += 1\n",
    "    if i=='I-LOC':\n",
    "        num_loc += 1\n",
    "    if i=='I-PER':\n",
    "        num_per += 1\n",
    "    if i=='I-MISC':\n",
    "        num_misc += 1\n",
    "print(\"I-ORG:  \", num_org)\n",
    "print(\"O:      \", num_o)\n",
    "print(\"I-LOC:  \", num_loc)\n",
    "print(\"I-PER:  \", num_per)\n",
    "print(\"I-MISC: \", num_misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP9s9J-lDKUC"
   },
   "source": [
    "In the data, you can see the different types of entities: \n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wfakfv0CRwAB"
   },
   "source": [
    "## Data Preprocessing\n",
    "There are too many NaN values in Sentence # column, fill NaN by preceding values.\n",
    "We have 47595 sentences that contain 35172 unique words and tagged by 17 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pcu5O3OlEdPA"
   },
   "source": [
    "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. As mentioned before, MEMM or CRF is often used for labeling or parsing of sequential data for named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "5EsvF8uXSgy5",
    "outputId": "8981e272-fc21-46de-8bd5-ad0b2462d1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in /opt/conda/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.8.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (1.14.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (4.45.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4F991p-IqNS"
   },
   "source": [
    "##Conditional random fields (CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-Xcf07iR79l"
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "NQPELELtSmYo",
    "outputId": "730f47d9-b8a1-4c4b-a558-234f7e5d289d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-docstart-', 'O')]\n",
      "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
      "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
      "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
      "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#Retrieving sentences with their tags in zip\n",
    "zip_sentences_train = []\n",
    "for line in range(len(sentence_train_split)):\n",
    "    combine_sentence = []\n",
    "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
    "        combine_sentence.append((each_word, each_tag))\n",
    "    zip_sentences_train.append(combine_sentence)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print(zip_sentences_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "RCJIH2emlP1y",
    "outputId": "2267da94-029a-431b-bd25-95883beaa04d"
   },
   "outputs": [],
   "source": [
    "#Retrieving sentences with their tags in zip\n",
    "zip_sentences_val = []\n",
    "for line in range(len(sentence_val_split)):\n",
    "    combine_sentence_val = []\n",
    "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
    "        combine_sentence_val.append((each_word, each_tag))\n",
    "    zip_sentences_val.append(combine_sentence_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alfVxIWIFEth"
   },
   "source": [
    "We extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite formateach sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bbaee897Sqoa"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    # postag = sent[i][1]\n",
    "    # a few features: upper? lower? title? \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:], # last three letters of the word\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(), \n",
    "        'word.istitle()': word.istitle(), # is it a title?\n",
    "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
    "       \n",
    "    }\n",
    "    # features of the previous word\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        # postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "          \n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    # features of the next word\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "       \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            \n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ME9Xu722SzYZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "features_train = [sent2features(s) for s in zip_sentences_train]\n",
    "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
    "\n",
    "features_val = [sent2features(s) for s in zip_sentences_val]\n",
    "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "3F2kJfNAS1N2",
    "outputId": "566d89e5-1525-4aa3-8446-7eace22f3c87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnxUCHw5FXGt"
   },
   "source": [
    "Because tag O (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag O when we evaluate classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGFs5K6EVC0R"
   },
   "source": [
    "B: begining of ... \n",
    "I: identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hSnMwxl4UVPN",
    "outputId": "8d533591-8f5f-41a2-b790-cbdc1ef145e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-PER', 'I-MISC', 'I-ORG', 'I-LOC']\n"
     ]
    }
   ],
   "source": [
    "ner_train_set.remove('O')\n",
    "classes = ner_train_set\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "9C9jdSefS4id",
    "outputId": "9b77e88e-a5a8-4cbd-d001-2533a65ea4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-PER       0.93      0.80      0.86       875\n",
      "      I-MISC       0.83      0.63      0.72       187\n",
      "       I-ORG       0.85      0.58      0.69       285\n",
      "       I-LOC       0.89      0.85      0.87       419\n",
      "\n",
      "   micro avg       0.90      0.76      0.82      1766\n",
      "   macro avg       0.88      0.72      0.78      1766\n",
      "weighted avg       0.90      0.76      0.82      1766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "y_pred = crf.predict(features_val)\n",
    "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3oWq_PnK8wk"
   },
   "source": [
    "The following shows what our classifier learned. It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "40His-7UKyvp",
    "outputId": "956c8a42-6b78-4bae-d9b6-0ab7adf5fd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-PER  -> I-PER   3.403927\n",
      "I-ORG  -> I-ORG   3.384090\n",
      "I-MISC -> I-MISC  2.828140\n",
      "I-LOC  -> I-LOC   2.064296\n",
      "O      -> O       0.776679\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-PER  -> I-LOC   -2.677780\n",
      "I-PER  -> I-ORG   -2.689004\n",
      "I-LOC  -> I-PER   -3.410616\n",
      "I-ORG  -> I-LOC   -3.463856\n",
      "I-ORG  -> I-PER   -3.736825\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQbtE0AYpvtX"
   },
   "source": [
    "## Bi-LSTM CRF model\n",
    "\n",
    "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. Please go through and complete the [Function for accuracy] section. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cCqGvJchOdR"
   },
   "source": [
    "#### Generate word_to_ix and tag_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MWAK0NV3INF"
   },
   "outputs": [],
   "source": [
    "# convert each unique word to the index\n",
    "word_to_ix = {}\n",
    "for sentence in total_sentences:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "word_list = list(word_to_ix.keys())\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
    "for tags in ner_train_split + ner_val_split:\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tndg_-ttwa6N",
    "outputId": "24b138a3-c5c3-49bd-aeba-cad4b60dfb16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "print(tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ajrekRAbtxL2",
    "outputId": "c85a5f3f-3e9c-4d88-8467-8e0f08233b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13972 7\n"
     ]
    }
   ],
   "source": [
    "print(len(word_list), len(tag_to_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEswz2QjhXBM"
   },
   "source": [
    "#### Generate Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     || 24.2 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "\u001b[K     || 103 kB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.13.19-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     || 128 kB 70.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Collecting botocore<1.17.0,>=1.16.19\n",
      "  Downloading botocore-1.16.19-py2.py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     || 6.2 MB 73.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     || 69 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     || 547 kB 77.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=6addc80f7ae9db828ae8447852e0c8c519b2ef1bb5acf4d834b94af4cf30375b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/bb/1c/9c/412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
      "Successfully built smart-open\n",
      "Installing collected packages: docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed boto3-1.13.19 botocore-1.16.19 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "-Oz6KVyjsxM9",
    "outputId": "0f981765-1fa6-4555-8b43-530a3a3877db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13972, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "# change a latest embedding!\n",
    "word_emb_model = api.load(\"glove-wiki-gigaword-100\") \n",
    "# word dimension\n",
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = []\n",
    "num_except = 0\n",
    "for word in word_list:\n",
    "    try:\n",
    "        embedding_matrix.append(word_emb_model.wv[word])\n",
    "    except:\n",
    "        num_except += 1\n",
    "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
    "\n",
    "embedding_matrix = np.array(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "Y0Y5AOY80TXw",
    "outputId": "381c8abd-e7b4-41d6-bb07-ba9a978fb93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n",
      "\u001b[K     || 660 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2019.8.19)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     || 1.1 MB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     || 5.6 MB 41.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     || 883 kB 86.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=dd6b1afbac578fee65fbe2d37284d739022df7e73e301b083358c3e1786a9f2a\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.5-py3-none-any.whl (334 kB)\n",
      "\u001b[K     || 334 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.7/site-packages (from flair) (4.45.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.7/site-packages (from flair) (3.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from flair) (0.22.2.post1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from flair) (2019.8.19)\n",
      "Requirement already satisfied: transformers>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from flair) (2.10.0)\n",
      "Collecting bpemb>=0.2.9\n",
      "  Downloading bpemb-0.3.0-py3-none-any.whl (19 kB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[K     || 788 kB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from flair) (0.8.7)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     || 981 kB 36.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hyperopt>=0.1.1\n",
      "  Downloading hyperopt-0.2.4-py2.py3-none-any.whl (964 kB)\n",
      "\u001b[K     || 964 kB 45.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytest>=5.3.2 in /opt/conda/lib/python3.7/site-packages (from flair) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from flair) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from flair) (3.8.3)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (3.0.10)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.1.91)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.0.43)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->flair) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (2.0.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2020.4.5.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=2.10.0->flair) (7.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=5.3.2->flair) (3.1.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (1.13.19)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (1.16.19)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.15.2)\n",
      "Building wheels for collected packages: segtok, mpld3, sqlitedict, langdetect\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25019 sha256=fe72bfceedd0318c40b008810f174e7d950f1090ac3050600ecbc11d0ac85f53\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=bce77c7f4df3afedc360c6753c63eb246636907eeb59beb2c2e01f6069893ddc\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14688 sha256=be41790b349150f2be32a328c3eab82f4789174bdbd739317b6be1cbc6a0b99f\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/58/dd/2c/0a57aadf6a7f26bec0af66d742c50af74d11967780f0bb7a7d\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=172c95021d4f54495660226bfc289600de21f3416bfb315044afbc02c156d97e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\n",
      "Successfully built segtok mpld3 sqlitedict langdetect\n",
      "Installing collected packages: bpemb, segtok, mpld3, sqlitedict, langdetect, hyperopt, deprecated, flair\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 hyperopt-0.2.4 langdetect-1.0.8 mpld3-0.3 segtok-1.5.10 sqlitedict-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7384/7384 [01:59<00:00, 61.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "bert_emb_model = TransformerWordEmbeddings('bert-base-uncased')\n",
    "\n",
    "bert_embeddings = []\n",
    "for each_sentence in tqdm(total_sentences):\n",
    "    sentence_bert_emb = []\n",
    "    each_sentence = \" \".join(each_sentence)\n",
    "    each_sentence = Sentence(each_sentence)\n",
    "    # for each sentence\n",
    "    bert_emb_model.embed(each_sentence)\n",
    "    for word in each_sentence:\n",
    "        sentence_bert_emb.append(word.embedding)\n",
    "    \n",
    "    bert_embeddings.append(sentence_bert_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_feature(from_feature_index, to_feature_index):\n",
    "    feature_list = []\n",
    "    for i in range(from_feature_index, to_feature_index+1): \n",
    "        bert_feature_list = []\n",
    "        for j in range(len(bert_embeddings[i])): \n",
    "            a =  bert_embeddings[i][j]\n",
    "            a = a.cpu().numpy()\n",
    "            a = list(a)\n",
    "            bert_feature_list.append(a)\n",
    "        \n",
    "        feature_list.append(bert_feature_list)\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlchZJO8hdXa"
   },
   "source": [
    "#### convert dataset into idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRs6mouFwEx4"
   },
   "outputs": [],
   "source": [
    "def to_index(data, to_ix):\n",
    "    input_index_list = []\n",
    "    for sent in data:\n",
    "        input_index_list.append([to_ix[w] for w in sent])\n",
    "    return input_index_list\n",
    "\n",
    "# use the index to represent each word in each sentence\n",
    "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
    "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
    "\n",
    "\n",
    "train_input_feature = get_bert_feature(0, 2999)\n",
    "\n",
    "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
    "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
    "# val_input_feature = get_feature(3000, 3699)\n",
    "\n",
    "val_input_feature = get_bert_feature(3000, 3699)\n",
    "\n",
    "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
    "# test_input_feature = get_feature(3700, 7383)\n",
    "test_input_feature = get_bert_feature(3700, 7383)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXEscWBrhjgb"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5AgRWakkfmT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "\n",
    "        # self.multihead_attn2 = nn.MultiheadAttention(embedding_dim, 2)\n",
    "        # Use nn.Embedding\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
    "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "\n",
    "        # self.multiheadattn1 = nn.MultiheadAttention(embedding_dim, 2)\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_3 = nn.LSTM(100+3072, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "      \n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
    "    \n",
    "    # CRF: use the transition matrix to train our model\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of the previous tag\n",
    "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    # Attention Calculation: two methods\n",
    "\n",
    "    def cal_self_attention(self, hidden, method):\n",
    "        # 1st type of calculation of the attention: Dot Product\n",
    "        if method == 'Dot Product':\n",
    "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
    "            # print(\"hidden1 \"+str(hidden1.shape))\n",
    "            # print(\"hidden2 \"+str(hidden2.shape))\n",
    "            # print(\"a shape \" + str(a.shape)) \n",
    "          \n",
    "            attn_weights = F.softmax(a, dim = -1)\n",
    "            # print(\"attn_weights\" + str(attn_weights.shape)) # [1, seq, 50]\n",
    "            # attn_weights = F.softmax(torch.bmm(hidden1, hidden2), dim=-1)\n",
    "            # print(\"hidden2.u\" + str((hidden2).shape))\n",
    "            attn_output = torch.bmm(attn_weights, hidden) \n",
    "            concat_output = torch.cat((attn_output, hidden), -1)\n",
    "            # print(concat_output,concat_output.size())\n",
    "\n",
    "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
    "        elif method == 'Scale Dot Product':\n",
    "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
    "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
    "            attn_output = torch.bmm(attn_weights, hidden) \n",
    "            concat_output = torch.cat((attn_output, hidden), -1)\n",
    "\n",
    "        return concat_output\n",
    "\n",
    "\n",
    "    def _get_lstm_features(self, sentence, features):\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        features = features.view(len(features),1,-1)\n",
    "        # concat the word embedding with the word features\n",
    "        word_concat = torch.cat((embeds, features), dim = 2) \n",
    "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden)        \n",
    "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Dot Product')\n",
    "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden)         \n",
    "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Dot Product')       \n",
    "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
    "     \n",
    "        # change from 3 dimensions to 2 dimensions\n",
    "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    ''' Calculate the score for the viterbi decoding'''\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).to(device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, features, tags):\n",
    "        feats = self._get_lstm_features(sentence, features)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    # sentence is a index expression of the words in the sentence \n",
    "    def forward(self, sentence, features):  \n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence, features)\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUNHEV1kiDKt"
   },
   "source": [
    "#### Function for accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Moqs-zwboIn"
   },
   "source": [
    "Please complete the cal_acc function that generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. You can refer to the [Train the model] section regarding what the inputs and outputs are and how it will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJmu0oSsjLBm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def cal_acc(model, input_index, input_feature, output_index):\n",
    "    ground_truth = []\n",
    "    predicted = []\n",
    "    for i in range(len(input_index)):\n",
    "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
    "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
    "      # add elements of tuple to list\n",
    "      ground_truth.extend(output_index[i])\n",
    "      _, outputs = model(input_index_tensor, input_feature_float)\n",
    "      predicted.extend(outputs)\n",
    "      accuracy = accuracy_score(predicted, ground_truth)\n",
    "      \n",
    "    return ground_truth, predicted, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_82UaXEOhoQQ"
   },
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuzZ_et6FD7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9UiokVOjPUn"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "a0CMFVSwlLru",
    "outputId": "5111ab2e-3305-46ff-f1db-3cb6ef007012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss: 39118.37, train acc: 0.8025, val loss: 6178.21, val acc: 0.7586, time: 292.43s\n",
      "Epoch:2, Training loss: 25450.14, train acc: 0.8134, val loss: 4830.81, val acc: 0.7673, time: 291.46s\n",
      "Epoch:3, Training loss: 18503.27, train acc: 0.8612, val loss: 3014.89, val acc: 0.8409, time: 290.47s\n",
      "Epoch:4, Training loss: 11945.49, train acc: 0.9169, val loss: 2007.53, val acc: 0.9219, time: 292.48s\n",
      "Epoch:5, Training loss: 8757.81, train acc: 0.9333, val loss: 1492.49, val acc: 0.9342, time: 292.75s\n",
      "Epoch:6, Training loss: 6779.26, train acc: 0.9488, val loss: 1180.98, val acc: 0.9463, time: 293.50s\n",
      "Epoch:7, Training loss: 5356.74, train acc: 0.9635, val loss: 978.37, val acc: 0.9592, time: 292.71s\n",
      "Epoch:8, Training loss: 4227.07, train acc: 0.9728, val loss: 823.05, val acc: 0.9688, time: 290.60s\n",
      "Epoch:9, Training loss: 3350.58, train acc: 0.9804, val loss: 716.31, val acc: 0.9727, time: 293.93s\n",
      "Epoch:10, Training loss: 2675.65, train acc: 0.9860, val loss: 658.81, val acc: 0.9754, time: 292.56s\n",
      "Epoch:11, Training loss: 2102.93, train acc: 0.9894, val loss: 602.71, val acc: 0.9764, time: 292.51s\n",
      "Epoch:12, Training loss: 1675.15, train acc: 0.9922, val loss: 567.67, val acc: 0.9772, time: 293.60s\n",
      "Epoch:13, Training loss: 1310.46, train acc: 0.9940, val loss: 539.71, val acc: 0.9794, time: 293.96s\n",
      "Epoch:14, Training loss: 1047.62, train acc: 0.9958, val loss: 526.45, val acc: 0.9794, time: 294.11s\n",
      "Epoch:15, Training loss: 785.19, train acc: 0.9973, val loss: 523.34, val acc: 0.9805, time: 292.67s\n",
      "Epoch:16, Training loss: 599.30, train acc: 0.9979, val loss: 523.35, val acc: 0.9801, time: 290.26s\n",
      "Epoch:17, Training loss: 470.12, train acc: 0.9987, val loss: 532.19, val acc: 0.9807, time: 291.25s\n",
      "Epoch:18, Training loss: 360.45, train acc: 0.9990, val loss: 533.89, val acc: 0.9825, time: 292.34s\n",
      "Epoch:19, Training loss: 292.99, train acc: 0.9993, val loss: 545.62, val acc: 0.9812, time: 293.29s\n",
      "Epoch:20, Training loss: 221.36, train acc: 0.9994, val loss: 547.44, val acc: 0.9819, time: 291.45s\n",
      "Epoch:21, Training loss: 181.46, train acc: 0.9995, val loss: 552.22, val acc: 0.9824, time: 290.74s\n",
      "Epoch:22, Training loss: 143.78, train acc: 0.9997, val loss: 563.32, val acc: 0.9829, time: 290.26s\n",
      "Epoch:23, Training loss: 113.67, train acc: 0.9997, val loss: 565.70, val acc: 0.9828, time: 292.81s\n",
      "Epoch:24, Training loss: 90.03, train acc: 0.9997, val loss: 585.49, val acc: 0.9827, time: 292.82s\n",
      "Epoch:25, Training loss: 76.12, train acc: 0.9998, val loss: 599.71, val acc: 0.9827, time: 292.92s\n",
      "Epoch:26, Training loss: 58.53, train acc: 0.9998, val loss: 623.04, val acc: 0.9823, time: 292.77s\n",
      "Epoch:27, Training loss: 43.74, train acc: 0.9999, val loss: 619.70, val acc: 0.9824, time: 292.84s\n",
      "Epoch:28, Training loss: 33.29, train acc: 0.9999, val loss: 656.22, val acc: 0.9820, time: 293.53s\n",
      "Epoch:29, Training loss: 26.84, train acc: 0.9999, val loss: 657.69, val acc: 0.9816, time: 294.44s\n",
      "Epoch:30, Training loss: 19.16, train acc: 0.9999, val loss: 667.93, val acc: 0.9823, time: 292.17s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Each epoch will take about 370s\"\"\"\n",
    "\n",
    "import datetime\n",
    "epoch_list = []\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(30):  \n",
    "    epoch_list.append(epoch) \n",
    "    time1 = datetime.datetime.now()\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    # i: index; idxs: word\n",
    "    for i, idxs in enumerate(train_input_index):\n",
    "        tags_index = train_output_index[i]\n",
    "\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "  \n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
    "        \n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        # Use the forward pass\n",
    "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "    train_loss_list.append(train_loss)\n",
    "    model.eval()\n",
    "    \n",
    "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
    "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
    "\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_loss = 0\n",
    "    # i: index; idxs: word\n",
    "    for i, idxs in enumerate(val_input_index):\n",
    "        tags_index = val_output_index[i]\n",
    "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
    "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
    "        val_loss+=loss.item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    time2 = datetime.datetime.now()\n",
    "\n",
    "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZxU1Zn/8c+XZmkQQVZFljQqdmSz1ZZgmAguKCqIJGpwJcZI4piJiRlHzUwSEsdoXKI/EjWD0QSMCTKokbiLStAMURuDCq4oKI3IIosgi9A8vz/OKaguqvdqqqvreb9e91W3zl3quVXd9dQ9595zZGY455xzAC2yHYBzzrmmw5OCc865XTwpOOec28WTgnPOuV08KTjnnNvFk4JzzrldPCm4jJL0uKQJmV43myQtlXRiI+x3jqRvxfnzJD1Vm3Xr8Tp9JG2SVFDfWF3+8KTgiF8YiWmnpC1Jz8+ry77M7BQzm5rpdZsiSddImpumvKukzyUNrO2+zOw+MzspQ3FVSmJm9qGZtTezikzsP+W1TNIhmd6vyx5PCo74hdHezNoDHwJjksruS6wnqWX2omyS7gW+LKlvSvl44HUzW5iFmJxrEE8KrkqSRkgql3SVpI+B30vqJOkRSaslrYvzvZK2Sa4S+YakFyTdHNddIumUeq7bV9JcSRslzZZ0u6Q/VhF3bWK8VtLf4/6ektQ1afkFkj6Q9Imk/6zq/TGzcuBZ4IKURRcCU2uKIyXmb0h6Ien5SElvSdog6TeAkpYdLOnZGN8aSfdJ2i8uuxfoA/w1nun9h6Si+Iu+ZVznQEmzJK2VtFjSJUn7niRphqRp8b1ZJKm0qvegKpI6xn2sju/lf0lqEZcdIulv8djWSLo/lkvSrZJWxWWv1eVsy2WGJwVXkwOAzsAXgImEv5nfx+d9gC3Ab6rZ/kvA20BX4Ebgbkmqx7p/Al4CugCT2POLOFltYjwXuAjoDrQG/h1AUn/gzrj/A+Prpf0ij6YmxyKpGCgB/lzLOPYQE9QDwH8R3ov3gGHJqwDXx/gOA3oT3hPM7AIqn+3dmOYl/gyUx+3PBH4h6YSk5acD04H9gFm1iTmNXwMdgYOA4YREeVFcdi3wFNCJ8N7+OpafBBwLHBpf++vAJ/V4bdcQZuaTT7smYClwYpwfAXwOFFazfgmwLun5HOBbcf4bwOKkZe0AAw6oy7qEL9QdQLuk5X8E/ljLY0oX438lPf9X4Ik4/xNgetKyfeJ7cGIV+24HfAp8OT6/Dni4nu/VC3H+QuAfSeuJ8CX+rSr2ewbwz3SfYXxeFN/LloQEUgHsm7T8euAPcX4SMDtpWX9gSzXvrQGHpJQVANuA/kll3wbmxPlpwBSgV8p2xwPvAEOBFtn+X8jXyc8UXE1Wm9nWxBNJ7ST9T6wS+BSYC+ynqq9s+TgxY2ab42z7Oq57ILA2qQxgWVUB1zLGj5PmNyfFdGDyvs3sM6r5tRpj+l/gwnhWcx7h7KE+71VCagyW/FxSd0nTJS2P+/0j4YyiNhLv5caksg+AnknPU9+bQtWtPakr4ezrgype4z8Iie6lWD31TQAze5ZwVnI7sFLSFEkd6vC6LgM8KbiapHaj+0OgGPiSmXUgnO5DUp13I1gBdJbULqmsdzXrNyTGFcn7jq/ZpYZtpgJnAyOBfYFHGhhHagyi8vFeT/hcBsf9np+yz+q6Pv6I8F7um1TWB1heQ0x1sQbYTqg22+M1zOxjM7vEzA4knEHcoXgFk5lNNrOjgAGEaqQrMxiXqwVPCq6u9iXUja+X1Bn4aWO/oJl9AJQBkyS1lnQMMKaRYpwJjJb0L5JaAz+n5v+T54H1hCqR6Wb2eQPjeBQYIOmr8Rf69wjVaAn7Apvifnuy5xfnSkJd/h7MbBnwf8D1kgolDQYuBu5Lt34ttY77KpRUGMtmANdJ2lfSF4ArCGc0SDorqcF9HSGJVUg6WtKXJLUCPgO2Eqq63F7kScHV1W1AW8KvwX8AT+yl1z0POIZQlfPfwP2Eeut06h2jmS0CLiM0bK8gfGmV17CNEerJvxAfGxSHma0BzgJuIBxvP+DvSav8DDgS2EBIIA+m7OJ64L8krZf072le4hxCO8NHwEPAT83s6drEVoVFhOSXmC4C/o3wxf4+8ALh/bwnrn808KKkTYSG7MvNbAnQAbiL8J5/QDj2mxsQl6sHxQYe53JKvIzxLTNr9DMV5/KJnym4nBCrFg6W1ELSKGAs8Jdsx+Vcc+N3qLpccQChmqQLoTrnUjP7Z3ZDcq758eoj55xzu3j1kXPOuV1ytvqoa9euVlRUlO0wnHMup8yfP3+NmXWrannOJoWioiLKysqyHYZzzuUUSR9Ut9yrj5xzzu1S66QgqUDSPyU9Ep93lvS0pHfjY6ekda+JXfK+LenkpPKjJL0el01O9IApqY2k+2P5i5KKMneIzjnnaqsuZwqXA28mPb8aeMbM+gHPxOeJrofHE/ouGUXo1yTRAdidhO6X+8VpVCy/mNB75CHArcAv63U0zjnnGqRWbQqxn5LTCN0CXxGLxxK6VobQIdgc4KpYPt3MtgFLJC0GhkhaCnQws3lxn9MIXf4+HreZFPc1E/iNJJlfL+tcXtq+fTvl5eVs3bq15pVdWoWFhfTq1YtWrVrVabvaNjTfRujuNrlnxf3NbAWAma2Q1D2W9yT085JQHsu2U7kPmUR5YptlcV87JG0g3KS0JjkISRMJZxr06dOnlqE753JNeXk5++67L0VFRVQ9JpOripnxySefUF5eTt++qaPFVq/G6iNJo4FVZja/lvtM9wlaNeXVbVO5wGyKmZWaWWm3blVeUeWcy3Fbt26lS5cunhDqSRJdunSp15lWbc4UhgGnSzoVKAQ6KIyNu1JSj3iW0ANYFdcvp3Lf770IvTGWU3lYw0R58jblsavgjsDaOh+Nc67Z8ITQMPV9/2o8UzCza8ysl5kVERqQnzWz8wld3k6Iq00AHo7zs4Dx8YqivoQG5ZdiVdNGSUPjVUcXpmyT2NeZ8TUapT3h73+Ha64Bb61wzrk9NeQ+hRuAkZLeJYw4dQPs6o9+BvAGof/4y8wsMVDGpcDvgMWEwcgfj+V3A11io/QVxCuZGsP8+XDDDbBqVc3rOufy0/r167njjjvqte2pp57K+vXra73+pEmTuPnmpjNsRJ3uaDazOYSrjDCzT4ATqljvOsKVSqnlZcDANOVbCYOKNLpDDw2Pb78N+++/N17ROZdrEknhX//1X/dYVlFRQUFB1cNsP/bYY40ZWqPLuzuai4vD49tvZzcO51zTdfXVV/Pee+9RUlLClVdeyZw5czjuuOM499xzGTRoEABnnHEGRx11FAMGDGDKlCm7ti0qKmLNmjUsXbqUww47jEsuuYQBAwZw0kknsWXLlmpfd8GCBQwdOpTBgwczbtw41q1bB8DkyZPp378/gwcPZvz48QD87W9/o6SkhJKSEo444gg2btyYkWPP2b6P6qtPH2jTxpOCc7ni+9+HBQsyu8+SErjttqqX33DDDSxcuJAF8YXnzJnDSy+9xMKFC3dd4nnPPffQuXNntmzZwtFHH83XvvY1unTpUmk/7777Ln/+85+56667OPvss3nggQc4//zzq3zdCy+8kF//+tcMHz6cn/zkJ/zsZz/jtttu44YbbmDJkiW0adNmV9XUzTffzO23386wYcPYtGkThYWFVe63LvLuTKGgAPr186TgnKubIUOGVLrmf/LkyRx++OEMHTqUZcuW8e677+6xTd++fSkpKQHgqKOOYunSpVXuf8OGDaxfv57hw4cDMGHCBObOnQvA4MGDOe+88/jjH/9Iy5bht/ywYcO44oormDx5MuvXr99V3lB5d6YAoQrptdeyHYVzrjaq+0W/N+2zzz675ufMmcPs2bOZN28e7dq1Y8SIEWnvCWjTps2u+YKCghqrj6ry6KOPMnfuXGbNmsW1117LokWLuPrqqznttNN47LHHGDp0KLNnz+aLX/xivfafLO/OFCAkhfffh+3bsx2Jc64p2nfffauto9+wYQOdOnWiXbt2vPXWW/zjH/+oct3a6tixI506deL5558H4N5772X48OHs3LmTZcuWcdxxx3HjjTeyfv16Nm3axHvvvcegQYO46qqrKC0t5a233mpwDJDHZwoVFSExJBqenXMuoUuXLgwbNoyBAwdyyimncNppp1VaPmrUKH77298yePBgiouLGTp0aEZed+rUqXznO99h8+bNHHTQQfz+97+noqKC888/nw0bNmBm/OAHP2C//fbjxz/+Mc899xwFBQX079+fU045JSMx5OwYzaWlpVbfQXZefBGGDoWHH4bTT89wYM65BnvzzTc57LDDsh1Gzkv3Pkqab2alVW2Tl9VHyfcqOOec2y0vk0KnTtCtmycF55xLlZdJAUJbgicF55yrzJOCc865XfI6KaxeDfEucuecc+R5UgA/W3DOuWR5nxTeeSe7cTjnmof27dvXqbypytukcNBB0LKlnyk451yyvE0KrVqFxOBJwTmX6qqrrqo0yM6kSZO45ZZb2LRpEyeccAJHHnkkgwYN4uGHH65mL5WZGVdeeSUDBw5k0KBB3H///QCsWLGCY489lpKSEgYOHMjzzz9PRUUF3/jGN3ate+utt2b8GKtSYzcXkgqBuUCbuP5MM/uppEnAJcDquOqPzOyxuM01wMVABfA9M3sylh8F/AFoCzwGXG5mJqkNMA04CvgE+LqZLc3QMVbJr0ByLgdkoe/s8ePH8/3vf3/XIDszZszgiSeeoLCwkIceeogOHTqwZs0ahg4dyumnn16r8ZAffPBBFixYwKuvvsqaNWs4+uijOfbYY/nTn/7EySefzH/+539SUVHB5s2bWbBgAcuXL2fhwoUAdRrJraFq0/fRNuB4M9skqRXwgqTEMJq3mlmlceQk9SeM5TwAOBCYLenQOCTnncBE4B+EpDCKMCTnxcA6MztE0njgl8DXG3541Tv0UHjqqdAPUjUDKTnn8swRRxzBqlWr+Oijj1i9ejWdOnWiT58+bN++nR/96EfMnTuXFi1asHz5clauXMkBBxxQ4z5feOEFzjnnHAoKCth///0ZPnw4L7/8MkcffTTf/OY32b59O2eccQYlJSUcdNBBvP/++/zbv/0bp512GieddNJeOOqgxqRgoXOkTfFpqzhV12HSWGC6mW0DlsRxl4dIWgp0MLN5AJKmAWcQksJYYFLcfibwG0myRu6YqbgYtm2DDz+EpG7SnXNNSZb6zj7zzDOZOXMmH3/88a7Rzu677z5Wr17N/PnzadWqFUVFRWm7zE6nqq+zY489lrlz5/Loo49ywQUXcOWVV3LhhRfy6quv8uSTT3L77bczY8YM7rnnnowdW3Vq1aYgqUDSAmAV8LSZvRgXfVfSa5LukdQplvUEliVtXh7Lesb51PJK25jZDmADUHkIoxDHREllkspWr16durjO/LJU51xVxo8fz/Tp05k5cyZnnnkmELrM7t69O61ateK5557jgw8+qPX+jj32WO6//34qKipYvXo1c+fOZciQIXzwwQd0796dSy65hIsvvphXXnmFNWvWsHPnTr72ta9x7bXX8sorrzTWYe6hVl1nx6qfEkn7AQ9JGkioCrqWcNZwLXAL8E0gXeWaVVNODcuS45gCTIHQS2ptYq9OclIYNaqhe3PONScDBgxg48aN9OzZkx49egBw3nnnMWbMGEpLSykpKanToDbjxo1j3rx5HH744Ujixhtv5IADDmDq1KncdNNNtGrVivbt2zNt2jSWL1/ORRddxM6dOwG4/vrrG+UY06nTeApmtl7SHGBUcluCpLuAR+LTcqB30ma9gI9iea805cnblEtqCXQE1tYltvro3h06dvQzBedceq+//nql5127dmXevHlp1920aVO15ZK46aabuOmmmyotnzBhAhMmTNhju715dpCsxuojSd3iGQKS2gInAm9J6pG02jhgYZyfBYyX1EZSX6Af8JKZrQA2Shqq0FR/IfBw0jaJd+VM4NnGbk8AkMLZgt/A5pxzQW3OFHoAUyUVEJLIDDN7RNK9kkoI1TxLgW8DmNkiSTOAN4AdwGWx+gngUnZfkvp4nADuBu6NjdJrCVcv7RXFxfDcc3vr1ZxzrmmrzdVHrwFHpCm/oJptrgOuS1NeBgxMU74VOKumWBpDcTHcey989hkkjcvtnMsyM6vV9f8uvfpWtuTtHc0JiVHYvArJuaajsLCQTz75pN5fbPnOzPjkk08oLCys87Z1amhujpKvQDpij/Mh51w29OrVi/LycjJx6Xm+KiwspFevXjWvmCLvk0K/fqHB2a9Acq7paNWqFX39jtKsyPvqo7ZtoU8fTwrOOQeeFADvGM855xI8KbD7XgVv03LO5TtPCoSksGkTrFiR7Uiccy67PCngHeM551yCJwU8KTjnXIInBaBnz3AVkicF51y+86QAtGgR7mz2pOCcy3eeFCK/LNU55zwp7FJcDEuXhuE5nXMuX3lSiIqLYedOWLw425E451z2eFKI/Aok55zzpLCLd6HtnHO1G46zUNJLkl6VtEjSz2J5Z0lPS3o3PnZK2uYaSYslvS3p5KTyoyS9HpdNjsNyEofuvD+WvyipKPOHWr0OHaBHDz9TcM7lt9qcKWwDjjezw4ESYJSkocDVwDNm1g94Jj5HUn/CcJoDgFHAHXEoT4A7gYmEcZv7xeUAFwPrzOwQ4Fbglxk4tjrzK5Ccc/muxqRgwab4tFWcDBgLTI3lU4Ez4vxYYLqZbTOzJcBiYIikHkAHM5tnYTilaSnbJPY1EzhBWRiHz+9VcM7lu1q1KUgqkLQAWAU8bWYvAvub2QqA+Ng9rt4TWJa0eXks6xnnU8srbWNmO4ANQJc0cUyUVCaprDFGZCouhrVrYc2ajO/aOedyQq2SgplVmFkJ0Ivwq39gNaun+4Vv1ZRXt01qHFPMrNTMSrt161ZT2HXmVyA55/Jdna4+MrP1wBxCW8DKWCVEfFwVVysHeidt1gv4KJb3SlNeaRtJLYGOwNq6xJYJnhScc/muNlcfdZO0X5xvC5wIvAXMAibE1SYAD8f5WcD4eEVRX0KD8kuximmjpKGxveDClG0S+zoTeDa2O+xVRUXQqpUnBedc/mpZi3V6AFPjFUQtgBlm9oikecAMSRcDHwJnAZjZIkkzgDeAHcBlZlYR93Up8AegLfB4nADuBu6VtJhwhjA+EwdXVy1bwiGHeFJwzuUvZeEHeUaUlpZaWVlZxvc7blxICm+8kfFdO+dc1kmab2alVS33O5pTFBeH/o927Mh2JM45t/d5UkhRXAzbt4ceU51zLt94UkiR6APJ2xWcc/nIk0IKvyzVOZfPPCmk6NoVOnf2pOCcy0+eFNLwjvGcc/nKk0IanhScc/nKk0IaxcXw8cfw6afZjsQ55/YuTwppJBqbfRQ251y+8aSQhl+B5JzLV54U0jj4YGjRwpOCcy7/eFJIo02b0GOqJwXnXL7xpFAFvwLJOZePPClUobg4NDTv3JntSJxzbu/xpFCF4mLYsgXKy2te1znnmgtPClXwK5Ccc/moNsNx9pb0nKQ3JS2SdHksnyRpuaQFcTo1aZtrJC2W9Lakk5PKj5L0elw2OQ7LSRy68/5Y/qKkoswfat14UnDO5aPanCnsAH5oZocBQ4HLJPWPy241s5I4PQYQl40HBgCjgDviUJ4AdwITCeM294vLAS4G1pnZIcCtwC8bfmgN06MHdOoE8+dnOxLnnNt7akwKZrbCzF6J8xuBN4Ge1WwyFphuZtvMbAmwGBgiqQfQwczmWRgDdBpwRtI2U+P8TOCExFlEtkhw8snw2GPe2Oycyx91alOI1TpHAC/Gou9Kek3SPZI6xbKewLKkzcpjWc84n1peaRsz2wFsALrUJbbGMGYMrFoFL7+c7Uicc27vqHVSkNQeeAD4vpl9SqgKOhgoAVYAtyRWTbO5VVNe3TapMUyUVCapbPXq1bUNvd5GjYKCAvjrXxv9pZxzrkmoVVKQ1IqQEO4zswcBzGylmVWY2U7gLmBIXL0c6J20eS/go1jeK015pW0ktQQ6AmtT4zCzKWZWamal3bp1q90RNkDnzjBsGDzySKO/lHPONQm1ufpIwN3Am2b2q6TyHkmrjQMWxvlZwPh4RVFfQoPyS2a2AtgoaWjc54XAw0nbTIjzZwLPxnaHrBs9Gl59FT78MNuROOdc46vNmcIw4ALg+JTLT2+Ml5e+BhwH/ADAzBYBM4A3gCeAy8ysIu7rUuB3hMbn94DHY/ndQBdJi4ErgKszcnQZMGZMeHz00ezG4Zxze4OayA/yOistLbWysrJGfx0z6NcPDj00XInknHO5TNJ8Myutarnf0VwDKZwtPPssfPZZtqNxzrnG5UmhFkaPhm3bYPbsbEfinHONy5NCLXzlK9Chg1+F5Jxr/jwp1ELr1uHu5kce8bubnXPNmyeFWhozBj7+GF55JduROOdc4/GkUEunnBLGbfa7m51zzZknhVrq2hWOOcbbFZxzzZsnhToYPTpUHy1fnu1InHOucXhSqAO/u9k519x5UqiD/v2hqMirkJxzzZcnhTpI3N08ezZs2ZLtaJxzLvM8KdTR6NEhITz7bLYjcc65zPOkUEfDh0P79n5pqnOuefKkUEdt2sBJJ4V2hRztYNY556rkSaEexowJl6UuWJDtSJxzLrM8KdTDqaeGRme/Csk519x4UqiH7t3hS1/ydgXnXPNTmzGae0t6TtKbkhZJujyWd5b0tKR342OnpG2ukbRY0tuSTk4qPyoO4blY0uQ4VjNxPOf7Y/mLkooyf6iZNXo0vPxy6CTPOeeai9qcKewAfmhmhwFDgcsk9SeMo/yMmfUDnonPicvGAwOAUcAdkgrivu4EJgL94jQqll8MrDOzQ4BbgV9m4Ngald/d7JxrjmpMCma2wsxeifMbgTeBnsBYYGpcbSpwRpwfC0w3s21mtgRYDAyR1APoYGbzLAwMPS1lm8S+ZgInJM4imqpBg6B3b29XcM41L3VqU4jVOkcALwL7m9kKCIkD6B5X6wksS9qsPJb1jPOp5ZW2MbMdwAagS5rXnyipTFLZ6tWr6xJ6xkmhCumpp2Dr1qyG4pxzGVPrpCCpPfAA8H0z+7S6VdOUWTXl1W1TucBsipmVmllpt27dagq50Y0ZA5s3w5w52Y7EOecyo1ZJQVIrQkK4z8wejMUrY5UQ8XFVLC8Heidt3gv4KJb3SlNeaRtJLYGOwNq6Hszedtxx0K6dX4XknGs+anP1kYC7gTfN7FdJi2YBE+L8BODhpPLx8YqivoQG5ZdiFdNGSUPjPi9M2SaxrzOBZ2O7Q5NWWAgjR/rdzc655qM2ZwrDgAuA4yUtiNOpwA3ASEnvAiPjc8xsETADeAN4ArjMzCrivi4FfkdofH4PeDyW3w10kbQYuIJ4JVMuGD0aPvwQXn8925E451zDtaxpBTN7gfR1/gAnVLHNdcB1acrLgIFpyrcCZ9UUS1N02mnh8ZFHYPDg7MbinHMN5Xc0N1CPHlBa6u0KzrnmwZNCBowZAy++CCtXZjsS55xrGE8KGXDGGaGh+eGHa17XOeeaMk8KGTBoEBx0EDz0ULYjcc65hvGkkAESjBsHzzwDGzZkOxrnnKs/TwoZMm4cbN8Ojz2W7Uicc67+PClkyDHHwP77exWScy63eVLIkBYtYOxYePxx7yDPOZe7PClk0LhxsGkTzJ6d7Uicc65+PClk0PHHQ4cOXoXknMtdnhQyqHXr0O3FrFmwY0e2o3HOubrzpJBh48bBmjXw979nOxLnnKs7TwoZdsop0KaNVyE553KTJ4UMa98+jLHw0EM+xoJzLvd4UmgE48aFMRb++c9sR+Kcc3XjSaERjBkT7lvwKiTnXK6pzXCc90haJWlhUtkkSctTRmJLLLtG0mJJb0s6Oan8KEmvx2WT45CcxGE774/lL0oqyuwh7n3dusFXvuJJwTmXe2pzpvAHYFSa8lvNrCROjwFI6g+MBwbEbe6QVBDXvxOYSBizuV/SPi8G1pnZIcCtwC/reSxNyrhxsGgRvPNOtiNxzrnaqzEpmNlcYG0t9zcWmG5m28xsCWEs5iGSegAdzGyemRkwDTgjaZupcX4mcELiLCKXnRGPzs8WnHO5pCFtCt+V9FqsXuoUy3oCy5LWKY9lPeN8anmlbcxsB7AB6JLuBSVNlFQmqWz16tUNCL3xfeELcOSRnhScc7mlvknhTuBgoARYAdwSy9P9wrdqyqvbZs9CsylmVmpmpd26datbxFkwblwYpnP58mxH4pxztVOvpGBmK82swsx2AncBQ+KicqB30qq9gI9iea805ZW2kdQS6Ejtq6uatHHjwqMP0+mcyxX1SgqxjSBhHJC4MmkWMD5eUdSX0KD8kpmtADZKGhrbCy4EHk7aZkKcPxN4NrY75Lz+/aFfP69Ccs7ljpY1rSDpz8AIoKukcuCnwAhJJYRqnqXAtwHMbJGkGcAbwA7gMjOriLu6lHAlU1vg8TgB3A3cK2kx4QxhfCYOrCmQ4KtfhVtugXXroFOnmrdxzrlsUq7+KC8tLbWysrJsh1GjF1+EoUNh2jS44IJsR+Ocy3eS5ptZaVXL/Y7mRnb00XDggV6F5JzLDZ4UGlmLFuGehSeegM2bsx2Nc85Vz5PCXjBuHGzZAk89le1InHOuep4U9oLhw0Mjs1chOeeaOk8Ke0GrVjB6NPz1r7B9e7ajcc65qnlS2EvGjQuXpc6dm+1InHOuap4U9pKTT4a2bb0KyTnXtHlS2EvatQuJ4S9/gZ07sx2Nc86l50lhLxo3LnSOlwP33Dnn8pQnhb1o9Gho2RL+53+yHYlzzqXnSWEv6twZLr8c7rkHnnsu29E459yePCnsZT//ORxyCFxyid/h7Jxrejwp7GXt2sFdd8F778GPf5ztaJxzrjJPClkwYgR8+9tw222hF1XnnGsqPClkyY03ht5Tv/lN2LYt29E451zgSSFLOnSA3/4W3ngDfvGLbEfjnHNBjUlB0j2SVklamFTWWdLTkt6Nj52Sll0jabGktyWdnFR+lKTX47LJcVhO4tCd98fyFyUVZfYQm67TToPzzgtJ4bXXsh2Nc9CfV9wAABG/SURBVM7V7kzhD8ColLKrgWfMrB/wTHyOpP6E4TQHxG3ukFQQt7kTmEgYt7lf0j4vBtaZ2SHArcAv63swuei220IPqhdfDDt2ZDsa51y+qzEpmNlcwtjJycYCU+P8VOCMpPLpZrbNzJYAi4EhknoAHcxsnoXxP6elbJPY10zghMRZRD7o2hV+85twl/Ott2Y7Gudcvqtvm8L+ZrYCID52j+U9gWVJ65XHsp5xPrW80jZmtgPYAHRJ96KSJkoqk1S2evXqeobe9Jx1Vhid7Sc/gXfeyXY0zrl8lumG5nS/8K2a8uq22bPQbIqZlZpZabdu3eoZYtMjwe23Q5s24aY27zDPOZct9U0KK2OVEPFxVSwvB3onrdcL+CiW90pTXmkbSS2BjuxZXdXsHXgg/OpXYbwF7xvJOZct9U0Ks4AJcX4C8HBS+fh4RVFfQoPyS7GKaaOkobG94MKUbRL7OhN4NrY75J2LLoITT4T/+A/48MNsR+Ocy0e1uST1z8A8oFhSuaSLgRuAkZLeBUbG55jZImAG8AbwBHCZmVXEXV0K/I7Q+Pwe8HgsvxvoImkxcAXxSqZ8JMGUKaH66DvfgfxMjc65bFKu/igvLS21smY6MMHkyaE31WnT4IILsh2Nc645kTTfzEqrWu53NDdBl10GX/4yfO978Mor2Y7GOZdPPCk0QQUF8Mc/hq4wjjsO/u//sh2Rcy5feFJoovr2heefh/33h5NOgmefzXZEzrl84EmhCevTJ1yi2rcvnHoqPPpotiNyzjV3nhSauAMOgDlzYNCgcNfz//5vtiNyzjVnnhRyQJcuMHs2DB0K48fD1Kk1b+Occ/XhSSFHdOwITzwBJ5wA3/gG3HFHtiNyzjVHnhRyyD77wKxZcPrp4bLVm27KdkTOuebGk0KOKSyEmTPhnHNCdxg//anf+eycy5yW2Q7A1V2rVnDvvdCuHfz857BxI9xyS+gmwznnGsKTQo4qKAj9JO2zTxic54MPQu+qXbtmOzLnXC7z6qMc1qJFGM7zppvgkUdg4ED461+zHZVzLpflX1LYuRPWrct2FBkjwb//O7z8crj7+fTTw3jPn36a7cicc7ko/5LCHXfAF78Y7gJrRi20gweHxPCjH8Ef/hCez5mT7aicc7km/5LCV74CvXvD2WfDV78KH31U8zY5onVruO46eOGFMH/ccfCDH8CWLdmOzDmXK/IvKRx+OPzjH3DjjeFusP794e67m9VZwzHHwD//Ge5luO02OPLIcBbhnHM1yb+kANCyJVx5Jbz2WkgS3/oWjBwJ77+f7cgyZp994De/gaeeCpesHnNMuKdh+/ZsR+aca8oalBQkLZX0uqQFkspiWWdJT0t6Nz52Slr/GkmLJb0t6eSk8qPifhZLmhzHcW58/frBc8/BnXfCSy+FXuduuw0qKmreNkeMHAkLF8K554Z7GoYMCYfsnHPpZOJM4TgzK0ka3u1q4Bkz6wc8E58jqT8wHhgAjALukFQQt7kTmAj0i9OoDMRVOy1ahAGRFy3aXQk/bFh43kzst18Y2vOBB+CTT+D440NX3K+/nu3InHNNTWNUH40FEv14TgXOSCqfbmbbzGwJsBgYIqkH0MHM5lkYMHpa0jZ7T+/e4SL/++6DxYvhiCPCT+vPP9/roTSWr34V3n47NKfMmxdqzi66CJYty3ZkzrmmoqFJwYCnJM2XNDGW7W9mKwDiY/dY3hNI/vopj2U943xq+R4kTZRUJqls9erVDQw97QuEepY334QzzwyV8CNHwtq1mX+tLGnbNjSnvPceXHEF/OlPcOihcPXVsH59tqNzzmVbQ5PCMDM7EjgFuEzSsdWsm66dwKop37PQbIqZlZpZabdu3eoebW116xa+Le+7L1ypNGwYLFnSeK+XBZ07w803wzvvwFlnhbOHgw+GX/0Ktm3LdnTOuWxpUFIws4/i4yrgIWAIsDJWCREfV8XVy4HeSZv3Aj6K5b3SlGffuefC00/DypVhhJuysmxHlHFf+EJob3jlFSgthR/+EIqLQz7cuTPb0Tnn9rZ6JwVJ+0jaNzEPnAQsBGYBE+JqE4CH4/wsYLykNpL6EhqUX4pVTBslDY1XHV2YtE32HXss/P3voUvS4cObbedCJSXw5JPhEtbOneH880NyuPVWr1ZyLp805Exhf+AFSa8CLwGPmtkTwA3ASEnvAiPjc8xsETADeAN4ArjMzBLXfl4K/I7Q+Pwe8HgD4sq8ww4LLbOHHRYGSr7zzmxH1GhGjgwnRPffH/pSuuIK6NkzXKDlVys51/zJcvRO3tLSUivb29U5n30WBkl+5JEwws3114dLWpuxV16B228PTSxbt4aTpe9+F8aODeM6OOdyi6T5SbcQ7KF5f6Nl2j77wEMPwaWXhpbZc88N35TN2JFHhl5AysvDIX/wQWiY7tsX/vu/Q3OLc6758KRQVy1bhp/Ov/xlqGNpZpesVqVLl3Ap6+LFYZzoAQPgxz8Ot3eccw785S/e8Z5zzYEnhfqQQvXR9Omhe4wvf7nZXbJalYICGDMmNEq/9VZoa3jqKRg3LlzJe/bZIVdu2pTtSJ1z9eFJoSG+/nWYPRtWrYKjjoJf/CKvRrcpLobJk+Hjj8OVu+efD3/7W2h26dYttMnfe69fveRcLvGG5kx4++1wmc5jj4WOhr73Pbj88nBtZ56pqAhX8D7wADz4YGiLaNUKTjgBvvY1GD0aDjgg21E6l79qamj2pJBJ8+eHUW4eegjatw8DGlxxBXTvXvO2zdDOnWEch5kzQ5JI1LAdfjicdBKcfDL8y79AmzbZjdO5fOJJIRsWLgxVSfffH77xJk4MrbQ903bplBfM4NVXw7hGTz4Zzia2bw/3BI4YsTtJFBeHJhvnXOPwpJBN77wT7mW4997QQvvNb8JVV0FRUbYjy7pNm8IY0om7qN95J5T36RMSxIknhrEfioo8STiXSZ4UmoKlS8MlrPfcE+pURowId4GNGAFHH+31J4S36KmnQpJ45hnYsCGUd+0a+mQqLQ1v1dFHQ48eWQ3VuZzmSaEpWb48XK7z5JOhLgWgsDBc0ppIEkOGhLI8tmNHeHvKykKbxMsvhzGPEgPi9exZOUmUlORts41zdeZJoalauxaefz7Uofztb7BgQah4b9Mm9Mg6YkTosvuww8K3YJ7XoWzeDP/8Z0gQiWSRqHKCkBQGDQrTwIHhccCAcBO6c243Twq5Yt06eOGFkCTmzAlJItF3dbt2YSScxFRcvHt+v/2yGXVWrV8f+mZ67bXQWd/rr4czis2bw3IJDjpod7IYMCB0z1FUFO6jyPM86/KUJ4VctX59uMT1nXfCfRDvvBOmJUsqD3TQvXtIDn36hMr2dFOHDnnzDVhREd6iRJJITO++W/lta9cuJIeiot2JIvmxU6e8ectcnvGk0Nxs2wbvv787USQely+HFSvSd9DXtu3uBHHAAaH1tkuXPadE+X77NbveX7dsCf02LV0akkbqY6JhO2HffdMnjMR8x457+QCcyxBPCvnELHy7rVhR9bRyJXzySZgSLbepWrQIP5U7dgzfjqlThw6Vn7dvH9pCUqfCwvTlbdqE25yb0E/x9et3J4hEskhMS5bs2ZfTfvuFBNGnTxh3oqqpY8cmdZhubzALV0ts3x4eU79jq/rONQuns2a7p6qed+oU/vfqwZOCS88s9NO0Zs3uJJGYEmWffgobN+5+TJ4y0eNdIkG0br1n0mjdOiSOli13P1Y3X1Cw52O6MikkvRYtds9XVZZ4qxCffQZr1iq8NWtgzSdhfu1a2PCp2LQJdqb5V2pZEHJoxw5G+32Mdm2NfdqFx8TUtq3RrtBoW7h7vk0baN0GWqQOV578/5ruyyL5SyS1LN3fQFVlyY/pyhKPtXnd1HFdU48hdVlFRdgm8VjdfPKUeK3UsoqK3VNi+3RTapyJv4HkrJ6YN9v9pZ/6WNWPrUy6887QG2U91JQUWtY7qAyTNAr4f0AB8DszuyHLITVvUvgZ27EjHHxw3bffuTMMOpRIENu2VZ62bt2zrKrp88/TlyX+0TZvTv/Pl5ivqNj9z5j6mIF/UAHt41RU140rgHVxyhWpX4ZS+jJIn1zTPaaeLqX7ok1IJPQWLXY/ps4nP09O6umWJ+ZT95s6Jf8YSE2AqfMQfpSk/nBJ90MmXVVsVaePye9X8nxq2Ze/nH77DGgSSUFSAXA7YfjOcuBlSbPM7I3sRuaq1KLF7uqjpizx6zGRKJJ/zab7RZuYkrdPfqxuviYp/+Bbt4lPN4oNn+45bfosnH1s3AgbN2lX7k1+vnEjbNkqNm9rgSF2Eh6T55PLQnrbU6Kmr23bMCVO0qqbEt97VX0vpvtuTD2pS/c83Xd1Vd/fqSd+VZ30VZUnqitL/T7OJ00iKQBDgMVm9j6ApOnAWMJ4zs7Vn7T7m6R162xHU0lhnBp6393OneHEauvW0KC+devuKfF8y5Y951OnxLLPPw8nYKnT1q17liWfsKWrTWkOqko0Vf2Ir+p5Yl9VTXVZPmlS6Lm/MTSVpNATWJb0vBz4UupKkiYCEwH69OmzdyJzrolr0SL80i8sbFq3rSROvpKr2hNJJPV56nx1U2qzQupJXuqJYEVF5aaK5Cm1qaK6faXbZ+pUXTtx4j1JN1W3LN3yxuyVv6kkhXQnaHucl5vZFGAKhIbmxg7KOVd/ySdpLnc0lYvRy4HeSc97AR9lKRbnnMtbTSUpvAz0k9RXUmtgPDAryzE551zeaRLVR2a2Q9J3gScJl6TeY2aLshyWc87lnSaRFADM7DHgsWzH4Zxz+aypVB8555xrAjwpOOec28WTgnPOuV08KTjnnNslZ3tJlbQa+KCem3cF1mQwnKaguR1TczseaH7H1NyOB5rfMaU7ni+YWbeqNsjZpNAQksqq6zo2FzW3Y2puxwPN75ia2/FA8zum+hyPVx8555zbxZOCc865XfI1KUzJdgCNoLkdU3M7Hmh+x9Tcjgea3zHV+Xjysk3BOedcevl6puCccy4NTwrOOed2ybukIGmUpLclLZZ0dbbjaShJSyW9LmmBpLJsx1Mfku6RtErSwqSyzpKelvRufOyUzRjroorjmSRpefycFkg6NZsx1pWk3pKek/SmpEWSLo/lOfk5VXM8Ofs5SSqU9JKkV+Mx/SyW1+kzyqs2BUkFwDvASMLAPi8D55hZzo4FLWkpUGpmOXvDjaRjgU3ANDMbGMtuBNaa2Q0xeXcys6uyGWdtVXE8k4BNZnZzNmOrL0k9gB5m9oqkfYH5wBnAN8jBz6ma4zmbHP2cJAnYx8w2SWoFvABcDnyVOnxG+XamMARYbGbvm9nnwHRgbJZjyntmNhdYm1I8Fpga56cS/mFzQhXHk9PMbIWZvRLnNwJvEsZWz8nPqZrjyVkWbIpPW8XJqONnlG9JoSewLOl5OTn+h0D40J+SNF/SxGwHk0H7m9kKCP/AQPcsx5MJ35X0WqxeyolqlnQkFQFHAC/SDD6nlOOBHP6cJBVIWgCsAp42szp/RvmWFJSmLNfrz4aZ2ZHAKcBlserCNT13AgcDJcAK4JbshlM/ktoDDwDfN7NPsx1PQ6U5npz+nMyswsxKCOPcD5E0sK77yLekUA70TnreC/goS7FkhJl9FB9XAQ8Rqsiag5Wx3jdR/7sqy/E0iJmtjP+wO4G7yMHPKdZTPwDcZ2YPxuKc/ZzSHU9z+JwAzGw9MAcYRR0/o3xLCi8D/ST1ldQaGA/MynJM9SZpn9hIhqR9gJOAhdVvlTNmARPi/ATg4SzG0mCJf8poHDn2OcVGzLuBN83sV0mLcvJzqup4cvlzktRN0n5xvi1wIvAWdfyM8urqI4B4idltQAFwj5ldl+WQ6k3SQYSzAwjjbf8pF49H0p+BEYRuflcCPwX+AswA+gAfAmeZWU403lZxPCMIVRIGLAW+najnzQWS/gV4Hngd2BmLf0Soh8+5z6ma4zmHHP2cJA0mNCQXEH7wzzCzn0vqQh0+o7xLCs4556qWb9VHzjnnquFJwTnn3C6eFJxzzu3iScE559wunhScc87t4knBOefcLp4UnHPO7fL/AUfDNScJqtu6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
    "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
    "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uj7ANbv_jSzI"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIh-mWrvi6Pw"
   },
   "outputs": [],
   "source": [
    "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
    "\n",
    "def decode_output(output_list):\n",
    "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "    return [ix_to_tag[output] for output in output_list]\n",
    "\n",
    "y_true_decode = decode_output(y_true)\n",
    "y_pred_decode = decode_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "VAnJVsyPq5kR",
    "outputId": "df269a97-67de-4aad-8079-0e87b68c7dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC     0.9371    0.9594    0.9481       419\n",
      "      I-MISC     0.8690    0.7807    0.8225       187\n",
      "       I-ORG     0.9634    0.8316    0.8927       285\n",
      "       I-PER     0.9841    0.9909    0.9875       875\n",
      "           O     0.9894    0.9965    0.9929      5790\n",
      "\n",
      "    accuracy                         0.9823      7556\n",
      "   macro avg     0.9486    0.9118    0.9287      7556\n",
      "weighted avg     0.9819    0.9823    0.9818      7556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ao_KMytuHgOB",
    "outputId": "8219cac3-3d19-4850-fe9d-8307831e729c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'Bilstm_crf_bert3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "vULrL_HFGrgt",
    "outputId": "e03dcd60-b9bd-4a58-d618-5a43b2c2331b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "O\n",
      "O\n",
      "I-ORG\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(y_pred_decode[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84Vihry_Y3lP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def leaderboard(model, input_index, input_feature):\n",
    "    predicted = []\n",
    "    for i in range(len(input_index)):\n",
    "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
    "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
    "      # add elements of tuple to list\n",
    "      \n",
    "      _, outputs = model(input_index_tensor, input_feature_float)\n",
    "      predicted.extend(outputs)\n",
    "      \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0Y0fX78Ysm7"
   },
   "outputs": [],
   "source": [
    "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
    "\n",
    "def decode_output(output_list):\n",
    "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "    return [ix_to_tag[output] for output in output_list]\n",
    "\n",
    "test_pred_decode = decode_output(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2xqOcTPz3iU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "co1 = []\n",
    "co2 = []\n",
    "for i in range(len(test_pred_decode)):\n",
    "    co1.append(i)\n",
    "    co2.append(test_pred_decode[i])\n",
    "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
    "leaderboard.to_csv(\"leaderboard_bert3.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (word_embeds): Embedding(13972, 100)\n",
       "  (lstm_1): LSTM(200, 50, bidirectional=True)\n",
       "  (lstm_2): LSTM(200, 50, bidirectional=True)\n",
       "  (lstm_3): LSTM(3172, 50, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=100, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A2_Bilstm_crf_BERT.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
