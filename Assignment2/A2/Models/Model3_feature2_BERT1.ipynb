{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model3_feature2_BERT1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "environment": {
      "name": "pytorch-gpu.1-4.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IKhhaHUvYgoa"
      },
      "source": [
        "# Model: Named Entity Recognition + CRF+ 3 bi-lstm + 2 scaled self-attention + 2 features + Adam + lr = 0.00001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gduy9kF7V3D",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vHXwxx77i32",
        "colab_type": "text"
      },
      "source": [
        "Since we use Google Cloud Platform, you need to upload the dataset manually, all the datasets are included in the Group52A2.zip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_xY4scQ1RUve",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VwUrZvQakO2P",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK73yG9zfHbt",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence and a list of NER\n",
        "\n",
        "sentences_train = df_train['Sentence'].tolist()\n",
        "ner_train = df_train['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_train_split = []\n",
        "ner_train_split = []\n",
        "for each_sentence in sentences_train:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_train_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_train:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_train_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VNInRtB7PDia",
        "colab": {}
      },
      "source": [
        "sentences_val = df_val['Sentence'].tolist()\n",
        "ner_val = df_val['NER'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_val_split = []\n",
        "ner_val_split = []\n",
        "for each_sentence in sentences_val:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_val_split.append(each_sentence)\n",
        "\n",
        "for each_ner in ner_val:\n",
        "    each_ner = each_ner.split(\" \")\n",
        "    ner_val_split.append(each_ner)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OjohNx5IvRVZ",
        "colab": {}
      },
      "source": [
        "# create a list of Sentence\n",
        "\n",
        "sentences_test = df_test['Sentence'].tolist()\n",
        "\n",
        "# split each sentence by \" \"\n",
        "sentence_test_split = []\n",
        "\n",
        "for each_sentence in sentences_test:\n",
        "    each_sentence = each_sentence.split(\" \")\n",
        "    sentence_test_split.append(each_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZpChGu7_vk",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uYyw1E38CnM",
        "colab_type": "text"
      },
      "source": [
        "Use the dataset of lab 9 to gather the pos tags. Since the length of our dataset is 3000 for training, 700 for validtaion and 3684 for testing set, we only get the corresponding number of sentences in the dataset of lab 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S049P4HVDJTc",
        "colab": {}
      },
      "source": [
        "def read_data(file_name, n_sample):\n",
        "    f = open(file_name)\n",
        "    documents = f.readlines()\n",
        "    pos_data = []\n",
        "    pos = []\n",
        "    for i in documents:\n",
        "        if i == '\\n':   \n",
        "            pos_data.append(pos)\n",
        "            pos = []\n",
        "        else:    \n",
        "            pos.append(i.replace('\\n','').split(' ')[1])\n",
        "    return pos_data[:n_sample]\n",
        "\n",
        "pos_train = read_data(\"trainpos.txt\", 3000)\n",
        "pos_validation = read_data(\"valpos.txt\",700)\n",
        "pos_test = read_data(\"testpos.txt\",3684)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_5gUSbrHQ6J2"
      },
      "source": [
        "# Input Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drwWPpH18yo8",
        "colab_type": "text"
      },
      "source": [
        "We use pretrained Glove word embedding as the basic input embedding and use the pos tag, tf-idf and pretrained BERT word embedding as the features. \n",
        "\n",
        "Our best model only uses the Glove and BERT pretrained word embeddings. The BERT embedding code is in the section under the word embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mH_xBcfvfQp-",
        "colab": {}
      },
      "source": [
        "# get the total dataset\n",
        "total_sentences = sentence_train_split + sentence_val_split + sentence_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MirHmtHeIcGp",
        "outputId": "696f80c7-e52f-4dd3-e378-dc509a72f777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "total_words = []\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        total_words.append(word)\n",
        "\n",
        "# there are 93,794 words and 13,972 unique words in total.\n",
        "print(len(total_words))\n",
        "print(len(set(total_words)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93794\n",
            "13972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x7og4EnAq8aG"
      },
      "source": [
        "Distribution Graph： show the length distribution of the sentences in the dataset. （you do Not need to run this.）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sO-vnejvEDZ7",
        "outputId": "8fa30dd2-e43d-4372-93cf-c8010f096f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentence_lengths = []\n",
        "for each_sentence in total_sentences:\n",
        "    length = len(each_sentence)\n",
        "    sentence_lengths.append(length)\n",
        "\n",
        "total_sentence_num = len(sentence_lengths)\n",
        "largest_length = max(sentence_lengths)\n",
        "mean_length = np.mean(sentence_lengths)\n",
        "counts_length = np.bincount(sentence_lengths)\n",
        "counts_length = np.argmax(counts_length)\n",
        "length_less_than_counts = 0\n",
        "length_less_than_mean = 0 \n",
        "length_less_than_15 = 0\n",
        "length_less_than_20 = 0\n",
        "length_less_than_25 = 0\n",
        "length_less_than_30 = 0\n",
        "\n",
        "for length in sentence_lengths:\n",
        "  if length < counts_length:\n",
        "    length_less_than_counts += 1\n",
        "  if length < mean_length:\n",
        "    length_less_than_mean += 1\n",
        "  if length < 15:\n",
        "    length_less_than_15 += 1\n",
        "  if length < 20:\n",
        "    length_less_than_20 += 1\n",
        "  if length < 25:\n",
        "    length_less_than_25 += 1\n",
        "  if length < 30:\n",
        "    length_less_than_30 += 1\n",
        "print(\"Total number of sentences: \"+ str(total_sentence_num)+\" Largest length of the sentence: \"+ str(largest_length))\n",
        "x_lengths = [counts_length, mean_length, 15, 20, 25, 30]\n",
        "y_rate = [length_less_than_counts/total_sentence_num, length_less_than_mean/total_sentence_num, length_less_than_15/total_sentence_num, length_less_than_20/total_sentence_num, length_less_than_25/total_sentence_num, length_less_than_30/total_sentence_num]\n",
        "print(y_rate)\n",
        "plt.plot(x_lengths, y_rate, 'g', label = 'Rate of lengths that are smaller than limits')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences: 7384 Largest length of the sentence: 124\n",
            "[0.340465872156013, 0.6533044420368364, 0.6905471289274107, 0.7588028169014085, 0.8263813651137595, 0.8867822318526544]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WigpqqC8tG9",
        "colab_type": "text"
      },
      "source": [
        "## POS Tags （Not used in the best model, please skip this section）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIqomMLA9Ez9",
        "colab_type": "text"
      },
      "source": [
        "There are 45 kinds of pos tags in total. We represent them as one-hot vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ezZdNCrEDCP",
        "colab": {}
      },
      "source": [
        "total_pos_list = []\n",
        "\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    pos_line = []\n",
        "    for each_pos in line:\n",
        "        pos_line.append(each_pos)\n",
        "    total_pos_list.append(pos_line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gWQNSEP8HXtS",
        "outputId": "a9d5b414-17ee-4c57-8f53-458ebdea9d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pos_to_ix = {}\n",
        "pos_list = []\n",
        "for line in pos_train + pos_validation + pos_test:\n",
        "    for pos in line:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "pos_list = sorted(list(pos_to_ix.keys()))\n",
        "\n",
        "pos_list_length = len(pos_list)\n",
        "print(pos_list_length)\n",
        "print(pos_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n",
            "['\"', '$', \"''\", '(', ')', ',', '-X-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "My7OPDfWVvnk",
        "outputId": "613add2e-ec2c-4b16-e59a-2cd4d294ca50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# key is the pos tag, value is the one hot expression\n",
        "onehotpos = {}\n",
        "\n",
        "for i in range(pos_list_length):   \n",
        "    onehot = np.eye(1, pos_list_length, i, dtype = int)\n",
        "    onehotpos[pos_list[i]] = list(onehot[0])\n",
        "\n",
        "print(onehotpos)\n",
        "\n",
        "def get_onehotpos(pos_sentence):\n",
        "    pos_list = []\n",
        "    for each_pos in pos_sentence:\n",
        "        onehot_pos = onehotpos[each_pos]\n",
        "        pos_list.append(onehot_pos)\n",
        "    return pos_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\"': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '$': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"''\": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '(': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ')': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ',': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '-X-': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '.': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ':': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CC': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'DT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'EX': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'FW': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'IN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'JJS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'LS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'MD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNPS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'NNS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'POS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PRP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBR': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'RP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'SYM': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'TO': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'UH': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'VBD': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'VBG': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'VBN': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VBP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'VBZ': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'WDT': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'WP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'WP$': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'WRB': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r14mferpb4dD",
        "colab": {}
      },
      "source": [
        "# Create a direction, the key is sentence id, the value is the sentence's one-hot pos list\n",
        "sentence_to_pos = {}\n",
        "total_length = len(sentence_train_split) + len(sentence_val_split) + len(sentence_test_split)\n",
        "for i in range(total_length):\n",
        "    sentence_to_pos[i] = get_onehotpos(total_pos_list[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jm1NsLQ3qlBP"
      },
      "source": [
        "## TF-IDF （Not used in the best model, please skip this section）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0XY3R9ePJOY",
        "outputId": "21f27612-a188-45d5-d784-5615eeb96292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "DF = {}\n",
        "\n",
        "for each_sentence in total_sentences:\n",
        "    for term in np.unique(each_sentence):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "\n",
        "print(len(DF))\n",
        "\n",
        "\n",
        "tf_idf = {}\n",
        "N = total_length\n",
        "print(N)\n",
        "\n",
        "for i in range(N):\n",
        "    counter = Counter(total_sentences[i])\n",
        "    total_num_words = len(total_sentences[i])   \n",
        "    # the tfidf of all words in a sentence\n",
        "    each_sentence_tfidf = []\n",
        "    \n",
        "    for term in total_sentences[i]:\n",
        "        tf = counter[term]/total_num_words\n",
        "        df = DF[term]\n",
        "        idf = math.log(N/(df+1))+1\n",
        "        each_sentence_tfidf.append(tf*idf)\n",
        "    # Create a dictionary, the key is the sentence, the value is the sentence's TF-IDF list\n",
        "    tf_idf[i] = each_sentence_tfidf\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972\n",
            "7384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zV9yfV_9Vdk",
        "colab_type": "text"
      },
      "source": [
        "Test the tf-idf list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F0WnqcLhCxNh",
        "outputId": "c2111ba9-72fa-473c-dc6f-e630e6bd0d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(tf_idf[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.7867733572317377]\n",
            "[0.7736257552240274, 0.9787176097238419, 0.6639161270509292, 0.8343528337093685, 0.31869858164379405, 1.023769288402527, 0.675381042188177, 0.9467529350069775, 0.20141025902330312]\n",
            "[3.8549230994232344, 3.711082063197344]\n",
            "[3.236541785848771, 2.568193075858512]\n",
            "[0.07835476022474784, 0.2026143126564531, 0.23388996727621744, 0.10974483919929756, 0.10687798888782925, 0.1526398202464369, 0.14205412928464836, 0.2936152829171526, 0.13366389695153158, 0.19917483811527875, 0.28402588050209326, 0.2868287234794147, 0.25348285610628807, 0.2868287234794147, 0.2936152829171526, 0.2026143126564531, 0.28402588050209326, 0.22163247460537353, 0.2936152829171526, 0.28402588050209326, 0.24473738062403838, 0.2609209744834284, 0.25348285610628807, 0.2303779500876232, 0.22163247460537353, 0.15312882657136337, 0.28402588050209326, 0.2868287234794147, 0.24226711488558098, 0.06042307770699094]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jFq1dlZnO9mi",
        "outputId": "f9806dd5-cf96-4eb0-8b9c-ef52ef4c6dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(len(sentence_to_pos[i]), len(tf_idf[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 1\n",
            "9 9\n",
            "2 2\n",
            "2 2\n",
            "30 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YpOBlqr93yB",
        "colab_type": "text"
      },
      "source": [
        "Combine each pos one-hot vector with the tf-idf value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3DcyEtJ93fo",
        "colab": {}
      },
      "source": [
        "def get_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        sentence_feature_list = []\n",
        "        for j in range(len(sentence_to_pos[i])): \n",
        "            sentence_feature_list.append(sentence_to_pos[i][j]+[tf_idf[i][j]])\n",
        "        \n",
        "        feature_list.append(sentence_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dF0Tv48EMi__",
        "outputId": "f79a7b65-aa19-4373-80b8-e6fefc76f357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# An example of the combined feature\n",
        "print(get_feature(0,5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.7867733572317377]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7736257552240274], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.9787176097238419], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6639161270509292], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8343528337093685], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.31869858164379405], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.023769288402527], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.675381042188177], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9467529350069775], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20141025902330312]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8549230994232344], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.711082063197344]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.236541785848771], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.568193075858512]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07835476022474784], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.23388996727621744], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10974483919929756], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10687798888782925], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1526398202464369], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.14205412928464836], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13366389695153158], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19917483811527875], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2026143126564531], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2936152829171526], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24473738062403838], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2609209744834284], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.25348285610628807], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2303779500876232], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22163247460537353], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.15312882657136337], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.28402588050209326], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2868287234794147], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24226711488558098], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06042307770699094]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16596441423822358], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.09252539467077893], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19607836708689008], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20986688369421072], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21886181195549406], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2525041688549307], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.10620468309609442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.10343031182693152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18074211880575866], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.24530598978027876], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.20398554315247025], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261784235708214], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2841438221778896], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13360902172251107], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.22460102571020152], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.18697409393578635], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1844327752953633], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.19031411583710375], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.21448303994068407], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1516543746285442], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2568116331331411], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2748637553246064], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0.12397695379016387], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.29722334179428206], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05847394616805574]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5cnLEAQ_Q5h",
        "colab_type": "text"
      },
      "source": [
        "# Output：NER tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7jFsK7PUsNox"
      },
      "source": [
        "There are 5 kinds of tag in total.\n",
        "\n",
        "'I-ORG': Organization\n",
        "\n",
        "'O': Other\n",
        "\n",
        "'I-LOC': Location \n",
        "\n",
        "'I-PER': Person \n",
        "\n",
        "'I-MISC': Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-UMIHEKrgCw",
        "outputId": "f3cd30b4-e425-41f3-b247-96ba05824fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "ner_train_list = []\n",
        "for each_ner in ner_train_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_train_list.append(each_tag)\n",
        "ner_train_set = list(set(ner_train_list))\n",
        "print(len(ner_train_list))\n",
        "print(len(ner_train_set))\n",
        "print(ner_train_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39572\n",
            "5\n",
            "['I-MISC', 'I-PER', 'O', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7chjiqNYkzNK",
        "outputId": "26918c46-b4d7-4b42-8343-d284d6828f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "ner_val_list = []\n",
        "for each_ner in ner_val_split:\n",
        "    for each_tag in each_ner:\n",
        "        ner_val_list.append(each_tag)\n",
        "ner_val_set = list(set(ner_val_list))\n",
        "print(len(ner_val_list))\n",
        "print(len(ner_val_set))\n",
        "print(ner_val_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7556\n",
            "5\n",
            "['I-MISC', 'I-PER', 'O', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FDuagDgs1Yj4",
        "outputId": "69be7027-cc74-4655-bc07-3cd24a2226ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_train_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   1526\n",
            "O:       32137\n",
            "I-LOC:   1994\n",
            "I-PER:   2840\n",
            "I-MISC:  1075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_NXJRv7k__M",
        "outputId": "2817e9c6-05e3-401f-aae8-b26309f54662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# count the number of each tag\n",
        "num_org = 0\n",
        "num_o = 0\n",
        "num_loc = 0\n",
        "num_per = 0\n",
        "num_misc = 0\n",
        "for i in ner_val_list:\n",
        "    if i=='I-ORG':\n",
        "        num_org += 1\n",
        "    if i=='O':\n",
        "        num_o += 1\n",
        "    if i=='I-LOC':\n",
        "        num_loc += 1\n",
        "    if i=='I-PER':\n",
        "        num_per += 1\n",
        "    if i=='I-MISC':\n",
        "        num_misc += 1\n",
        "print(\"I-ORG:  \", num_org)\n",
        "print(\"O:      \", num_o)\n",
        "print(\"I-LOC:  \", num_loc)\n",
        "print(\"I-PER:  \", num_per)\n",
        "print(\"I-MISC: \", num_misc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-ORG:   285\n",
            "O:       5790\n",
            "I-LOC:   419\n",
            "I-PER:   875\n",
            "I-MISC:  187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP9s9J-lDKUC"
      },
      "source": [
        "In the data, you can see the different types of entities: \n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h4F991p-IqNS"
      },
      "source": [
        "##Conditional random fields (CRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pcu5O3OlEdPA"
      },
      "source": [
        "We will now train a CRF model for named entity recognition using sklearn-crfsuite on our dataset. We use CRF here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5EsvF8uXSgy5",
        "outputId": "8981e272-fc21-46de-8bd5-ad0b2462d1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /opt/conda/lib/python3.7/site-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (1.14.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.7/site-packages (from sklearn_crfsuite) (4.45.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-Xcf07iR79l",
        "colab": {}
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NQPELELtSmYo",
        "outputId": "730f47d9-b8a1-4c4b-a558-234f7e5d289d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_train = []\n",
        "for line in range(len(sentence_train_split)):\n",
        "    combine_sentence = []\n",
        "    for each_word, each_tag in zip(sentence_train_split[line], ner_train_split[line]):\n",
        "        combine_sentence.append((each_word, each_tag))\n",
        "    zip_sentences_train.append(combine_sentence)\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(zip_sentences_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('-docstart-', 'O')]\n",
            "[('eu', 'I-ORG'), ('rejects', 'O'), ('german', 'I-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "[('peter', 'I-PER'), ('blackburn', 'I-PER')]\n",
            "[('brussels', 'I-LOC'), ('1996-08-22', 'O')]\n",
            "[('the', 'O'), ('european', 'I-ORG'), ('commission', 'I-ORG'), ('said', 'O'), ('on', 'O'), ('thursday', 'O'), ('it', 'O'), ('disagreed', 'O'), ('with', 'O'), ('german', 'I-MISC'), ('advice', 'O'), ('to', 'O'), ('consumers', 'O'), ('to', 'O'), ('shun', 'O'), ('british', 'I-MISC'), ('lamb', 'O'), ('until', 'O'), ('scientists', 'O'), ('determine', 'O'), ('whether', 'O'), ('mad', 'O'), ('cow', 'O'), ('disease', 'O'), ('can', 'O'), ('be', 'O'), ('transmitted', 'O'), ('to', 'O'), ('sheep', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RCJIH2emlP1y",
        "colab": {}
      },
      "source": [
        "#Retrieving sentences with their tags in zip\n",
        "zip_sentences_val = []\n",
        "for line in range(len(sentence_val_split)):\n",
        "    combine_sentence_val = []\n",
        "    for each_word, each_tag in zip(sentence_val_split[line], ner_val_split[line]):\n",
        "        combine_sentence_val.append((each_word, each_tag))\n",
        "    zip_sentences_val.append(combine_sentence_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "alfVxIWIFEth"
      },
      "source": [
        "We extract more features (word parts, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code were taken from [sklearn-crfsuites official site](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bbaee897Sqoa",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    # postag = sent[i][1]\n",
        "    # a few features: upper? lower? title? \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:], # last three letters of the word\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(), \n",
        "        'word.istitle()': word.istitle(), # is it a title?\n",
        "        'word.isdigit()': word.isdigit(), # is it a digit?\n",
        "       \n",
        "    }\n",
        "    # features of the previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        # postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "          \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    # features of the next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "       \n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            \n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ME9Xu722SzYZ",
        "colab": {}
      },
      "source": [
        "\n",
        "features_train = [sent2features(s) for s in zip_sentences_train]\n",
        "labels_train = [sent2labels(s) for s in zip_sentences_train]\n",
        "\n",
        "features_val = [sent2features(s) for s in zip_sentences_val]\n",
        "labels_val = [sent2labels(s) for s in zip_sentences_val]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3F2kJfNAS1N2",
        "outputId": "566d89e5-1525-4aa3-8446-7eace22f3c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# train a CRF model for named entity recognition using sklearn-crfsuite \n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VnxUCHw5FXGt"
      },
      "source": [
        "Because tag “O” (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag “O” when we evaluate classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hSnMwxl4UVPN",
        "outputId": "8d533591-8f5f-41a2-b790-cbdc1ef145e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ner_train_set.remove('O')\n",
        "classes = ner_train_set\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I-MISC', 'I-PER', 'I-LOC', 'I-ORG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9C9jdSefS4id",
        "outputId": "9b77e88e-a5a8-4cbd-d001-2533a65ea4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#evaluation\n",
        "y_pred = crf.predict(features_val)\n",
        "print(metrics.flat_classification_report(labels_val, y_pred, labels=classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      I-MISC       0.83      0.63      0.72       187\n",
            "       I-PER       0.93      0.80      0.86       875\n",
            "       I-LOC       0.89      0.85      0.87       419\n",
            "       I-ORG       0.85      0.58      0.69       285\n",
            "\n",
            "   micro avg       0.90      0.76      0.82      1766\n",
            "   macro avg       0.88      0.72      0.78      1766\n",
            "weighted avg       0.90      0.76      0.82      1766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g3oWq_PnK8wk"
      },
      "source": [
        "The following shows what our classifier learned. It is very likely that the inside person entity (I-PER) will be followed by a token inside person entity (I-PER)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "40His-7UKyvp",
        "outputId": "956c8a42-6b78-4bae-d9b6-0ab7adf5fd53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "I-PER  -> I-PER   3.403927\n",
            "I-ORG  -> I-ORG   3.384090\n",
            "I-MISC -> I-MISC  2.828140\n",
            "I-LOC  -> I-LOC   2.064296\n",
            "O      -> O       0.776679\n",
            "\n",
            "Top unlikely transitions:\n",
            "I-PER  -> I-LOC   -2.677780\n",
            "I-PER  -> I-ORG   -2.689004\n",
            "I-LOC  -> I-PER   -3.410616\n",
            "I-ORG  -> I-LOC   -3.463856\n",
            "I-ORG  -> I-PER   -3.736825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sQbtE0AYpvtX"
      },
      "source": [
        "# Bi-LSTM CRF model\n",
        "\n",
        "Now we will apply the Bi-LSTM CRF model we just learned to CoNLL 2003 NER dataset using the pretrained glove embeddings. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2cCqGvJchOdR"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MWAK0NV3INF",
        "colab": {}
      },
      "source": [
        "# convert each unique word to the index\n",
        "word_to_ix = {}\n",
        "for sentence in total_sentences:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in ner_train_split + ner_val_split:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tndg_-ttwa6N",
        "outputId": "24b138a3-c5c3-49bd-aeba-cad4b60dfb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'I-ORG': 3, 'I-MISC': 4, 'I-PER': 5, 'I-LOC': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ajrekRAbtxL2",
        "outputId": "c85a5f3f-3e9c-4d88-8467-8e0f08233b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(word_list), len(tag_to_ix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13972 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GEswz2QjhXBM"
      },
      "source": [
        "#### Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQ6hVie7T0p",
        "colab_type": "code",
        "colab": {},
        "outputId": "189b825f-9362-49c1-dc63-bb465d73c52a"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
            "Collecting smart-open>=1.8.1\n",
            "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 71.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.13.19-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 70.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
            "Collecting botocore<1.17.0,>=1.16.19\n",
            "  Downloading botocore-1.16.19-py2.py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 73.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 10.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 77.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=6addc80f7ae9db828ae8447852e0c8c519b2ef1bb5acf4d834b94af4cf30375b\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/bb/1c/9c/412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
            "Successfully built smart-open\n",
            "Installing collected packages: docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "Successfully installed boto3-1.13.19 botocore-1.16.19 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Oz6KVyjsxM9",
        "outputId": "0f981765-1fa6-4555-8b43-530a3a3877db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "# change a latest embedding!\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-100\") \n",
        "# word dimension\n",
        "EMBEDDING_DIM = 100\n",
        "embedding_matrix = []\n",
        "num_except = 0\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        num_except += 1\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM) # '-docstart-': 0*50\n",
        "\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MKgVMs5Efpc",
        "colab_type": "text"
      },
      "source": [
        "## Generate BERT word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7VNLLP1EzvD",
        "colab_type": "text"
      },
      "source": [
        "Use the pretrained BERT model from https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0Y5AOY80TXw",
        "outputId": "381c8abd-e7b4-41d6-bb07-ba9a978fb93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 5.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2019.8.19)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 23.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 41.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 86.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=dd6b1afbac578fee65fbe2d37284d739022df7e73e301b083358c3e1786a9f2a\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuZjGARt7T0v",
        "colab_type": "code",
        "colab": {},
        "outputId": "7255cbb7-9557-4274-9cdf-af74171b25de"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.5-py3-none-any.whl (334 kB)\n",
            "\u001b[K     |████████████████████████████████| 334 kB 4.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.7/site-packages (from flair) (4.45.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.7/site-packages (from flair) (3.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from flair) (2019.8.19)\n",
            "Requirement already satisfied: transformers>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from flair) (2.10.0)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading bpemb-0.3.0-py3-none-any.whl (19 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 15.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from flair) (0.8.7)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 36.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting hyperopt>=0.1.1\n",
            "  Downloading hyperopt-0.2.4-py2.py3-none-any.whl (964 kB)\n",
            "\u001b[K     |████████████████████████████████| 964 kB 45.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pytest>=5.3.2 in /opt/conda/lib/python3.7/site-packages (from flair) (5.4.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from flair) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from flair) (3.8.3)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.18.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.7.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (3.0.10)\n",
            "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.1.91)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=2.10.0->flair) (0.0.43)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect->flair) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n",
            "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (20.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.13.0)\n",
            "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (2.0.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (1.25.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=2.10.0->flair) (2020.4.5.1)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=2.10.0->flair) (7.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (1.13.19)\n",
            "Requirement already satisfied: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (1.16.19)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.19->boto3->smart-open>=1.8.1->gensim>=3.4.0->flair) (0.15.2)\n",
            "Building wheels for collected packages: segtok, mpld3, sqlitedict, langdetect\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25019 sha256=fe72bfceedd0318c40b008810f174e7d950f1090ac3050600ecbc11d0ac85f53\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=bce77c7f4df3afedc360c6753c63eb246636907eeb59beb2c2e01f6069893ddc\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14688 sha256=be41790b349150f2be32a328c3eab82f4789174bdbd739317b6be1cbc6a0b99f\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/58/dd/2c/0a57aadf6a7f26bec0af66d742c50af74d11967780f0bb7a7d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=172c95021d4f54495660226bfc289600de21f3416bfb315044afbc02c156d97e\n",
            "  Stored in directory: /home/jupyter/.cache/pip/wheels/59/f6/9d/85068904dba861c0b9af74e286265a08da438748ee5ae56067\n",
            "Successfully built segtok mpld3 sqlitedict langdetect\n",
            "Installing collected packages: bpemb, segtok, mpld3, sqlitedict, langdetect, hyperopt, deprecated, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.5 hyperopt-0.2.4 langdetect-1.0.8 mpld3-0.3 segtok-1.5.10 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX-w_kcn7T0x",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b32357e-a021-41d2-e5fd-1ad18384396d"
      },
      "source": [
        "from flair.embeddings import FlairEmbeddings, TransformerWordEmbeddings\n",
        "from flair.data import Sentence\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "bert_emb_model = TransformerWordEmbeddings('bert-base-uncased')\n",
        "\n",
        "bert_embeddings = []\n",
        "for each_sentence in tqdm(total_sentences):\n",
        "    sentence_bert_emb = []\n",
        "    each_sentence = \" \".join(each_sentence)\n",
        "    each_sentence = Sentence(each_sentence)\n",
        "    # for each sentence\n",
        "    bert_emb_model.embed(each_sentence)\n",
        "    for word in each_sentence:\n",
        "        sentence_bert_emb.append(word.embedding)\n",
        "    \n",
        "    bert_embeddings.append(sentence_bert_emb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7384/7384 [01:50<00:00, 66.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TMrZaKtEq5Z",
        "colab_type": "text"
      },
      "source": [
        "get bert word embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tk7BVC67T00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bert_feature(from_feature_index, to_feature_index):\n",
        "    feature_list = []\n",
        "    for i in range(from_feature_index, to_feature_index+1): \n",
        "        bert_feature_list = []\n",
        "        for j in range(len(bert_embeddings[i])): \n",
        "            a =  bert_embeddings[i][j]\n",
        "            a = a.cpu().numpy()\n",
        "            a = list(a)\n",
        "            bert_feature_list.append(a)\n",
        "        \n",
        "        feature_list.append(bert_feature_list)\n",
        "\n",
        "    return feature_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlchZJO8hdXa"
      },
      "source": [
        "#### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fRs6mouFwEx4",
        "colab": {}
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# use the index to represent each word in each sentence\n",
        "train_input_index =  to_index(sentence_train_split, word_to_ix)\n",
        "train_output_index = to_index(ner_train_split, tag_to_ix)\n",
        "\n",
        "\n",
        "train_input_feature = get_bert_feature(0, 2999)\n",
        "\n",
        "val_input_index = to_index(sentence_val_split, word_to_ix)\n",
        "val_output_index = to_index(ner_val_split, tag_to_ix)\n",
        "# val_input_feature = get_feature(3000, 3699)\n",
        "\n",
        "val_input_feature = get_bert_feature(3000, 3699)\n",
        "\n",
        "test_input_index = to_index(sentence_test_split, word_to_ix)\n",
        "# test_input_feature = get_feature(3700, 7383)\n",
        "test_input_feature = get_bert_feature(3700, 7383)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXEscWBrhjgb"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a5AgRWakkfmT",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "  \n",
        "        # Use nn.Embedding\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Use the embedding matrix as the initial weights of nn.Embedding\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
        "        self.lstm_3 = nn.LSTM(100+3072, hidden_dim // 2, num_layers=1, bidirectional=True) #100 from glove embedding; 3072 from bert embedding\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "      \n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    # CRF: use the transition matrix to train our model\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of the previous tag\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    # Attention Calculation: two methods\n",
        "\n",
        "    def cal_self_attention(self, hidden, method):\n",
        "        # 1st type of calculation of the attention: Dot Product\n",
        "        if method == 'Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1)) # [1, seq, 50] * [1,50,seq] = [1,seq, seq]\n",
        "            # print(\"hidden1 \"+str(hidden1.shape))\n",
        "            # print(\"hidden2 \"+str(hidden2.shape))\n",
        "            # print(\"a shape \" + str(a.shape)) \n",
        "          \n",
        "            attn_weights = F.softmax(a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "            # print(concat_output,concat_output.size())\n",
        "\n",
        "        # 2nd type of calculation of the attention: Scaled Dot Product\n",
        "        elif method == 'Scale Dot Product':\n",
        "            a = torch.bmm(hidden, hidden.permute(0,2,1))\n",
        "            attn_weights = F.softmax((1/np.sqrt(self.hidden_dim))*a, dim = -1)\n",
        "            attn_output = torch.bmm(attn_weights, hidden) \n",
        "            concat_output = torch.cat((attn_output, hidden), -1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "\n",
        "    def _get_lstm_features(self, sentence, features):\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        features = features.view(len(features),1,-1)\n",
        "        # concat the word embedding with the word features\n",
        "        word_concat = torch.cat((embeds, features), dim = 2) \n",
        "        lstm_out_summary, (h_n,c_n) = self.lstm_3(word_concat, self.hidden)        \n",
        "        attn_output1 = self.cal_self_attention(lstm_out_summary, 'Scale Dot Product')\n",
        "        lstm_out_1, self.hidden = self.lstm_1(attn_output1, self.hidden)         \n",
        "        attn_output2 = self.cal_self_attention(lstm_out_1, 'Scale Dot Product')       \n",
        "        lstm_out_2, _ = self.lstm_2(attn_output2)     \n",
        "     \n",
        "        # change from 3 dimensions to 2 dimensions\n",
        "        lstm_out = lstm_out_2.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    ''' Calculate the score for the viterbi decoding'''\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, features, tags):\n",
        "        feats = self._get_lstm_features(sentence, features)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    # sentence is a index expression of the words in the sentence \n",
        "    def forward(self, sentence, features):  \n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence, features)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUNHEV1kiDKt"
      },
      "source": [
        "#### Function for accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Moqs-zwboIn"
      },
      "source": [
        "Generates the model predictions using the input data and calculates the accuracy by comparing the model predictions with the ground truth labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bJmu0oSsjLBm",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "def cal_acc(model, input_index, input_feature, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      ground_truth.extend(output_index[i])\n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      accuracy = accuracy_score(predicted, ground_truth)\n",
        "      \n",
        "    return ground_truth, predicted, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_82UaXEOhoQQ"
      },
      "source": [
        "#### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NyuzZ_et6FD7",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u9UiokVOjPUn"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a0CMFVSwlLru",
        "outputId": "5111ab2e-3305-46ff-f1db-3cb6ef007012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 275s\"\"\"\n",
        "\n",
        "import datetime\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "for epoch in range(30):  \n",
        "    epoch_list.append(epoch) \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "  \n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_train = torch.from_numpy(np.array(train_input_feature[i])).float().to(device)\n",
        "        \n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        # Use the forward pass\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_train, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "    train_loss_list.append(train_loss)\n",
        "    model.eval()\n",
        "    \n",
        "    _, _, train_acc = cal_acc(model, train_input_index, train_input_feature, train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_loss = 0\n",
        "    # i: index; idxs: word\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        sentence_features_val = torch.from_numpy(np.array(val_input_feature[i])).float().to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, sentence_features_val, targets)\n",
        "        val_loss+=loss.item()\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 51367.62, train acc: 0.7647, val loss: 7652.26, val acc: 0.6989, time: 274.28s\n",
            "Epoch:2, Training loss: 30837.48, train acc: 0.8082, val loss: 5545.80, val acc: 0.7646, time: 275.06s\n",
            "Epoch:3, Training loss: 20286.29, train acc: 0.8624, val loss: 3425.59, val acc: 0.8416, time: 274.24s\n",
            "Epoch:4, Training loss: 14053.00, train acc: 0.8891, val loss: 2496.91, val acc: 0.8855, time: 274.21s\n",
            "Epoch:5, Training loss: 10814.90, train acc: 0.9150, val loss: 1895.58, val acc: 0.9189, time: 274.47s\n",
            "Epoch:6, Training loss: 8707.96, train acc: 0.9359, val loss: 1552.07, val acc: 0.9383, time: 274.80s\n",
            "Epoch:7, Training loss: 7188.76, train acc: 0.9463, val loss: 1312.82, val acc: 0.9438, time: 275.28s\n",
            "Epoch:8, Training loss: 5972.22, train acc: 0.9565, val loss: 1139.29, val acc: 0.9514, time: 275.08s\n",
            "Epoch:9, Training loss: 4894.80, train acc: 0.9658, val loss: 996.64, val acc: 0.9579, time: 274.97s\n",
            "Epoch:10, Training loss: 3974.91, train acc: 0.9754, val loss: 880.88, val acc: 0.9647, time: 275.37s\n",
            "Epoch:11, Training loss: 3184.74, train acc: 0.9823, val loss: 775.75, val acc: 0.9722, time: 275.98s\n",
            "Epoch:12, Training loss: 2519.61, train acc: 0.9878, val loss: 714.69, val acc: 0.9741, time: 275.67s\n",
            "Epoch:13, Training loss: 1958.25, train acc: 0.9909, val loss: 672.80, val acc: 0.9755, time: 274.85s\n",
            "Epoch:14, Training loss: 1515.06, train acc: 0.9938, val loss: 635.60, val acc: 0.9766, time: 274.26s\n",
            "Epoch:15, Training loss: 1186.73, train acc: 0.9956, val loss: 610.80, val acc: 0.9783, time: 274.35s\n",
            "Epoch:16, Training loss: 911.43, train acc: 0.9970, val loss: 597.78, val acc: 0.9787, time: 274.47s\n",
            "Epoch:17, Training loss: 713.57, train acc: 0.9978, val loss: 596.92, val acc: 0.9798, time: 274.41s\n",
            "Epoch:18, Training loss: 561.76, train acc: 0.9984, val loss: 588.02, val acc: 0.9796, time: 274.07s\n",
            "Epoch:19, Training loss: 434.52, train acc: 0.9989, val loss: 609.61, val acc: 0.9805, time: 274.28s\n",
            "Epoch:20, Training loss: 339.44, train acc: 0.9991, val loss: 593.06, val acc: 0.9800, time: 274.50s\n",
            "Epoch:21, Training loss: 261.48, train acc: 0.9995, val loss: 608.66, val acc: 0.9809, time: 274.68s\n",
            "Epoch:22, Training loss: 206.83, train acc: 0.9996, val loss: 619.82, val acc: 0.9816, time: 275.32s\n",
            "Epoch:23, Training loss: 167.98, train acc: 0.9996, val loss: 609.04, val acc: 0.9809, time: 274.91s\n",
            "Epoch:24, Training loss: 124.90, train acc: 0.9997, val loss: 626.59, val acc: 0.9817, time: 275.14s\n",
            "Epoch:25, Training loss: 94.66, train acc: 0.9998, val loss: 650.88, val acc: 0.9815, time: 275.41s\n",
            "Epoch:26, Training loss: 76.26, train acc: 0.9999, val loss: 674.20, val acc: 0.9817, time: 276.35s\n",
            "Epoch:27, Training loss: 56.53, train acc: 0.9999, val loss: 676.97, val acc: 0.9816, time: 276.29s\n",
            "Epoch:28, Training loss: 40.29, train acc: 0.9999, val loss: 696.38, val acc: 0.9819, time: 277.37s\n",
            "Epoch:29, Training loss: 33.65, train acc: 1.0000, val loss: 677.65, val acc: 0.9827, time: 277.41s\n",
            "Epoch:30, Training loss: 25.98, train acc: 1.0000, val loss: 717.09, val acc: 0.9819, time: 278.24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEAcsUL-7T1B",
        "colab_type": "code",
        "colab": {},
        "outputId": "2114b511-9f07-4cb3-b580-3062c117e607"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_list,  train_loss_list, 'b', label = 'train loss')\n",
        "plt.plot(epoch_list, val_loss_list, 'r', label = 'val loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epoch_list, train_acc_list, 'b', label = 'train accuracy')\n",
        "plt.plot(epoch_list, val_acc_list, 'r', label = 'val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uj7ANbv_jSzI"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iIh-mWrvi6Pw",
        "colab": {}
      },
      "source": [
        "y_true, y_pred,_ = cal_acc(model, val_input_index, val_input_feature, val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VAnJVsyPq5kR",
        "outputId": "df269a97-67de-4aad-8079-0e87b68c7dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-LOC     0.9352    0.9642    0.9495       419\n",
            "      I-MISC     0.8571    0.7701    0.8113       187\n",
            "       I-ORG     0.9560    0.8386    0.8935       285\n",
            "       I-PER     0.9920    0.9920    0.9920       875\n",
            "           O     0.9899    0.9969    0.9934      5790\n",
            "\n",
            "    accuracy                         0.9829      7556\n",
            "   macro avg     0.9460    0.9123    0.9279      7556\n",
            "weighted avg     0.9825    0.9829    0.9825      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ao_KMytuHgOB",
        "colab": {}
      },
      "source": [
        "torch.save(model, 'Bilstm_crf_bert1.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oD53DGCGOLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('Bilstm_crf_bert1.pt').to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghUSX9EOFoyG",
        "colab_type": "text"
      },
      "source": [
        "# Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "84Vihry_Y3lP",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def leaderboard(model, input_index, input_feature):\n",
        "    predicted = []\n",
        "    for i in range(len(input_index)):\n",
        "      input_index_tensor = torch.tensor(input_index[i]).to(device)\n",
        "      input_feature_float = torch.from_numpy(np.array(input_feature[i])).float().to(device)\n",
        "      # add elements of tuple to list\n",
        "      \n",
        "      _, outputs = model(input_index_tensor, input_feature_float)\n",
        "      predicted.extend(outputs)\n",
        "      \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0Y0fX78Ysm7",
        "colab": {}
      },
      "source": [
        "test_pred = leaderboard(model, test_input_index, test_input_feature)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "test_pred_decode = decode_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n2xqOcTPz3iU",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "co1 = []\n",
        "co2 = []\n",
        "for i in range(len(test_pred_decode)):\n",
        "    co1.append(i)\n",
        "    co2.append(test_pred_decode[i])\n",
        "leaderboard = pd.DataFrame({'Id':co1, 'Predicted':co2})\n",
        "leaderboard.to_csv(\"leaderboard_bert1.csv\", index=False, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NulHCRa37T1T",
        "colab_type": "code",
        "colab": {},
        "outputId": "8584c157-f5e4-4112-dc55-adb526abb723"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(13972, 100)\n",
              "  (lstm_1): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_2): LSTM(200, 50, bidirectional=True)\n",
              "  (lstm_3): LSTM(3172, 50, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMYU5CYnHSei",
        "colab_type": "text"
      },
      "source": [
        "Reference:\n",
        "1. All lab materials of COMP5046\n",
        "2. RaRe-Technologies/gensim-data.\n",
        "https://github.com/RaRe-Technologies/gensim-data\n",
        "3. BERT pretrained model. \n",
        "https://huggingface.co/transformers/pretrained_models.html\n",
        "4. Flair Transformer Embedding. https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md\n"
      ]
    }
  ]
}